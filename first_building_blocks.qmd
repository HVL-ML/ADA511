# First building blocks
{{< include _macros.qmd >}}

We shall first discuss how to represent and work with the *agent*, *assumptions*, *conclusions*, *probability* elements, leaving the *actions* and *utilities* to later.


## Agents

The agent is the person or device that has to make a choice between different courses of action. An agent has a specific set of data and background information available, a specific set of choices, and can incur specific gains or losses dependent on the consequences of the available choices.

:::{.column-margin}
We'll use the neutral pronouns *it*/*its* when referring to an agent, since an agent could be a person or a machine.
:::

It is important to identify the agent or agents involved in a problem, because each one will generally have different data, or different available actions, or different gains and losses. A person buying an insurance policy from an insurance company is an example of decision problem with two agents, the person and the company, that have roughly the same data and a common course of action (buy-sell) that is optimal for both. The optimality comes from the fact that the two agents have very different gains and losses for their various courses of action.

::: {.callout-caution}
## {{< fa book-open >}} Reading
[§ 1.1.4 in *Artificial Intelligence*](https://hvl.instructure.com/courses/25074/modules/items/660089)
:::

### Notation

When necessary, agents are typically denoted by capital letters: $A, B,\dotsc$. But we'll rarely need symbols for them.


## Assumptions & conclusions, knowns & unknowns: Sentences

### Assumptions

The "assumptions" often include all or part of the data and information that the agent knows. There is a difference between "assumptions" and "knowns", however. In approaching a decision problem, and especially when considering decision sub-problems of a larger problem, the agent must often reason *hypothetically* or *counterfactually*.

Consider for instance an aeronautics problem where it must be decided whether to replace the fuel currently employed by a particular aircraft model, with a newly produced fuel type. To assess the consequence of employing the new fuel, the engineer must momentarily imagine that the new fuel is actually used and then assess thermodynamic, environmental, and economic consequences of this imagined situation. This is an example of *hypothetical reasoning*. Hypothetical reasoning is sometimes assisted by performing experiments in restricted and controlled conditions, in which the new fuel is really used. Such supporting experiments, however, may not be viable, and in any case they are not full reflections of the hypothetical situation.

The engineer may also have data from another aircraft model with which the new fuel was ultimately *not* used, and may try to assess what the consequences of the new fuel would have been *if it had been replaced* in that model, because such assessment may be easier post-facto. This is an example of *counterfactual reasoning*.

In either instance, the engineer sets up a decision problem in which the assumptions consist of a combination of real data and of a situation that in one case is only imagined, and in the other case never happened. Both kinds of reasoning are staples of scientific research.


### Conclusions

The "conclusions" often include all or part of the hypotheses or conjectures whose truths are unknown to the agent, and the agent would like to assess. Conclusions may also include known data, however. Similarly to "assumptions" and "knowns", there's a difference between "conclusions" and "unknowns".

Consider a data engineer testing the responses of a new machine-learning algorithm, in controlled conditions; this is an example of decision problem about a decision agent. The algorithm being evaluated assesses the truth of a particular situation; this truth is unknown to the algorithm itself, but known to the engineer. More generally, we shall see that an agent may have to assess the truth of a known situation, assuming an  unknown one, as a temporary step in a more general inference.

### Sentences

Is there a flexible and general way of representing assumptions, conclusions, knowns, unknowns, data, information, hypotheses; and, later, also consequences and actions?

When speaking of "data", what comes to mind to many people is basically numbers or collections of numbers. So numbers could perhaps be used to representing assumptions etc. This option turns out to be too limiting, however.

I give you this number: $8$, saying that it is "data". But what is it about? As a decision agent, you can hardly call this number a piece of information, because you have no clue what to do with it. Instead, if I tell you: "*[The number of official planets in the solar system is 8](https://solarsystem.nasa.gov/planets/overview)*", then we can say that I've given you data. So "data" is not just numbers: a number is not "data" unless there's some verbal, non-numeric context accompanying it -- even if this context is only implicitly understood. Note that representing this meta-data information as numbers only shifts the problem one level up: we would need auxiliary verbal context explaining what the meta-data numbers are about.

Data can, moreover, also be completely non-numeric. A clinician saying "*The patient has fully recovered from the disease*" (we imagine to know who's the patient and what was the disease) is giving us a piece of information that we could further use, for instance, to make prognoses about other, similar patients. The clinician's statement surely is "data", but essentially non-numeric data. In some situations we can represent it as "1", while "0" would represent "not recovered"; yet the opposite convention could also be used, showing that these numbers have really nothing to do with the clinician's data.

But the examples above actually contain the answer to our needs. In them we expressed the data by means of [**sentences**]{.text-warning}. Clearly any piece of information, or hypothesis, conclusion, consequence, action can be expressed by a sentence. We shall therefore use sentences, also called *propositions* or *statements*^[These three terms are not always equivalent in Formal Logic, but here we'll use them as synonyms.], to represent and communicate assumptions, conclusions, knowns, unknowns, data, information, hypotheses, consequences, and actions. In some cases we can of course summarize a sentence by a number, as a shorthand, when the full meaning of the sentence is understood.

But what is a sentence? The everyday meaning of this word will work for us, even though there is still a lot of research in logic an artificial intelligence on how to define and use sentences. We shall adopt this useful definition:

::::{.column-margin}
::: {.callout-tip}
## {{< fa book-open >}} For the curious [Propositions](https://plato.stanford.edu/archives/win2020/entries/propositions)
:::
::::

::: {.callout-warning}
##
a "sentence" is a verbal message for which we can determine, at least in principle, whether it is `true` or `false`, in a way that all interested receivers of the message would agree.
:::

For instance, in most engineering contexts the phrase "This valve will operate for at least two months" is a sentence; whereas the phrase "Apples are much tastier than pears" is not, because it's a matter of personal taste. However, the phrase "Rita finds apples tastier than pears" could be a sentence.

Note that a sentence can contain numbers, and even pictures and graphs: this possibility is not excluded from the definition above.

The use of sentences in our framework has important practical consequences:

- **Clarity, analysis, goal-orientation.** A data engineer must acquire information and convey information. Acquiring information is not simply making some measurement or counting something: the engineer must understand *what* is being measured and *why*. If data is gathered from third parties, the engineer must ask what exactly the data mean and how they were acquired. In designing and engineering a solution, it is important to understand what information or outcomes the end user exactly wants. A data engineer will often ask "wait, what do you mean by that?"; this question is not just an unofficial parenthesis in the official data-transfer workflow between the engineer and someone else. It is an integral part of that workflow; it means that the data has not been completely transferred yet.

- **Artificial Intelligence.** Sentences are the central components of knowledge representation and inference in artificial-intelligence agents.

::: {.callout-caution}
## {{< fa book-open >}} Reading
[§ 7.1 in *Artificial Intelligence*](https://hvl.instructure.com/courses/25074/modules/items/660089)
:::

#### Notation

We'll denote sentences by sans-serif italic letters: $\se{A},\se{B},\se{a},\se{b},\dotsc$ For example,
$$
\se{O} \coloneqq \pr{The power output is 100 W}
$$
means that the symbol $\se{O}$ stands for the sentence above. Often we shall simply write sentences in abbreviated form, when their full meaning is understood from the context; for example
"$O = 100\,\mathrm{W}$"
 or even just
"$100\,\mathrm{W}$"
for the sentence above.

We'll next see how more complex sentences are built from simpler ones. No matter whether complex or simple, any sentence can be represented by symbols like the ones above.

## Combining sentences

### Basic sentences

In analysing the assumptions and conclusions of a decision problem it is convenient to find a collection of [**basic sentences**]{.text-warning}^[A more technical term is "atomic"] out of which all other sentences of interest can be constructed. Often these basic sentences represent a elementary pieces of information in the problem.

Consider for instance the following statement in a High-Performance Computing engineering problem:

> "All three CPUs report a temperature of 50 °C. CPUs 1 and 2 are consuming 100 W, whereas CPU 3 is consuming either 110 W or 90 W."

For the sake of this example, let's say that the statement above represents data, that is, it's the description of a factual situation. But keep in mind that in a different problem -- say, one where the unknown temperatures and consumptions of the three CPU need to be assessed -- the same statement could represent a hypothesis, that is, one possible state of affairs among other possible ones.

In the statement above we can identify at least seven basic sentences, which we denote by convenient symbols:
\begin{align*}
\se{t}_{1,50} &\coloneqq \pr{CPU\,1 reports a temperature of 50\,°C}
\\
\se{t}_{2,50} &\coloneqq \pr{CPU\,2 reports a temperature of 50\,°C}
\\
\se{t}_{3,50} &\coloneqq \pr{CPU\,3 reports a temperature of 50\,°C}
\\
\se{c}_{1,100} &\coloneqq \pr{CPU\,1 is consuming 100\,W}
\\
\se{c}_{2,100} &\coloneqq \pr{CPU\,2 is consuming 100\,W}
\\
\se{c}_{3,90} &\coloneqq \pr{CPU\,3 is consuming 90\,W}
\\
\se{c}_{3,110} &\coloneqq \pr{CPU\,3 is consuming 110\,W}
\end{align*}

The decision problem may actually require more basic sentences than just these. For instance, it might become necessary to consider basic sentences with other values for the temperature and of the power consumption, such as
$$\begin{aligned}
\se{t}_{1,55} &\coloneqq \pr{CPU\,1 reports a temperature of 55\,°C} \ ,
\\
\se{t}_{1,60} &\coloneqq \pr{CPU\,1 reports a temperature of 60\,°C} \ ,
\end{aligned}$$
and so on, and similarly for the others CPUs and for the power consumption. Moreover, the phrase "All three CPUs..." suggests that the basic sentence
$$
\se{n} \coloneqq \pr{There are three CPUs}
$$ 
might be part of the data as well. Finally, there are obvious data that we don't even think about but may have to be spelled out explicitly. In our problem an example is the sentence
$$
\pr{CPU\,3 cannot be consuming both 90\,W and 110\,W} \ .
$$


### Connectives

How do we construct the initial data sentence and other complex sentences out of the basic ones?

We consider one way or operation to change a sentence into another related to it, and two ways or operations to combine two or more sentences together. These operations are called [**connectives**]{.text-warning}. Our natural language offer many more operations to combine sentences, but these three turn out to be all we need in virtually all engineering problems. The three connectives and their symbols are:

[Not:\ \ $\lnot$]{.text-warning}
: for example,
$$
\lnot \se{t}_{1,55} = \pr{CPU\,1 reports a temperature different from 55\,°C}
$$

[And:\ \ $\land$]{.text-warning}
: for example,
$$
\se{t}_{2,55} \land \se{c}_{2,100} = \pr{CPU\,2 reports a temperature of 55\,°C and is consuming 100\,W}
$$

[Or:\ \ $\lor$]{.text-warning}
: for example,
$$
\se{c}_{3,90} \lor \se{c}_{2,110} = \pr{CPU\,3 is consuming 90\,W, or 110\,W, or both}
$$

Note some important subtleties of the connectives:

:::{.border}
- There is not a strict correspondence between the words "not", "and", "or" in natural language and the three connectives. For instance the `and` connective could correspond to the words "but" or "whereas", or just to a comma " , ".

- "Not" doesn't mean some kind of complementary quality, but only the negation. For instance, $\lnot\pr{The chair is black}$ does not mean $\pr{The chair is white}$.

- "Or" does not exclude that both sentences can be true. So in our example\ \ $\se{c}_{3,90} \lor \se{c}_{2,110}$\ \ does not exclude, a priori, that CPU 3 can be consuming both 90 W and 100 W. (There is a connective for that: "exclusive-or", but it can be constructed out of the three we already have.)
:::

From the last remark we see that the sentence
$$
\pr{CPU\,3 is consuming either 110\,W or 90\,W}
$$
does *not* correspond to \ \ $\se{c}_{3,90} \lor \se{c}_{3,110}$. The situation assumes implicitly that a CPU cannot have two different power consumption rates at the same time. Convince yourself that the correct way to write that sentence is this:
$$
(\se{c}_{3,90} \lor \se{c}_{3,110})
\land
\lnot(\se{c}_{3,90} \land \se{c}_{3,110})
$$

Finally, the full initial statement can be written in symbols as follows:
$$
\se{t}_{1,50} \land \se{t}_{2,50} \land \se{t}_{3,50}
\land \se{c}_{1,100} \land \se{c}_{2,100}
\land (\se{c}_{3,90} \lor \se{c}_{3,110})
\land
\lnot(\se{c}_{3,90} \land \se{c}_{3,110})
$$


## Distinguishing assumptions and conclusions

Now we know to represent arbitrarily complex sentences and express them in symbols. Let's introduce a way to clearly distinguish those that constitute the *assumptions* from those that constitute the *conclusions* in a specific decision problem. 

We can simply use the symbol\ \ "$\pmb{\|[\big]}$",\ \ a **vertical bar**^[Notation in formal logic uses the symbols\ \ $\models$\ \ or\ \ $\vdash$,\ \ and writes assumptions on the *left*, conclusions on the *right*. We use the notation used in probability logic.]:

- on its *left* side those that make up our desired *conclusion*,
- on its *right* side we write the sentences that make up our *assumptions*, `and`-ed together:

$$
\textit{\small conclusion} \pmb{\|[\big]} \textit{\small assumptions}
$$





So, in symbols, our inference is this:
$$
b \|[\Big] (b\lor r)\, \land\, \lnot r\, \land\, \lnot(b \land r)\, \land\, D
$$
Note how we `and`-ed all assumptions together. The collection of assumptions on the right side of the bar "$\|[\big]$" is called the [**conditional**]{.text-warning}. The expression above is read "$b$ *given* $(b\lor r)$" etc., or "$b$ *conditional on* $(b\lor r)$" etc.

All data in the conditional (that is, on the right side of "$\|[\big]$") are considered (at least temporarily) to be `true`. Our goal is to determine whether the sentence on the left of "$\|[\big]$" is `true` or `false`.






"Basic" in the sense that we will not analyse these sentences into further sub-sentences. In the trivial example above we identify three such sentences: $\pr{Rita has an umbrella}$, $\pr{The umbrella is blue}$, and $\pr{The umbrella is red}$. Let's represent them by symbols:
$$
\begin{aligned}
b &\coloneqq \pr{Rita's umbrella is blue}
\\
r &\coloneqq \pr{Rita's umbrella is red}
\end{aligned}
$$

<!-- ::::{.column-margin} -->
<!-- ::: {.callout-warning appearance="simple"} -->
<!-- ## -->
<!-- {{< fa exclamation-triangle >}} Note a subtlety in our data -- and again why we need to make their underlying sentences as clear as possible: it is understood here that the umbrella is all of one colour. We'll come back to this later. -->
<!-- ::: -->
<!-- :::: -->

### Connectives

We didn't consider $\pr{Rita's umbrella is either blue or red}$, $\pr{The umbrella is not blue}$, and $\pr{The umbrella is not red}$ as basic sentences. These sentences can in fact be expressed in terms of the basic sentences $b$ and $r$. We consider one way or operation to change a sentence into another related to it, and two ways or operations to combine two or more sentences together. These operations are called **connectives**. Our natural language offers many more operations to combine sentences, but these three turn out to be all we need in virtually all engineering problems. The three connectives are:

Not: $\lnot$
: for example,
$$
\lnot b = \pr{Rita's umbrella is not blue}
$$

And: $\land$
: for example,
$$
b \land r = \pr{Rita's umbrella is blue, and it is red}
$$

Or: $\lor$
: for example,
$$
b \lor r = \pr{Rita's umbrella is blue, or red, or both}
$$

::: {.callout-warning appearance="simple"}
## 
{{< fa exclamation-triangle >}} Note some subtleties of the connectives:

- "Not" doesn't mean some kind of complementary quality, but only the negation. For instance, $\lnot\pr{Rita's umbrella is black}$ does not mean $\pr{Rita's umbrella is white}$.

- $b \lor r$ does not exclude, a priori, that the umbrella cannot be both blue and black (there is a connective for that: "exclusive-or", but it can be constructed out of the three we already have.)

- It is important to distinguish between *logical* impossibility and *physical* impossibility. It is physically impossible that an umbrella be fully white and fully black, but formal logic does allow us to consider the sentence "the umbrella is fully white and fully black", without setting it true or false a priori. We express its physical impossibility by assigning to it the value `false` in any inference we want to make. This generality of formal logic is a feature: it allows us to entertain and study hypotheses even if we still don't know whether they are physically impossible. Scientific research could not be done without this feature.
:::

What about the "if" in "if the umbrella..."? Shouldn't that be a connective? This "if" is treated in a special way; we shall now see how it works.

:::{.column-margin}
<!-- {{< fa info-circle >}}  -->
There is an [old and still ongoing debate](https://plato.stanford.edu/entries/logic-conditionals) in logic and probability on how to deal with "if"-statements. Here we take the seemingly most common approach, which is simple and effective in applied problems.
:::


Obviously we possess even more information, which is implicitly understood. For example, it's understood that the umbrella is all of one colour. It must also be understood what an umbrella is, what "red" and "blue" mean, and so on. Usually this kind of information is extremely obvious or irrelevant, so we don't think about it very much and don't mention it. In real engineering problems, however, it may happen that we have to stop and examine this implicit, hidden knowledge, maybe to check whether it contains contradictory information or contradictory goals. It's a good idea to represent this implicitly-understood information by a symbol, for example $I$ (for "extra information"; we could have used $K$ for "knowledge").




### Separating assumptions and conclusions

Now we have the sentences that represent all our data and the information we are interested in, and even symbols to represent them in a compact way. It's important to keep the assumptions we make well separated from the conclusions we want to draw. Let's introduce a symbol to do just that.

We can simply use a vertical bar: on its right side we write the sentences that make up our assumptions, and on its left side those that make up our desired conclusions.^[Current notation in logic uses the symbols $\models$ or $\vdash$, and writes assumptions on the *left*, conclusions on the *right*. We use a different notation for an easier transition to probability logic.] So, in symbols, our inference is this:
$$
b \|[\Big] (b\lor r)\, \land\, \lnot r\, \land\, \lnot(b \land r)\, \land\, D
$$
Note how we `and`-ed all assumptions together. The collection of assumptions on the right side of the bar "$\|[\big]$" is called the [**conditional**]{.text-warning}. The expression above is read "$b$ *given* $(b\lor r)$" etc., or "$b$ *conditional on* $(b\lor r)$" etc.

All data in the conditional (that is, on the right side of "$\|[\big]$") are considered (at least temporarily) to be `true`. Our goal is to determine whether the sentence on the left of "$\|[\big]$" is `true` or `false`.





## well-posed and ill-posed sentences

We face problems when the sentences that should convey information and data are not clear. Suppose that an electric-car model [consumes 150 Wh/km](https://ev-database.org/cheatsheet/energy-consumption-electric-car) and [has a range of 200 km](https://ev-database.org/cheatsheet/range-electric-car); a second car model consumes 250 Wh/km and has a range of 600 km. Someone says "I think the second model is better; what do you think?". It isn't clear how we should answer; what does "better" mean? If it refers to consumption, then the first car model is "better". If it refers to range, then the second model is "better". If it refers to a combination of these two characteristics, or to something else, then we simply can't answer. Here we have a problem with querying and giving data, because the sentence underlying such query is not clear.

We say that such sentences are **not well-posed**, or that they are **ill-posed**.

This may seem an obvious discussion to you. Yet you'd be surprised by how often unclear sentences appear in scientific papers about data engineering! Not seldom we find discussions and disagreements that actually come from unclear underlying sentences, that two parties interpret in different ways.

As a data engineer, you'll often have the upper hand if you are on the lookout for ill-posed sentences. Whenever you face an important question, or you're given an important piece of information, or you must provide an important piece of information, *always take a little time to examine whether the question or information is actually well-posed*.

@@ [TODO] Exercise: give actual paper to analyse_



## Reading list {.unnumbered}

