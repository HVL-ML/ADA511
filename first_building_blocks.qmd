# First building blocks
{{< include macros.qmd >}}

We shall first discuss how to represent and work with the *agent* and *background information*, *assumptions*, *outcomes*, *probability* elements, leaving the *decisions* and *utilities* to later.


## Agents

The agent is the person or device that has to make a choice between different decisions. An agent possesses a specific set of background information and data, a specific set of available decisions, and can incur specific gains or losses dependent on the outcomes of the available decisions.

:::{.column-margin}
We'll use the neutral pronouns *it*/*its* when referring to an agent, since an agent could be a person or a machine.
:::

It is important to identify the agent or agents involved in a problem, because each one will generally have different data, or different available decisions, or different gains and losses. A person buying an insurance policy from an insurance company is an example of decision problem with two agents, the person and the company, that have roughly the same data and a common decision (buy-sell) that is optimal for both. The optimality comes from the fact that the two agents have very different gains and losses for their various decisions.

::: {.callout-caution}
## {{< fa book-open >}} Reading
§ 1.1.4 in [*Artificial Intelligence*](https://hvl.instructure.com/courses/25074/modules/items/660089)
:::

### Notation

When necessary, agents are typically denoted by capital letters: [$A, B,\dotsc$.]{.together} But we'll rarely need symbols for them.


## Assumptions & outcomes, knowns & unknowns

### Assumptions

The "assumptions" often include all or part of the data and information that the agent knows. There is a difference between "assumptions" and "knowns", however. In approaching a decision problem, and especially when considering decision sub-problems of a larger problem, the agent must often make **hypothetical** or **counterfactual** reasonings.

Consider for instance an aeronautics problem where it must be decided whether to replace the fuel currently employed in a particular aircraft model, with a newly produced fuel type. To assess the outcome of employing the new fuel, the engineer must momentarily imagine that the new fuel is actually used and then assess thermodynamic, environmental, and economic outcomes of this imagined situation. This is an example of *hypothetical reasoning*. Hypothetical reasoning is sometimes assisted by performing experiments in restricted and controlled conditions, in which the new fuel is really used. Such supporting experiments, however, may not be viable, and in any case they are not full reflections of the hypothetical situation.

The engineer may also have data from another, smaller aircraft model in which the new fuel was ultimately *not* used, and may try to assess what the outcomes of the new fuel would have been *if it had been replaced* in that model, maybe because they are easier to assess in that case. This is an example of *counterfactual reasoning*.

In either instance, the engineer sets up a decision problem in which the assumptions consist of a combination of real data and of a situation that in the hypotetical case is only imagined, and in the counterfactual case never happened. Both kinds of reasoning are staples of scientific research.


### Outcomes

The "outcomes" often include all or part of the hypotheses or conjectures whose truths are unknown to the agent and that the agent would like to assess. But outcomes may also include known data. Similarly to "assumptions" and "knowns", there's a difference between "outcomes" and "unknowns".

Consider a data engineer testing, in controlled conditions, the responses of a new machine-learning algorithms. This is an example of decision problem about a decision agent. The algorithm infers the truth of a particular outcome. In the test, this truth is unknown to the algorithm itself, but it is known to the engineer. More generally, we shall see that an agent may have to assess the truth of a known outcome, given a unknown assumption, as a temporary step in a more general inference.

## Sentences

### How to represent assumptions, outcomes, decisions?

Is there a flexible and general way of representing assumptions, outcomes, knowns, unknowns, data, information, hypotheses; and, later, also outcomes and decisions?

When speaking of "data", what comes to mind to many people is basically numbers or collections of numbers. So numbers could perhaps be used to representing assumptions etc. This option turns out to be too limiting, however.

I give you this number: [$8$,]{.together} saying that it is "data". But what is it about? As a decision agent, you can hardly call this number a piece of information, because you have no clue what to do with it. Instead, if I tell you: "*[The number of official planets in the solar system is 8](https://solarsystem.nasa.gov/planets/overview)*", then we can say that I've given you data. So "data" is not just numbers: a number is not "data" unless there's some verbal, non-numeric context accompanying it -- even if this context is only implicitly understood. Note that representing this meta-data information as numbers only shifts the problem one level up: we would need auxiliary verbal context explaining what the meta-data numbers are about.

Data can, moreover, also be completely non-numeric. A clinician saying "*The patient has fully recovered from the disease*" (we imagine to know who's the patient and what was the disease) is giving us a piece of information that we could further use, for instance, to make prognoses about other, similar patients. The clinician's statement surely is "data", but essentially non-numeric data. In some situations we can represent it as "1", while "0" would represent "not recovered"; yet the opposite convention could also be used, showing that these numbers have really nothing to do with the clinician's data.

But the examples above actually reveal the answer to our needs. In the examples we expressed the data by means of [**sentences**]{.blue}. Clearly any piece of information, hypothesis, outcome, decision can be expressed by a sentence. We shall therefore use sentences, also called *propositions* or *statements*^[These three terms are not always equivalent in Formal Logic, but here we'll use them as synonyms.], to represent and communicate assumptions, outcomes, knowns, unknowns, data, information, hypotheses, and decisions. In some cases we can of course summarize a sentence by a number, as a shorthand, when the full meaning of the sentence is understood.

But *what is a sentence*? The everyday meaning of this word will work for us, even though there is still a lot of research in logic an artificial intelligence on how to define and use sentences. We shall adopt this useful definition:

::::{.column-margin}
::: {.callout-tip}
## {{< fa book-open >}} For the curious [Propositions](https://plato.stanford.edu/archives/win2020/entries/propositions)
:::
::::

::: {.callout-note}
##
[A "sentence" is a verbal message for which we can determine whether it is `true` or `false`, at least in principle and in such a way that all interested receivers of the message would agree.]{style="color:#4477AA;font-size:125%"}
:::

For instance, in most engineering contexts the phrase "This valve will operate for at least two months" is a sentence; whereas the phrase "Apples are much tastier than pears" is not, because it's a matter of personal taste -- there's no objective criterion to determine its truth or falsity. However, the phrase "Rita finds apples tastier than pears" could be a sentence.

Note that a sentence can contain numbers, and even pictures and graphs: this possibility is not excluded from the definition above.

The use of sentences in our framework has important practical consequences:

- **Clarity, analysis, goal-orientation**. A data engineer must acquire information and convey information. Acquiring information is not simply making some measurement or counting something: the engineer must understand *what* is being measured and *why*. If data is gathered from third parties, the engineer must ask what exactly the data mean and how they were acquired. In designing and engineering a solution, it is important to understand what information or outcomes the end user exactly wants. A data engineer will often ask "wait, what do you mean by that?"; this question is not just an unofficial parenthesis in the official data-transfer workflow between the engineer and someone else. It is an integral part of that workflow; it means that the data has not been completely transferred yet.

- **Artificial Intelligence**. Sentences are the central components of knowledge representation and inference in artificial-intelligence agents.

::: {.callout-caution}
## {{< fa book-open >}} Reading
§ 7.1 in [*Artificial Intelligence*](https://hvl.instructure.com/courses/25074/modules/items/660089)
:::

#### Notation

We'll denote sentences by sans-serif italic letters: $\se{A},\se{B},\se{a},\se{b},\dotsc$ For example,
$$
\se{O} \coloneqq \pr{The power output is 100 W}
$$
means that the symbol $\se{O}$ stands for the sentence above. Often we shall simply write sentences in abbreviated form, when their full meaning is understood from the context; for example
["$O = 100\,\mathrm{W}$"]{.together}
 or even just
["$100\,\mathrm{W}$"]{.together}
for the sentence above.

We'll next see how more complex sentences are built from simpler ones. No matter whether complex or simple, any sentence can be represented by symbols like the ones above.

## Combining sentences

### Basic sentences

In analysing the assumptions and outcomes of a decision problem it is convenient to find a collection of [**basic sentences**]{.blue}^[A more technical term is *atomic sentences*.] out of which all other sentences of interest can be constructed. Often these basic sentences represent elementary pieces of information in the problem.

Consider for instance the following sentence which could appear in our earlier assembly-line problem:

> "The electronic component is still whole after the shock test and the subsequent heating test. The voltage reported in the power test is either 90 mV or 110 mV."

In our example the statement above represents data, that is, it's the description of a factual situation. But keep in mind that in a different problem -- say, one where it need to be assessed whether the component is still whole -- the same statement could represent a hypothesis, that is, one possible state of affairs among other possible ones.

In the statement above we can identify at least four basic sentences, which we denote by convenient symbols:
\begin{align*}
\se{s} &\coloneqq \pr{The component is whole after the shock test}
\\
\se{h} &\coloneqq \pr{The component is whole after the heating test}
\\
\se{v}_{90} &\coloneqq \pr{The power-test voltage reading is 90\,mV}
\\
\se{v}_{110} &\coloneqq \pr{The power-test voltage reading is 110\,mV}
\end{align*}

The decision problem may actually require more basic sentences than just these. For instance, it might become necessary to consider basic sentences with other values for the reported voltage, such as
$$\begin{aligned}
\se{v}_{110} &\coloneqq \pr{The power-test voltage reading is 100\,mV}
\\
\se{v}_{80} &\coloneqq \pr{The power-test voltage reading is 80\,mV}
\end{aligned}$$
and so on.

There may also be other basic sentences coming from data or hypotheses that aren't stated explicitly because obvious. Yet they may have to be spelled out. An example in our decision problem is the sentence
$$
\pr{The electronic component cannot be broken after the shock test and whole after the subsequent heating test}
$$
which must necessarily be true for physical reasons.

### Connectives

How do we construct the initial data sentence, and more complex sentences out of simpler ones in general?

We consider one way or operation to change a sentence into another related to it, and two ways or operations to combine two or more sentences together. These operations are called [**connectives**]{.blue}. Our natural language offer many more operations to combine sentences, but these three turn out to be all we need in virtually all engineering problems. The three connectives and their symbols are:

:::{.border}
[Not:\ \ $\lnot$]{.blue}
: for example,
$$
\lnot \se{s} = \pr{The component is broken after the shock test}
$$

[And:\ \ $\land$]{.blue}
: for example,
$$
\se{s} \land \se{h} = \pr{The component is whole after the shock and heating tests}
$$

[Or:\ \ $\lor$]{.blue}
: for example,
$$
\se{v}_{90} \lor \se{v}_{110} = \pr{The power-test voltage reading is 90\,mV, or 110\,mV, or both}
$$
:::
\

The connectives can be applied multiple times, to form increasingly complex sentences.

{{< fa exclamation-circle >}}\ \ Note some important subtleties of the connectives:

- There is no strict correspondence between the words "not", "and", "or" in natural language and the three connectives. For instance the `and` connective could correspond to the words "but" or "whereas", or just to a comma " , ".

- `Not` doesn't mean some kind of complementary quality, but only the negation. For instance,\ \ $\lnot\pr{The chair is black}$\ \ does not mean\ \ [$\pr{The chair is white}$ ,]{.together}\ \  although in some situations these two sentences could amount to the same thing.

- It's best to always declare explicitly what the `not` of a sentence concretely means. In our example, we take\ \ $\lnot\pr{The component is whole}$\ \ to mean\ \ [$\pr{The component is broken}$ .]{.together}\ \ But in other examples the negation of "being whole" could comprise several different conditions. A good guideline is to always state the `not` of a sentence in *positive* terms.

- `Or` does not exclude that both the sentences it connects can be true. So in our example\ \ $\se{v}_{90} \lor \se{v}_{110}$\ \ does not exclude, a priori, that the reported voltage could be both 90 mV and 110 mV. (There is a connective for that: "exclusive-or", but it can be constructed out of the three we already have.)

From the last remark we see that the sentence
$$
\pr{The power-test voltage reading is 90\,mV or 110\,mV}
$$
does *not* correspond to \ \ [$\se{v}_{90} \lor \se{v}_{110}$ .]{.together}\ \ It is implicitly clear that a voltage reading cannot yield two different values at the same time. Convince yourself that the correct way to write that sentence is this:
$$
(\se{v}_{90} \lor \se{v}_{110})
\land
\lnot(\se{v}_{90} \land \se{v}_{110})
$$

Finally, the full data statement of our present example can be written in symbols as follows:
$$
\se{s} \land \se{h} \land
(\se{v}_{90} \lor \se{v}_{110})
\land
\lnot(\se{v}_{90} \land \se{v}_{110})
$$


## Distinguishing assumptions and outcomes

Now we know how to represent arbitrarily complex sentences and express them in symbols. Let's introduce a way to clearly distinguish sentences that constitute the *assumptions* from those that constitute the *outcome* in a basic decision problem. In our assembly-line example, suppose that assumptions are the statement discussed in the previous section. The outcome to be inferred is expressed by this sentence:
$$
\se{f} \coloneqq \pr{The component will fail within a year}
$$

To distinguish assumptions and outcomes we can simply use a vertical bar,^[Notation in formal logic uses the symbols\ \ [" $\models$ "]{.together}\ \ or\ \ [" $\vdash$ ",]{.together}\ \ and writes assumptions on the *left*, outcomes on the *right*. We use the notation used in probability logic.] like\ \ ["$\color[RGB]{68,119,170}\pmb{\|[\big]}$" :]{.together}

- on its *left* side we write the sentence representing the *outcome*,
- on its *right* side we write the sentences that make up our *assumptions*, `and`-ed together:

$$
\textit{\small outcome} \pmb{\|[\big]} \textit{\small assumptions}
$$

So in our example we write:
$$
f \|[\Big]
\se{s} \land \se{h} \land
(\se{v}_{90} \lor \se{v}_{110})
\land
\lnot(\se{v}_{90} \land \se{v}_{110})
$$

The collection of assumptions on the right side of the bar ["$\pmb{\|[\big]}$"]{.together} is called the [**conditional**]{.blue}. The expression above is read\
["$\se{c}_{2,90}$\ \  *given*\ \  $\se{t}_{1,50} \land \se{t}_{2,50}
\land\dotsb$"]{.together}\
or\
["$\se{c}_{2,90}$\ \  *conditional on*\ \  $\se{t}_{1,50} \land \se{t}_{2,50} \land\dotsb$".]{.together}

\

We are now equipped with all the notions and symbolic notation to deal with our first concrete goal: drawing uncertain inferences.

## Inferences: certain and uncertain

In a decision problem we have a set of different outcomes that we want to assess given the same assumptions:
$$\begin{aligned}
\textit{\small outcome\,1} &\pmb{\|[\big]} \textit{\small assumptions}
\\
\textit{\small outcome\,2} &\pmb{\|[\big]} \textit{\small assumptions}
\\
\textit{\small outcome\,3} &\pmb{\|[\big]} \textit{\small assumptions}
\\
\dotso&
\end{aligned}$$

The first goal in a decision problem is to assess these outcomes. What do we mean by "assess"? We cannot demand that the truth or falsity of the outcomes be determined with certainty. 
