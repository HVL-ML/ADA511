# [Statistics]{.yellow}
{{< include macros.qmd >}}
{{< include macros_statistics.qmd >}}


## The difference between Probability Theory and Statistics

"Probability theory" and "statistics" are often mentioned together. We shall soon see why and what are the relationship between them. But first let's try to define them more precisely:

[**Probability theory**]{.blue}
: is the theory that describes and norms the quantification and propagation of uncertainty, as we saw in [§ @sec-probability-def].


[**Statistics**]{.blue}
: is the study of collective properties of the variates of populations or, more generally, of collections of data.

There are clear and crucial differences between the two:

- The fact that uncertain about something doesn't mean that there are populations or replicas involved. We can apply probability theory without doing any statistics.
- If we have full information about a population -- the value of the variate for each unit -- then we can calculate summaries and other properties of the variate. And there's no uncertainty involved: at all times we can exactly calculate any information we like about the variate. So we do statistics but probability theory plays no role (except perhaps in the form of propositional logic).


Many texts do not clearly distinguish between probability and statistics. The distinction is important for us because we will have to solve problems involving the *uncertainty* about particular *statistics*, so the two must be kept clearly separate. This distinction was observed by [James Clerk Maxwell](https://clerkmaxwellfoundation.org/html/about_maxwell.html) who used it to develop the theories of statistical mechanics and kinetic theory.

::::{.column-margin}
::: {.callout-tip}
## {{< fa rocket >}} For the extra curious

Maxwell explains the statistical method and its use in the molecular description of matter:

- [*Introductory Lecture on Experimental Physics*](https://hvl.instructure.com/courses/25074/modules/items/676284)
- [*Molecules*](https://hvl.instructure.com/courses/25074/modules/items/676285)
:::
::::


In many concrete problems, however, these do theories do go hand in hand and interact. This happens mainly in two non-mutually exclusive ways:

- the statistics of a population give information that can be used in the conditional of an inference
- we want to draw inferences about some statistics of a population, whose values we don't know.

\

Let's now discuss some important statistics.



## Frequency distributions {#sec-freq-distribs}

Consider a statistical population of $N$ units, with a variate $X$ having a finite set of $K$ values as domain. To keep things simple let's just say these values are $\set{1, 2, \dotsc, K}$ (without any ordering implied); the discussion applies for any finite set.
<!-- $\set{a_1, a_2, \dotsc, a_K}$  -->
The variate $X$ could be of any non-continuous type: nominal, ordinal, interval, binary ([§ @sec-basic-types]), or of a joint or complex type ([§ @sec-quantities-types-multi]). Let's denote the variate associated with unit $i$ with $X_i$. For instance, we express that unit #3 has variate value $5$ and unit #7 has variate value $1$ by writing

$$
X_3 \mo 5 \land X_7 \mo 1
\quad\text{\small or more compactly}\quad
X_3 \mo 5 \and X_7 \mo 1
$$

For each value $a$ in the domain of the variate, we count how many units in the population have that particular value, let's call the number we find $n_a$. This is the [**absolute frequency**]{.blue} of the value $a$ in this population. Obviously $n_a$ must be an integer between $0$ (included) and $K$ (included). The set of absolute frequencies of all values is called the [**absolute frequency distribution**]{.blue} of the values (or of the variate) in the population. We must have

$$\sum_{a=1}^K n_a = N \ .$$

It is often useful to give not the absolute count of the times the value $a$ appears in a population, but the fraction with respect to the population size, which we denote by $f_a$:

$$f_a \defd n_a/N$$

This is called the [**relative frequency**]{.blue} of the value $a$. Obviously $0 \le f_a \le 1$. The collection of relative frequencies for all values, $\set{f_1, f_2, \dotsc, f_K}$, satisfies

$$\sum_{a=1}^K f_a = 1 \ .$$

We call this collection the [**relative frequency distribution**]{.blue}. We shall denote it with the boldface symbol $\vec{f}$ (boldface indicates that it is a tuple of numbers):

$\vec{f} \defd (f_1, f_2, \dotsc, f_K)$

with an analogous convention if other letters are used instead of "$f$".

In the following we shall call relative frequencies simply "frequencies".

\

The frequency distribution of values in a population does not give us full information about the latter, because it doesn't tell which unit has which value. In many situations, however, this is all we need to know.

Frequencies and frequency distributions are *quantities* in the technical sense of [§ @sec-quant-value-dom]. In fact we can say, for instance, "The frequency of the value $7$ is 0.3", or "The frequency distribution for the values $1,2,3$ is $(0.2, 0.7, 0.1)$". We shall denote the quantity, as separate from its value, by the corresponding capital letter, for example $F_1$, so that we can write sentences about frequencies in our usual abbreviated form. For instance

$$
F_3\mo f_3
$$

means "The frequency of the variate value $3$ is equal to $f_3$", where $f_3$ must be a specific number.


:::{.callout-caution}
## {{< fa user-edit >}} Exercise

A statistical population is defined as follows:

- *units:* the bookings at a specific hotel during a specific time period
- *variate:* the market segment of the booking
- *variate domain:* the set of five values $\set{\cat{Offline},\  \cat{Online},\  \cat{Corporate},\  \cat{Aviation},\  \cat{Complementary},\  \cat{Complementary}}$

The population data is stored in [this `csv` file](datasets/hotel_bookings.csv). Each row of the file corresponds to a unit, and lists the unit id (this is not a variate in the present population) and the market segment.

Use any method you like (a script in your favourite programming language, counting by hand, or whatever) to answer these questions:

- How many units are in the population?
- What are the absolute frequencies of the five values?
- What are their relative frequencies?
- Which units have the value $\cat{Corporate}$?
:::



### Differences between frequencies and probabilities

The fact that frequencies are non-negative and sum up to 1 makes them somewhat similar to probabilities *from a purely numerical point of view*. The two notions, however, are completely different and have different uses. Here is a list of some important differences:

::::{.column-margin}
Not few works in machine learning tend to call "probabilities" any set of positive numbers that sum up to one. Be careful when reading them. Mentally replace *probability* with *degree of belief* and see if the text mentioning "probabilities" still makes sense.
::::

1.
    - [*A probability expresses a **degree of belief**.*]{.green}
    - [*A frequency is just the **count** of how many times something appears.*]{.purple}

2.
    - [*The probability of a sentence depends on an agent's state of knowledge and background information.*]{.green} Two agents can assign different probabilities to the same sentence.
    - [*The frequency of a value in a population is an objective physical quantity.*]{.purple} All agents agree on the frequency (if they know it).


<!-- 3. As a consequence of the difference above, [*a probability is updated when the background information changes.*]{.green}\ -->
<!-- [*The frequency of a value in a population will always stay the same.*]{.purple} -->

3.
    - [*Probabilities refer to **sentences**.*]{.green}
    - [*Frequencies refer to **values** in a population*]{.purple}, not to sentences (unless we are speaking of how many times a sentence appears in, say, a book; but this is a completely different and peculiar case.)

4.
    - [*A probability can refer to a specific unit in a population.*]{.green} An agent can consider, for instance, the probability that the variate for unit #7 has value `3`.
    - [*A frequency cannot refer to a specific unit in a population.*]{.purple} It is somewhat meaningless to "count how many times the value `3` appears in unit #7".

<!-- 5. -->
<!--     - [*The probability that a particular unit has a particular quantity value is independent of the population considered.*]{.green} For instance, the probability that a particular rock from Mars contains hematite does not depend on whether we consider that rock as one of the rocks in a particular crater, or one of the rocks on all of Mars, or one of the rocks in the whole solar system. -->
<!--     - [*The frequency of a value  depends completely on the population considered.*]{.purple} For instance, hematite might appear with a frequency of 30% among all rocks in a particular Mars crater, but with a frequency of 10% among all rocks on Mars. -->


### Limit frequencies

In discussing statistical populations we said ([§ @sec-infinite-populations]) that we shall often focus on practically infinite populations, that is, populations whose number of units is much larger than the number which will be used as data or on which inferences will be drawn.

Relative frequencies are ratios of two integers, the denominator being the population size $N$. So a frequency $f$ can only take on $N+1$ rational values $0/N, \dotsc, N/N$ between $0$ and $1$. As the population size increases, the number of distinct, possible frequencies increases and eventually can be considered practically continuous. Frequencies in this case are sometimes called **limit frequencies** and they are treated as real numbers between $0$ and $1$.


<!-- It is then useful to proceed as is [§ @sec-prob-densities] and use a  [**frequency density**]{.blue} $f(v)$ defined as -->

<!-- $$ -->
<!-- f(v) -->
<!-- \defd -->
<!-- \frac{ -->
<!-- \text{\small absolute frequency of all values between \(v-\epsilon/2\) and \(v+\epsilon/2\)} -->
<!-- }{\epsilon} -->
<!-- $$ -->

<!-- The discussion of [§ @sec-prob-densities] about densities applies also in the case of frequency distributions. -->


## Quantiles

[@@ TODO]{.small .grey}

### Median and interquartile range

[@@ TODO]{.small .grey}

## Mean and standard deviation

[@@ TODO]{.small .grey}
