Machine Learning and Artificial Intelligence are developing extremely fast, they are increasingly used in ethically sensitive domains such as medicine, they see many possibilities of improvement with near-future technologies. When factors such as these converge, one rediscovers the importance of the scientific foundations of a field. Bayesian foundations in this case.

This is the goal of a new course at the Western Norway University of Applied Sciences, endorsed by the Artificial Intelligence Engineering group. The course's name is ``foundations of data science and data-driven engineering'', but more precisely it is about \emph{Bayesian nonparametric density inference} and \emph{Bayesian decision theory}: most present-day machine-learning algorithms are indeed essentially doing an approximate form of nonparametric density inference.

The course is part the master's programme in Applied Computer Science, and is designed to cater for students with very diverse backgrounds within computer science and data science, and never exposed to Bayesian notions before. % The mathematical level had to be kept at the level of basic functional analysis and integration.
The introduction of Bayesian probability \&\ decision theory turned out to be very natural from an artificial-intelligence perspective. The students want to build an \emph{AI agent} capable of drawing inferences and making decisions under uncertainty, at least in specific applications.

We adopted an approach Ã  la Johnson, Jeffreys, Cox, Jaynes, Hailperin, taking \emph{propositions} as the basic objects for the probability calculus. They are particularly suited to an artificial-intelligence approach, as they can flexibly represent information, hypotheses, decisions. Their use moreover connects with much AI literature on knowledge-base representation.

Probability emerges as an inevitable notion to quantify the agent's uncertainty or degree of belief. The four basic axioms of coherence (or Cox's axioms) and the principle of maximal expected utility also enter quite naturally, as the rules by which the AI agent can calculate any needed degrees of belief in a self-consistent way, update them according to new training data entering its knowledge base, and make optimal decisions.

The students found such a framework sensible, and readily grasped the difference between probability and frequency, as well as the necessity of initial degrees of belief (priors) and utilities to ``jump-start'' the agent.

We gradually focused this framework on the construction of an AI agent capable of solving specific tasks where an assumption of \emph{exchangeability} can be made.

The students easily understood the idea of exchangeability and how it applies to specific machine-learning tasks. De~Finetti's representation theorem was introduced in an intuitive way, the integration parameter presented as the ``future and past frequencies'' of a task's outcomes. From a principled point of view we are not completely satisfied with such an interpretation. But it seems that the students grasped it easily and it also helped them not to conflate probability and frequency.

An exciting part of the course was the final design and building of a simple but concrete ``AI agent'' that operates exactly according to the coherence rules and the exchangeability assumption, learns from data, draws inferences, and makes decisions. The students had become increasingly eager to build it, their enthusiasm was very contagious! Their common mathematical denominator didn't allow for the development of nonparametric models with continuous variates, possibly needing Monte Carlo methods. We focused instead on inference and decision tasks involving variates of nominal type, and built an AI agent based on the Dirichlet distribution -- a nonparametric model on a finite dimensional space.

Students with prior machine-learning education were positively surprised by the flexibility and features of their AI agent. In particular that: (1) it does not have a hard-coded distinction between ``features'' (predictors) and ``labels'' (predictands): given any known variate, it can calculate the probability of any unknown variate as desired; (2) it can tell how the calculated probability could change if more training data were available -- one of the beautiful features of de~Finetti's theorem; (3) it outputs probabilities, and so can make decisions based on utilities that can change from a task instance to the next.

These observations also made the students realize the intrinsic assumptions, approximations, and limitations of many present-day machine-learning algorithms such as neural networks (for instance the maximum-likelihood approximation underlying most machine-learning models, or the fact that utilities are intrinsically hard-coded). Indeed, the most fulfilling outcome of the course is that many students concluded it with ambitions about modifying complex machine-learning models or build completely new ones that could better approximate the ``perfect (Bayesian) AI agent''. Some of them will probably go on working with Bayesian neural networks or fully nonparametric Bayesian models.

Our and our students' experience during this course shows that Bayesian Theory can be fully integrated with Artificial Intelligence and Machine Learning, at their very foundations. Maybe a good strategy is not to insist on particular terminology or vernaculars. We used the adjective ``Bayesian'' only once or twice in the whole course, yet it is undeniable that the students learned the basics and some important applications of Bayesian Theory.

The course did not have a textbook, or rather we created our own (see below), drawing from Parts~III--IV of Russell \&\ Norvig's \href{http://aima.cs.berkeley.edu/global-index.html}{\emph{Artificial Intelligence: A Modern Approach}} (Pearson 2022) -- an excellent text for Bayesian inference and decision theory -- as well as some parts of Lindley's \emph{Making Decisions} (Wiley 1988), O'Hagan's \href{https://doi.org/10.1007/978-94-009-1211-3}{\emph{Probability: Methods and measurement}} (Chapman \&\ Hall 1988), Fenton \&\ Neil's \href{https://doi.org/10.1201/b21982}{\emph{Risk Assessment and Decision Analysis with Bayesian Networks}}, and other texts and articles.

\smallskip


We will be extremely happy if other teachers find the course or any of its parts useful. It is freely accessible on GitHub at\enspace \url{https://hvl-ml.github.io/ADA511/}\,,\enspace and can be freely forked from \url{https://github.com/pglpm/ADA511}. Any comments, corrections, criticisms, suggestions for improvements are heartily welcome.

