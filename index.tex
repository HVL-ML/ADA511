% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames,x11names}{xcolor}
%
\documentclass[
  a4paper,
  DIV=11,
  numbers=noendperiod,
  oneside]{scrreprt}

\usepackage{amsmath,amssymb}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else  
    % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\usepackage[left=1in,marginparwidth=2.0in,textwidth=4.0in,marginparsep=0.3in]{geometry}
\usepackage{svg}
\setlength{\emergencystretch}{3em} % prevent overfull lines
\setcounter{secnumdepth}{2}
% Make \paragraph and \subparagraph free-standing
\ifx\paragraph\undefined\else
  \let\oldparagraph\paragraph
  \renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
  \let\oldsubparagraph\subparagraph
  \renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi


\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother

\KOMAoption{captions}{tableheading}
\usepackage{mathtools}
\usepackage[normalem]{ulem}
\makeatletter
\@ifpackageloaded{tcolorbox}{}{\usepackage[skins,breakable]{tcolorbox}}
\@ifpackageloaded{fontawesome5}{}{\usepackage{fontawesome5}}
\definecolor{quarto-callout-color}{HTML}{909090}
\definecolor{quarto-callout-note-color}{HTML}{0758E5}
\definecolor{quarto-callout-important-color}{HTML}{CC1914}
\definecolor{quarto-callout-warning-color}{HTML}{EB9113}
\definecolor{quarto-callout-tip-color}{HTML}{00A047}
\definecolor{quarto-callout-caution-color}{HTML}{FC5300}
\definecolor{quarto-callout-color-frame}{HTML}{acacac}
\definecolor{quarto-callout-note-color-frame}{HTML}{4582ec}
\definecolor{quarto-callout-important-color-frame}{HTML}{d9534f}
\definecolor{quarto-callout-warning-color-frame}{HTML}{f0ad4e}
\definecolor{quarto-callout-tip-color-frame}{HTML}{02b875}
\definecolor{quarto-callout-caution-color-frame}{HTML}{fd7e14}
\makeatother
\makeatletter
\makeatother
\makeatletter
\@ifpackageloaded{bookmark}{}{\usepackage{bookmark}}
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\AtBeginDocument{%
\ifdefined\contentsname
  \renewcommand*\contentsname{Table of contents}
\else
  \newcommand\contentsname{Table of contents}
\fi
\ifdefined\listfigurename
  \renewcommand*\listfigurename{List of Figures}
\else
  \newcommand\listfigurename{List of Figures}
\fi
\ifdefined\listtablename
  \renewcommand*\listtablename{List of Tables}
\else
  \newcommand\listtablename{List of Tables}
\fi
\ifdefined\figurename
  \renewcommand*\figurename{Figure}
\else
  \newcommand\figurename{Figure}
\fi
\ifdefined\tablename
  \renewcommand*\tablename{Table}
\else
  \newcommand\tablename{Table}
\fi
}
\@ifpackageloaded{float}{}{\usepackage{float}}
\floatstyle{ruled}
\@ifundefined{c@chapter}{\newfloat{codelisting}{h}{lop}}{\newfloat{codelisting}{h}{lop}[chapter]}
\floatname{codelisting}{Listing}
\newcommand*\listoflistings{\listof{codelisting}{List of Listings}}
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\@ifpackageloaded{subcaption}{}{\usepackage{subcaption}}
\makeatother
\makeatletter
\@ifpackageloaded{tcolorbox}{}{\usepackage[skins,breakable]{tcolorbox}}
\makeatother
\makeatletter
\@ifundefined{shadecolor}{\definecolor{shadecolor}{rgb}{.97, .97, .97}}
\makeatother
\makeatletter
\makeatother
\makeatletter
\@ifpackageloaded{sidenotes}{}{\usepackage{sidenotes}}
\@ifpackageloaded{marginnote}{}{\usepackage{marginnote}}
\makeatother
\makeatletter
\makeatother
\makeatletter
\@ifpackageloaded{fontawesome5}{}{\usepackage{fontawesome5}}
\makeatother
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same} % disable monospaced font for URLs
\hypersetup{
  pdftitle={ADA511:  Data science and data-driven engineering},
  pdfauthor={Steffen Mæland; PierGianLuca Porta Mana},
  colorlinks=true,
  linkcolor={blue},
  filecolor={Maroon},
  citecolor={Blue},
  urlcolor={Blue},
  pdfcreator={LaTeX via pandoc}}

\title{ADA511: Data science and data-driven engineering}
\author{Steffen Mæland \and PierGianLuca Porta Mana}
\date{2023-06-24}

\begin{document}
\maketitle
\ifdefined\Shaded\renewenvironment{Shaded}{\begin{tcolorbox}[frame hidden, enhanced, borderline west={3pt}{0pt}{shadecolor}, boxrule=0pt, breakable, interior hidden, sharp corners]}{\end{tcolorbox}}\fi

\renewcommand*\contentsname{Table of contents}
{
\hypersetup{linkcolor=}
\setcounter{tocdepth}{2}
\tableofcontents
}
\bookmarksetup{startatroot}

\hypertarget{preface}{%
\chapter*{Preface}\label{preface}}
\addcontentsline{toc}{chapter}{Preface}

\markboth{Preface}{Preface}

\hfill\break
\hfill\break
\hfill\break
\hfill\break
\hfill\break
\hfill\break

\emph{Science is built up with facts, as a house is with stones. But a
collection of facts is no more a science than a heap of stones is a
house.} ~~~~{(H. Poincaré)}

**WARNING: THIS IS A WORKING DRAFT. TEXT WILL CHANGE A LOT. MANY
PASSAGES ARE JUST TEMPORARY, INCOHERENT, AND DISJOINTED.

To be written.

\begin{itemize}
\item
  Difference between car mechanic and automotive engineer
\item
  ``Engineering based on data'' is just how engineering and science in
  general have been in the past 400 years or so. Nothing new there.
\item
  The amount of available data has changed. This may lead to a reduction
  -- or in some cases an increase -- in uncertainty, and therefore to
  different solutions.
\item
  Luckily the fundamental theory to deal with large amount of data is
  exactly the same to deal with small amounts. So the foundations
  haven't changed.
\end{itemize}

This course makes you acquainted with the foundations.

\part{An invitation}

\hypertarget{sec-intro}{%
\chapter{Accept or discard?}\label{sec-intro}}

\providecommand{\ul}{\uline}
\renewcommand*{\|}[1][]{\nonscript\:#1\vert\nonscript\:\mathopen{}}
\providecommand*{\pr}[1]{\textsf{\small`#1'}}
\renewcommand*{\pr}[1]{\textsf{\small`#1'}}
\providecommand*{\prq}[1]{\textsf{\small #1}}
\renewcommand*{\prq}[1]{\textsf{\small #1}}
\providecommand{\se}[1]{\mathsfit{#1}}
\renewcommand{\se}[1]{\mathsfit{#1}}
\providecommand{\p}{\mathrm{p}}
\renewcommand{\p}{\mathrm{p}}
\renewcommand{\P}{\mathrm{P}}
\definecolor{quarto-callout-note-color}{HTML}{4477AA}
\definecolor{quarto-callout-note-color-frame}{HTML}{4477AA}
\definecolor{quarto-callout-important-color}{HTML}{AA3377}
\definecolor{quarto-callout-important-color-frame}{HTML}{AA3377}
\definecolor{quarto-callout-warning-color}{HTML}{EE6677}
\definecolor{quarto-callout-warning-color-frame}{HTML}{EE6677}
\definecolor{quarto-callout-tip-color}{HTML}{228833}
\definecolor{quarto-callout-tip-color-frame}{HTML}{228833}
\definecolor{quarto-callout-caution-color}{HTML}{CCBB44}
\definecolor{quarto-callout-caution-color-frame}{HTML}{CCBB44}

Let's start with a question that could arise in a particular engineering
problem:

\begin{quote}
A particular kind of electronic component is produced on an assembly
line. At the end of the line, there is an automated inspection device
that works as follows with every newly produced component coming out of
the line.

The inspection device first makes some tests on the new component. The
tests give an uncertain forecast of whether that component will fail
within its first year of use, or after.

Then the device decides whether the component is accepted and packaged
for sale, or discarded and thrown away.

When a new electronic component is sold, the manufacturer has a net gain
of \(1\$\). If the component fails within a year of use, however, the
manufacturer incur net \emph{loss} of \(11\$\) (12\$ loss, minus the 1\$
gained at first), owing to warranty refunds and damage costs to be paid
to the buyer. When a new electronic component is discarded, the
manufacturer has \(0\$\) net gain.

For a specific new electronic component, just come out of the assembly
line, the tests of the automated inspection device indicate that there
is a \(10\%\) probability that the component will fail within its first
year of use.
\end{quote}

\begin{marginfigure}

{\centering \includegraphics[width=1\textwidth,height=\textheight]{accept_discard.png}

}

\end{marginfigure}

{\textbf{\emph{Should the inspection device accept or discard the new
component?}}}\\

First, try to give and motivate an answer.

This is not the real question of this exercise, however. In fact it
doesn't matter if you don't get the correct answer; not even if you
don't manage to get an answer at all.

\begin{tcolorbox}[enhanced jigsaw, toptitle=1mm, colback=white, opacityback=0, bottomtitle=1mm, breakable, toprule=.15mm, left=2mm, bottomrule=.15mm, coltitle=black, opacitybacktitle=0.6, colbacktitle=quarto-callout-caution-color!10!white, titlerule=0mm, colframe=quarto-callout-caution-color-frame, title={\faIcon{user-edit} Very first exercise!}, arc=.35mm, leftrule=.75mm, rightrule=.15mm]

The purpose here is for you to do some introspection about your own
reasoning. Then examine and discuss these points:

\begin{itemize}
\item
  Which numerical elements in the problem seem to affect the answer?
\item
  Can these numerical elements be clearly separated? How would you
  separate them?
\item
  How would the answer change, if these numerical elements were changed?
  Feel free to change them, also in extreme ways, and see how the answer
  would change.
\item
  Could we solve the problem if we didn't have the probabilities? Why?
\item
  Could we solve the problem if we didn't know the various gains and
  losses? Why?
\item
  Can this problem be somehow abstracted, and then transformed into
  another one with completely different details? For instance, consider
  translating along these lines:

  \begin{itemize}
  \tightlist
  \item
    inspection device → computer pilot of self-driving car
  \item
    tests → camera image
  \item
    fail within a year → pedestrian in front of car
  \item
    accept/discard → keep on going/~break
  \end{itemize}
\end{itemize}

\end{tcolorbox}

\hypertarget{framework}{%
\chapter{Framework}\label{framework}}

\providecommand{\ul}{\uline}
\renewcommand*{\|}[1][]{\nonscript\:#1\vert\nonscript\:\mathopen{}}
\providecommand*{\pr}[1]{\textsf{\small`#1'}}
\renewcommand*{\pr}[1]{\textsf{\small`#1'}}
\providecommand*{\prq}[1]{\textsf{\small #1}}
\renewcommand*{\prq}[1]{\textsf{\small #1}}
\providecommand{\se}[1]{\mathsfit{#1}}
\renewcommand{\se}[1]{\mathsfit{#1}}
\providecommand{\p}{\mathrm{p}}
\renewcommand{\p}{\mathrm{p}}
\renewcommand{\P}{\mathrm{P}}
\definecolor{quarto-callout-note-color}{HTML}{4477AA}
\definecolor{quarto-callout-note-color-frame}{HTML}{4477AA}
\definecolor{quarto-callout-important-color}{HTML}{AA3377}
\definecolor{quarto-callout-important-color-frame}{HTML}{AA3377}
\definecolor{quarto-callout-warning-color}{HTML}{EE6677}
\definecolor{quarto-callout-warning-color-frame}{HTML}{EE6677}
\definecolor{quarto-callout-tip-color}{HTML}{228833}
\definecolor{quarto-callout-tip-color-frame}{HTML}{228833}
\definecolor{quarto-callout-caution-color}{HTML}{CCBB44}
\definecolor{quarto-callout-caution-color-frame}{HTML}{CCBB44}

\hypertarget{what-does-the-intro-problem-tell-us}{%
\section{What does the intro problem tell
us?}\label{what-does-the-intro-problem-tell-us}}

Let's approach the ``accept or discard?'' problem of the previous
chapter~\ref{sec-intro} in an intuitive way.

\marginnote{\begin{footnotesize}

We're jumping the gun here, because we haven't learned the method to
solve this problem yet!

\end{footnotesize}}

First let's say that we \texttt{accept} the component. What happens?

We must try to make sense of that \(10\%\) probability that the
component fails within a year. Different people do this with different
imagination tricks. We can imagine, for instance, that this situation is
repeated 100 times. In 10 of these repetitions the accepted electronic
component is sold and fails within a year after selling. In the
remaining 90 repetitions, the component is sold and works fine for at
least a year.

In each of the 10 imaginary repetitions in which the component fails
early, the manufacturer loses \(11\$\). That's a total loss of
\(10 \cdot 11\$ = 110\$\). In each of the 90 imaginary repetitions in
which the component doesn't fail early, the manufacturer gains \(1\$\).
That's a total gain of \(90\$\). So over all 100 imaginary repetitions
the manufacturer gains \[
10\cdot (-11\$) + 90\cdot 1\$ = {\color[RGB]{238,102,119} -20\$} \ ,
\] that is, the manufacturer has not gained, but \emph{lost} \(20\$\)\,!
That's an average of \(0.2\$\) \emph{lost} per repetition.

Now let's say that we \texttt{discard} the component instead. What
happens? In this case we don't need to invoke imaginary repetitions, but
even if we do, it's clear that the manufacturer doesn't gain or lose
anything -- that is, the ``gain'' is \(0\$\) -- in each and all of the
repetitions.

The conclusion is that if in a situation like this we {accept} the
component, then we'll {lose \(0.2\$\)} on average; whereas if we
{discard} it, then on average we won't {lose anything or gain anything}.

Obviously the best, or ``least worst'', decision to make is to
\textbf{discard} the component.

\begin{tcolorbox}[enhanced jigsaw, toptitle=1mm, colback=white, opacityback=0, bottomtitle=1mm, breakable, toprule=.15mm, left=2mm, bottomrule=.15mm, coltitle=black, opacitybacktitle=0.6, colbacktitle=quarto-callout-caution-color!10!white, titlerule=0mm, colframe=quarto-callout-caution-color-frame, title={\faIcon{user-edit} Exercises}, arc=.35mm, leftrule=.75mm, rightrule=.15mm]

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Now that we have an idea of the general reasoning, check what happens
  with different values of the probability of failure and of the failure
  cost: is it still best to discard? For instance, try with

  \begin{itemize}
  \tightlist
  \item
    failure probability \texttt{10\%} and failure cost \texttt{5\$};
  \item
    failure probability \texttt{5\%} and failure cost \texttt{11\$};
  \item
    failure probability \texttt{10\%}, failure cost \texttt{11\$},
    non-failure gain \texttt{2\$}.
  \end{itemize}

  Feel free to get wild and do plots.
\item
  Identify the failure probability at which accepting the component
  doesn't lead to any loss or any gain, so it doesn't matter whether we
  discard or accept. (You can solve this as you prefer: analytically
  with an equation, visually with a plot, by trial\,\&\,error on several
  cases, or whatnot.)
\item
  Consider the special case with failure probability \texttt{0\%} and
  failure cost \texttt{10\$}. This means no new component will ever
  fail. To decide in such a case we do not need imaginary repetitions;
  but \textbf{confirm} that we arrive at the same logical conclusion
  whether we reason through imaginary repetitions or not.
\item
  Consider this completely different problem:

  \begin{quote}
  A patient is examined by a brand-new medical diagnostics AI system.

  The AI first performs some clinical tests on the patient. The tests
  give an uncertain forecast of whether the patient has a particular
  disease or not.

  Then the AI decides whether the patient should be dismissed without
  treatment, or treated with a particular medicine.

  If the patient is dismissed, then the life expectancy doesn't increase
  or decrease if the disease is not present, but it decreases by
  10~years if the disease is actually present. If the patient is
  treated, then the life expectancy decreases by 1~year if the disease
  is not present (owing to treatment side-effects), but also if the
  disease is present (because it cures the disease, so the life
  expectancy doesn't decrease by 10 years; but it still decreases by 1
  year owing to the side effects).

  For this patient, the clinical tests indicate that there is a \(10\%\)
  probability that the patient has the disease.
  \end{quote}

  Should the diagnostic AI dismiss or treat the patient? Find
  differences and similarities, even numerical, with the assembly-line
  problem.
\end{enumerate}

\end{tcolorbox}

\hfill\break

From the solution of the problem and from the exploring exercises, we
gather some instructive points:

\begin{itemize}
\item
  Is it enough if we simply know that the component is less likely to
  fail than not? in other words, if we simply know that the probability
  of failure is less than \(50\%\)?

  Obviously not. We found that if the failure probability is \(10\%\)
  then it's best to discard; but if it's \(5\%\) then it's best to
  accept. In both cases the component was less likely to fail than not,
  but the decisions were different. Moreover, we found that the
  probability affected the loss if one made the non-optimal decision.
  Therefore:

  {\textbf{Knowledge of exact probabilities is absolutely necessary for
  making the best decision}}
\item
  Is it enough if we simply know that failure leads to a cost? that is,
  that its gain is less than the gain for non-failure?

  Obviously not. The situation is similar to that with the probability.
  In the exercise we found that if the failure cost is \(11\$\) then
  it's best to discard; but if it's \(5\$\) then it's best to accept.
  It's also best to accept if the failure cost is \(11\$\) but the
  non-failure gain is \(2\$\). Therefore:

  {\textbf{Knowledge of the exact gains and losses is absolutely
  necessary for making the best decision}}
\item
  Is this kind of decision situation only relevant to assembly lines and
  sales?

  By all means not. We found a clinical situation that's exactly
  analogous: there's uncertainty, there are gains and losses (of time
  rather than money), and the best decision depends on both.
\end{itemize}

\hypertarget{our-focus-decision-making-inference-and-data-science}{%
\section{Our focus: decision-making, inference, and data
science}\label{our-focus-decision-making-inference-and-data-science}}

Every data-driven engineering project is unique, with its unique
difficulties and problems. But there are also problems common to all
engineering projects.

In the scenarios we explored above, we found an extremely important
problem-pattern. There is a decision or choice to make (and ``not
deciding'' is not an option -- or it's just another kind choice). Making
a particular decision will lead to some consequences, some leading to a
desired goal, others leading to something undesirable. The decision is
difficult because its consequences are not known with certainty, given
the information and data available in the problem. We may lack
information and data about past or present details, about future events
and responses, and so on. This is what we call a problem of
{\textbf{decision-making under uncertainty}} or \textbf{under
risk}\footnote{We'll avoid the word ``risk'' because it has several
  different technical meanings in the literature, some even
  contradictory.}, or simply a ``decision problem'' for short.

This problem-pattern appears literally everywhere. But our explored
scenarios also suggest that this problem-pattern has a sort of
systematic solution method.

In this course we're going to focus on decision problems and their
systematic solution method. We'll learn a framework and some abstract
notions that allow us to frame and analyse this kind of problem, and
we'll learn a universal set of principles to solve it. This set of
principles goes under the name of {\textbf{Decision Theory}}.

But what do decision-making under uncertainty and Decision Theory have
to do with \emph{data} and \emph{data science}? The three are profoundly
and tightly related on many different planes:

\marginnote{\begin{footnotesize}

\begin{tcolorbox}[enhanced jigsaw, toptitle=1mm, colback=white, opacityback=0, bottomtitle=1mm, breakable, toprule=.15mm, left=2mm, bottomrule=.15mm, coltitle=black, opacitybacktitle=0.6, colbacktitle=quarto-callout-tip-color!10!white, titlerule=0mm, colframe=quarto-callout-tip-color-frame, title={\faIcon{rocket} For the extra curious}, arc=.35mm, leftrule=.75mm, rightrule=.15mm]

\href{https://hvl.instructure.com/courses/25074/modules/items/665981}{\emph{Decision
theory in expert systems and artificial intelligence}}

\end{tcolorbox}

\end{footnotesize}}

\begin{itemize}
\item
  We saw that \emph{probability} values are essential in a decision
  problem. How do we find them? As you can imagine, \emph{data} play an
  important part in their calculation. In our intro example, the failure
  probability must come from observations or experiments on similar
  electronic components.
\item
  We saw that also the values of \emph{gains and losses} are essential.
  \emph{Data} play an important part in their calculation as well.
\item
  \emph{Data science} is based on the laws of \emph{Decision Theory}.
  Here's an analogy: a rocket engineer relies on fundamental physical
  laws (balance of momentum, energy, and so on) for making a rocket
  work. Failure to account for those laws leads at best to sub-optimal
  solutions, at worst to disasters. As we shall see, the same is true
  for a data scientist and the rules of decision theory.
\item
  \emph{Machine-learning} algorithms, in particular, are realizations or
  approximations of the rules of \emph{Decision Theory}. This is clear,
  for instance, considering that the main task of a machine-learning
  classifier is to decide among possible output labels or classes.
\item
  The rules of \emph{Decision Theory} are also the foundations upon
  which \emph{artificial-intelligence} agents, which must make optimal
  inferences and decisions, are built.
\end{itemize}

These five planes will constitute the major parts of the present course.

\hfill\break

@@ TODO add examples: algorithm giving outputs is a decision agent. @@
Include one with \url{https://hjerterisiko.helsedirektoratet.no}

There are other important aspects in engineering problems, besides the
one of making decisions under uncertainty. For instance the
\emph{discovery} or the \emph{invention} of new technologies and
solutions. These aspects can barely be planned or decided; but their
fruits, once available, should be handled and used optimally -- thus
leading to a decision problem.

Artificial intelligence is proving to be a valuable aid in these more
creative aspects too. This kind of use of AI is outside the scope of the
present notes. Some aspects of this creativity-assisting use, however,
do fall within the domain of the present notes. A pattern-searching
algorithm, for example, can be optimized by means of the method we are
going to study.

\hypertarget{our-goal-optimality-not-success}{%
\section{Our goal: optimality, not
``success''}\label{our-goal-optimality-not-success}}

What should we demand from a systematic method for solving decision
problems?

By definition, in a decision problem under uncertainty there is
generally no method to \emph{determine} the decision that surely leads
to the desired consequence -- if such a method existed, then the problem
would not have any uncertainty! Therefore, if there is a method to deal
with decision problems, its goal cannot be the determination of the
\emph{successful} decision. This also means that a priori we cannot
blame an engineer for making an unsuccessful decision in a situation of
uncertainty.

Imagine two persons, Henry and Tina, who must bet on ``heads'' or
``tails'' under the following conditions (but who otherwise don't get
any special thrill from betting):

\begin{itemize}
\tightlist
\item
  If the bet is ``heads'' and the coin lands ``heads'', the person wins
  a \emph{small} amount of money; but if it lands ``tails'', they lose a
  \emph{large} amount of money.
\item
  If the bet is ``tails'' and the coin lands ``tails'', the person
  \emph{wins} a small amount of money; if it lands ``heads'', they lose
  the same \emph{small} amount of money.
\end{itemize}

Henry chooses the first bet, on ``heads''. Tina chooses the second bet,
on ``tails''. The coin comes down ``heads''. So Henry wins the small
amount of money, while Tina loses the same small amount. What would we
say about their decisions?

Henry's decision was lucky, and yet \emph{irrational}: he risked losing
much more money than in the second bet, without any possibility of at
least winning more. Tina's decision was unlucky, and yet
\emph{rational}: the possibility and amount of winning was the same in
the two bets, and she chose the bet with the least amount of loss. We
expect that any person making Henry's decision in similar, future bets
will eventually lose more money than any person making Tina's decision.

This example shows two points. First, ``success'' is generally not a
good criterion to judge a decision under uncertainty; success can be the
pure outcome of luck, not of smarts. Second, even if there is no method
to determine which decision is successful, there is a method to
determine which decision is rational or {\textbf{optimal}}, given the
particular gains, losses, and uncertainties involved in the decision
problem. We had a glimpse of this method in our introductory scenarios.

Let us emphasize, however, that we are not giving up on ``success'', or
trading it for ``optimality''. Indeed we'll find that {\textbf{Decision
Theory automatically leads to the \emph{successful} decision}} in
problems where uncertainty is not present or is irrelevant. It's a
win-win. It's important to keep this point in mind:

\begin{figure*}

\begin{tcolorbox}[enhanced jigsaw, toptitle=1mm, colback=white, opacityback=0, bottomtitle=1mm, breakable, toprule=.15mm, left=2mm, bottomrule=.15mm, coltitle=black, opacitybacktitle=0.6, colbacktitle=quarto-callout-note-color!10!white, titlerule=0mm, colframe=quarto-callout-note-color-frame, title={}, arc=.35mm, leftrule=.75mm, rightrule=.15mm]

{Aiming to find the solutions that are \emph{successful} can make us
\emph{fail} to find those that are optimal when the successful ones
cannot be determined.}

{Aiming to find the solutions that are \emph{optimal} makes us
automatically find those that are \emph{successful} when those can be
determined.}

\end{tcolorbox}

\end{figure*}

We shall later witness this fact with our own eyes, and will take it up
again in the discussion of some misleading techniques to evaluate
machine-learning algorithms.

\hypertarget{decision-theory}{%
\section{Decision Theory}\label{decision-theory}}

So far we have mentioned that Decision Theory has the following
features:

\begin{itemize}
\item
  {\faIcon{check} it tells us what's optimal and, when possible, what's
  successful}
\item
  {\faIcon{check} it takes into consideration decisions, consequences,
  costs and gains}
\item
  {\faIcon{check} it is able to deal with uncertainties}
\end{itemize}

What other kinds of features should we demand from it, in order to be
applied to as many kinds of decision problems as possible, and to be
relevant for data science?

If we find an optimal decision in regards to some outcome, it may still
happen that the decision can be realized in several ways that are
equivalent in regard to the outcome, but inequivalent in regard to time
or resources. In the assembly-line scenario, for example, the decision
\texttt{discard} could be carried out by burning, recycling, and so on.
We thus face a decision within a decision. In general, a decision
problem may involve several decision sub-problems, in turn involving
decision sub-sub-problems, and so on.

In data science, a common engineering goal is to design and build an
automated or AI-based device capable of making an optimal decision in a
specific kind of uncertain situations. Think for instance of an
aeronautic engineer designing an autopilot system, or a software company
designing an image classifier.

Decision Theory turns out to meet these demands too, thanks to the
following features:

\begin{itemize}
\item
  {\faIcon{check} it is susceptible to recursive, sequential, and
  modular application}
\item
  {\faIcon{check} it can be used not only for human decision-makers, but
  also for automated or AI devices}
\end{itemize}

\hfill\break

Decision Theory has a long history, going back to Leibniz in the 1600s
and partly even to Aristotle in the −300s, and appearing in its present
form around 1920--1960. What's remarkable about it is that it is not
only \emph{a} framework, but \emph{the} framework we must use. A
logico-mathematical theorem shows that {\textbf{any framework that does
not break basic optimality and rationality criteria has to be equivalent
to Decision Theory}}. In other words, any ``alternative'' framework may
use different technical terminology and rewrite mathematical operations
in a different way, but it boils down to the same notions and operations
of Decision Theory. So if you wanted to invent and use another
framework, then either (a) it would lead to some irrational or illogical
consequences, or (b) it would lead to results identical to Decision
Theory's. Many frameworks that you are probably familiar with, such as
optimization theory or Boolean logic, are just specific applications or
particular cases of Decision Theory.

Thus we list one more important characteristic of Decision Theory:

\begin{itemize}
\tightlist
\item
  {\faIcon{check} it is {\textbf{normative}}}
\end{itemize}

\marginnote{\begin{footnotesize}

\begin{tcolorbox}[enhanced jigsaw, toptitle=1mm, colback=white, opacityback=0, bottomtitle=1mm, breakable, toprule=.15mm, left=2mm, bottomrule=.15mm, coltitle=black, opacitybacktitle=0.6, colbacktitle=quarto-callout-tip-color!10!white, titlerule=0mm, colframe=quarto-callout-tip-color-frame, title={\faIcon{rocket} For the extra curious}, arc=.35mm, leftrule=.75mm, rightrule=.15mm]

\begin{itemize}
\tightlist
\item
  \href{https://hvl.instructure.com/courses/25074/modules/items/665858}{\emph{Judgment
  under uncertainty}}
\item
  \href{https://hvl.instructure.com/courses/25074/modules/items/665859}{\emph{Heuristics
  and Biases}}
\item
  \href{https://hvl.instructure.com/courses/25074/modules/items/665860}{\emph{Thinking,
  Fast and Slow}}
\end{itemize}

\end{tcolorbox}

\end{footnotesize}}

\emph{Normative} contrasts with \emph{descriptive}. The purpose of
Decision Theory is not to describe, for example, how human
decision-makers typically make decisions. Because human decision-makers
typically make irrational, sub-optimal, or biased decisions. That's
exactly what we want to avoid and improve!

\hypertarget{basic-decision-problems}{%
\chapter{Basic decision problems}\label{basic-decision-problems}}

\providecommand{\ul}{\uline}
\renewcommand*{\|}[1][]{\nonscript\:#1\vert\nonscript\:\mathopen{}}
\providecommand*{\pr}[1]{\textsf{\small`#1'}}
\renewcommand*{\pr}[1]{\textsf{\small`#1'}}
\providecommand*{\prq}[1]{\textsf{\small #1}}
\renewcommand*{\prq}[1]{\textsf{\small #1}}
\providecommand{\se}[1]{\mathsfit{#1}}
\renewcommand{\se}[1]{\mathsfit{#1}}
\providecommand{\p}{\mathrm{p}}
\renewcommand{\p}{\mathrm{p}}
\renewcommand{\P}{\mathrm{P}}
\definecolor{quarto-callout-note-color}{HTML}{4477AA}
\definecolor{quarto-callout-note-color-frame}{HTML}{4477AA}
\definecolor{quarto-callout-important-color}{HTML}{AA3377}
\definecolor{quarto-callout-important-color-frame}{HTML}{AA3377}
\definecolor{quarto-callout-warning-color}{HTML}{EE6677}
\definecolor{quarto-callout-warning-color-frame}{HTML}{EE6677}
\definecolor{quarto-callout-tip-color}{HTML}{228833}
\definecolor{quarto-callout-tip-color-frame}{HTML}{228833}
\definecolor{quarto-callout-caution-color}{HTML}{CCBB44}
\definecolor{quarto-callout-caution-color-frame}{HTML}{CCBB44}

Decision Theory analyses any decision-making problem in terms of nested
or sequential \emph{basic} or \emph{minimal} decision problems. The
assembly-line scenario of the introduction~\ref{sec-intro} is an
example.

\hypertarget{graphical-representation-and-elements}{%
\section{Graphical representation and
elements}\label{graphical-representation-and-elements}}

A basic decision problem can be represented by a diagram like this:

\includegraphics[width=1\textwidth,height=\textheight]{index_files/mediabag/basic_decision_tree.pdf}

It has one \emph{decision node}, usually represented by a square
\faIcon{square}, from which the available decisions depart as lines.
Each decision leads to an \emph{uncertainty node}, usually represented
by a circle \faIcon{circle}, from which the possible outcomes depart as
lines. Each outcome leads to a particular utility value. The uncertainty
of each outcome is quantified by a probability.

A basic decision problem is analysed in terms of these elements:

\begin{itemize}
\tightlist
\item
  {\faIcon{cube} \textbf{Agent}}, and {\textbf{background}} or
  {\textbf{prior information}}. The agent is the person or device that
  has to make the decision. An agent always possess (or has been
  programmed with) specific background information that is used and
  taken for granted in the decision-making process. This background
  information determines the probabilities and utilities of the
  outcomes, together with other available data and information. Since
  different agents typically have different background information, we
  shall somehow conflate agents and prior information.
\end{itemize}

\marginnote{\begin{footnotesize}

We'll use the neutral pronouns \emph{it}/\emph{its} when referring to an
agent, since an agent could be a person or a machine.

\end{footnotesize}}

\begin{itemize}
\item
  {\faIcon{cube} \textbf{Decisions}}, also called \textbf{courses of
  actions}, available to the agent. They are assumed to be mutually
  exclusive and exhaustive; this can always be achieved by recombining
  them if necessary, as we'll discuss later.
\item
  {\faIcon{cube} \textbf{Outcomes}} of the possible decisions. Every
  decision can have a different set of outcomes, or some outcomes can
  appear for several or all decisions (in this case they are reported
  multiple times in the decision diagram). Note that even if an outcome
  can happen for two or more different decisions, its probabilities can
  still be different depending on the decision.
\item
  {\faIcon{cube} \textbf{Probabilities}} for each of the outcomes. Their
  values typically depend on the background information, the decision,
  and the additional data.
\item
  {\faIcon{cube} \textbf{Utilities}}: the gains or losses associated
  with each of the possible outcomes. Their values also depend on the
  background information, the decision, and the additional data.
\item
  {\faIcon{cube} \textbf{Data}} and other {\textbf{additional
  information}}, sometimes called {\textbf{evidence}}. They differ from
  the background information in that they can change with every decision
  instance made by the same agent, while the background information
  stays the same. In the assembly-line scenario, for example, the test
  results could be different for every new electric component.
\end{itemize}

\marginnote{\begin{footnotesize}

\begin{tcolorbox}[enhanced jigsaw, toptitle=1mm, colback=white, opacityback=0, bottomtitle=1mm, breakable, toprule=.15mm, left=2mm, bottomrule=.15mm, coltitle=black, opacitybacktitle=0.6, colbacktitle=quarto-callout-tip-color!10!white, titlerule=0mm, colframe=quarto-callout-tip-color-frame, title={}, arc=.35mm, leftrule=.75mm, rightrule=.15mm]

\faIcon{seedling} Remember: What matters is to be able to identify these
elements in a concrete problem, understanding their role. Their
technical names don't matter.

\end{tcolorbox}

\end{footnotesize}}

Note that it is not always the case that the \emph{outcomes} are unknown
and the \emph{data} are known. As we'll discuss later, in some
situations we reason in hypothetical or counterfactual ways, using
hypothetical data and considering outcomes which have already occurred.

\begin{tcolorbox}[enhanced jigsaw, toptitle=1mm, colback=white, opacityback=0, bottomtitle=1mm, breakable, toprule=.15mm, left=2mm, bottomrule=.15mm, coltitle=black, opacitybacktitle=0.6, colbacktitle=quarto-callout-caution-color!10!white, titlerule=0mm, colframe=quarto-callout-caution-color-frame, title={\faIcon{book} Reading}, arc=.35mm, leftrule=.75mm, rightrule=.15mm]

§\,1.1.4 in
\href{https://hvl.instructure.com/courses/25074/modules/items/660089}{\emph{Artificial
Intelligence}}

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, toptitle=1mm, colback=white, opacityback=0, bottomtitle=1mm, breakable, toprule=.15mm, left=2mm, bottomrule=.15mm, coltitle=black, opacitybacktitle=0.6, colbacktitle=quarto-callout-caution-color!10!white, titlerule=0mm, colframe=quarto-callout-caution-color-frame, title={\faIcon{user-edit} Exercise}, arc=.35mm, leftrule=.75mm, rightrule=.15mm]

\begin{itemize}
\tightlist
\item
  Identify the elements above in the assembly-line decision problem of
  the introduction~\ref{sec-intro}.
\item
  Sketch the diagram of the assembly-line decision problem.
\end{itemize}

\end{tcolorbox}

Some of the decision-problem elements listed above may need to be in
turn analysed by a decision sub-problem. For instance, the utilities
could depend on uncertain factors: thus we have a decision sub-problem
to determine the optimal values to be used for the utilities of the main
problem. This is an example of the modular character of decision theory.

We shall soon see how to mathematically represent these elements.

The elements above must be identified unambiguously in every decision
problem. The analysis into these elements greatly helps in making the
problem and its solution well-defined.

An advantage of decision theory is that its application \emph{forces} us
to make sense of an engineering problem. A useful procedure is to
formulate the general problem in terms of the elements above,
identifying them clearly. If the definition of any of the terms involves
uncertainty of further decisions, then we analyse it in turn as a
decision sub-problem, and so on.

\begin{quote}
Suppose someone (probably a politician) says: ``We must solve the energy
crisis by reducing energy consumption or producing more energy''. From a
decision-making point of view, this person has effectively said
\emph{nothing whatsoever}. By definition the ``energy crisis'' is the
problem that energy production doesn't meet demand. So this person has
only said ``we would like the problem to be solved'', without specifying
any solution. A decision-theory approach to this problem requires us to
specify which concrete courses of action should be taken for reducing
consumption or increasing productions, and what their probable outcomes,
costs, and gains would be.
\end{quote}

\marginnote{\begin{footnotesize}

\begin{tcolorbox}[enhanced jigsaw, toptitle=1mm, colback=white, opacityback=0, bottomtitle=1mm, breakable, toprule=.15mm, left=2mm, bottomrule=.15mm, coltitle=black, opacitybacktitle=0.6, colbacktitle=quarto-callout-tip-color!10!white, titlerule=0mm, colframe=quarto-callout-tip-color-frame, title={\faIcon{rocket} For the extra curious}, arc=.35mm, leftrule=.75mm, rightrule=.15mm]

See MacKay's options-vs-costs rational analysis in
\href{https://www.withouthotair.com}{Sustainable Energy -- without the
hot air}

\end{tcolorbox}

\end{footnotesize}}

\hypertarget{inference-utility-maximization}{%
\section{Inference, utility,
maximization}\label{inference-utility-maximization}}

The solution of a basic decision-making problem can be roughly divided
into three main stages: inference, utility assessment, and
expected-utility maximization.

{\faIcon{cube} \textbf{Inference}} is the stage where the probabilities
of the possible outcomes are calculated. Its rules are given by the
{\textbf{Probability Calculus}}. Inference is independent from decision:
in some situations we may simply wish to assess whether some hypotheses,
conjectures, or outcomes are more or less plausible than others, without
making any decision. This kind of assessment can be very important in
problems of communication and storage, and it is specially considered by
{\textbf{Information Theory}}.

The calculation of probabilities can be the part that demands most
thinking, time, and computational resources in a decision problem. It is
also the part that typically makes most use of data -- and where data
can be most easily misused.

Roughly half of this course will be devoted in understanding the laws of
inference, their applications, uses, and misuses.\\

{\faIcon{cube} \textbf{Utility assesment}} is the stage where the gains
or losses of the possible outcomes are calculated. Often this stage
requires further inferences and further decision-making sub-problems.
The theory underlying utility assessment is still much underdeveloped,
compared to probability theory.\\

{\faIcon{cube} \textbf{Expected-utility maximization}} is the final
stage where the probabilities and gains or costs of the possible
outcomes are combined, in order to determine the optimal decision.

\part{Inference}

\hypertarget{what-is-an-inference}{%
\chapter{What is an inference?}\label{what-is-an-inference}}

\providecommand{\ul}{\uline}
\renewcommand*{\|}[1][]{\nonscript\:#1\vert\nonscript\:\mathopen{}}
\providecommand*{\pr}[1]{\textsf{\small`#1'}}
\renewcommand*{\pr}[1]{\textsf{\small`#1'}}
\providecommand*{\prq}[1]{\textsf{\small #1}}
\renewcommand*{\prq}[1]{\textsf{\small #1}}
\providecommand{\se}[1]{\mathsfit{#1}}
\renewcommand{\se}[1]{\mathsfit{#1}}
\providecommand{\p}{\mathrm{p}}
\renewcommand{\p}{\mathrm{p}}
\renewcommand{\P}{\mathrm{P}}
\definecolor{quarto-callout-note-color}{HTML}{4477AA}
\definecolor{quarto-callout-note-color-frame}{HTML}{4477AA}
\definecolor{quarto-callout-important-color}{HTML}{AA3377}
\definecolor{quarto-callout-important-color-frame}{HTML}{AA3377}
\definecolor{quarto-callout-warning-color}{HTML}{EE6677}
\definecolor{quarto-callout-warning-color-frame}{HTML}{EE6677}
\definecolor{quarto-callout-tip-color}{HTML}{228833}
\definecolor{quarto-callout-tip-color-frame}{HTML}{228833}
\definecolor{quarto-callout-caution-color}{HTML}{CCBB44}
\definecolor{quarto-callout-caution-color-frame}{HTML}{CCBB44}

In the assembly-line decision problem of §~\ref{sec-intro}, the
probability of early failure (and that of late failure), in view of the
test results, was very important in determining the optimal decision. If
the probability had been \(5\%\) instead of \(10\%\), the optimal
decision would have been different. In that scenario the probabilities
of the outcomes in view of the test results were already given. In real
decision problems, however, probabilities almost always need to be
calculated, and their calculation can be the most time- and
resource-demanding step in solving a decision problem.

We'll loosely refer to problems of calculating probabilities as
``\emph{inference} problems'', and to their calculation as ``drawing an
inference''. Drawing inferences is very often a goal or need in itself,
with no underlying decision process.

\hypertarget{sec-inference-scenarios}{%
\section{The wide scope and characteristics of
inferences}\label{sec-inference-scenarios}}

Let's see a couple more informal examples of inference problems. For
some of them an underlying decision problem is also alluded to:

\begin{enumerate}
\def\labelenumi{\Alph{enumi}.}
\item
  Looking at the weather we try to assess if it'll rain today, to decide
  whether to take an umbrella.
\item
  Considering a patient's symptoms, test results, and medical history, a
  clinician tries to assess which disease affects a patient, so as to
  decide on the optimal treatment.
\item
  Looking at the present game position
  \includegraphics[width=0.1\textwidth,height=\textheight]{XsOs.png} the
  X-player, which moves next, wonders whether placing the next
  {\textbf{X}} on the mid-right position leads to a win.
\item
  From the current set of camera frames, the computer of a self-driving
  car needs to assess whether a particular patch of colours in the
  frames is a person, so as to slow down the car and stop.
\item
  Given that {\(G=6.67 \cdot 10^{-11}\,\mathrm{m^3\,s^{-2}\,kg^{-1}}\),}
  \(M = 5.97 \cdot 10^{24}\,\mathrm{kg}\) (mass of the Earth), and
  \(r = 6.37 \cdot 10^{6}\,\mathrm{m}\) (radius of the Earth),
  \href{http://nasaphysics.cet.edu/escape-velocity.html}{a rocket
  engineer needs to know} how much is {\(\sqrt{2\,G\,M/r\,}\).}
\item
  We'd like to know whether the rolled die is going to show
  \faIcon{dice-six}.
\item
  An
  \href{https://aerospaceamerica.aiaa.org/features/a-i-in-the-cockpit}{aircraft's
  autopilot system} needs to assess how much the aircraft's
  \href{https://www.grc.nasa.gov/www/k-12/VirtualAero/BottleRocket/airplane/roll.html}{roll}
  will change if the right wing's
  \href{https://www.grc.nasa.gov/www/k-12/VirtualAero/BottleRocket/airplane/incline.html}{angle
  of attack} is increased by \(0.1\,\mathrm{rad}\).
\item
  By looking at the dimensions, shape, texture of a newly dug-out fossil
  bone, an archaeologist wonders whether it belonged to a Tyrannosaurus
  rex.
\item
  A voltage test on a newly produced electronic component yields a
  reading of \(100\,\mathrm{mV}\). The electronic component turns out to
  be defective. An engineer wants to assess whether the voltage-test
  reading could have been \(100\,\mathrm{mV}\), if the component had not
  been defective.
\item
  Same as above, but the engineer wants to assess whether the
  voltage-test reading could have been \(80\,\mathrm{mV}\), if the
  component had not been defective.
\end{enumerate}

\hfill\break

\begin{enumerate}
\def\labelenumi{\Alph{enumi}.}
\setcounter{enumi}{10}
\tightlist
\item
  From measurements of the Sun's energy output and of concentrations of
  various substances in the Earth's atmosphere over the past 500\,000
  years, and of the emission rates of various substances in the years
  1900--2022, climatologists and geophysicists try to assess the rate of
  mean-temperature increase in the years 2023--2100.
\end{enumerate}

\marginnote{\begin{footnotesize}

\begin{tcolorbox}[enhanced jigsaw, toptitle=1mm, colback=white, opacityback=0, bottomtitle=1mm, breakable, toprule=.15mm, left=2mm, bottomrule=.15mm, coltitle=black, opacitybacktitle=0.6, colbacktitle=quarto-callout-tip-color!10!white, titlerule=0mm, colframe=quarto-callout-tip-color-frame, title={\faIcon{rocket} For the extra curious}, arc=.35mm, leftrule=.75mm, rightrule=.15mm]

Ch.\,10 in
\href{https://hvl.instructure.com/courses/25074/modules/items/668578}{\emph{A
Survival Guide to the Misinformation Age}}.

\end{tcolorbox}

\end{footnotesize}}

\hfill\break

\begin{tcolorbox}[enhanced jigsaw, toptitle=1mm, colback=white, opacityback=0, bottomtitle=1mm, breakable, toprule=.15mm, left=2mm, bottomrule=.15mm, coltitle=black, opacitybacktitle=0.6, colbacktitle=quarto-callout-caution-color!10!white, titlerule=0mm, colframe=quarto-callout-caution-color-frame, title={\faIcon{user-edit} Exercises}, arc=.35mm, leftrule=.75mm, rightrule=.15mm]

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{4}
\item
  For each example above, pinpoint what has to be inferred, and also the
  \emph{agent} interested in the inference.
\item
  Point out which of the examples above \emph{explicitly} give data or
  information that should be used for the inference.
\item
  For the examples that do not give explicit data or information,
  speculate what information could be implicitly assumed. For those that
  do give explicit data, speculate which other additional information
  could be implicitly assumed.
\item
  Can any of the inferences above be done perfectly, that is, without
  any uncertainty, based the data given explicitly or implicitly?
\item
  Find the examples that explicitly involve a decision. In which of them
  does the decision affect the results of the inference? In which it
  does not?
\item
  Are any of the inferences ``\emph{one-time only}'' -- that is, their
  object or the data on which they are based have never happened before
  and will never happen again?
\item
  Are any of the inferences based on data and information that come
  chronologically \emph{after} the object of the inference?
\item
  Are any of the inferences about something that is actually already
  known to the agent that's making the inference?
\item
  Are any of the inferences about something that actually did not
  happen?
\item
  Do any of the inferences use ``data'' or ``information'' that are
  actually known (within the scenario itself) to be fictive, that is,
  \emph{not} real?
\end{enumerate}

\end{tcolorbox}

From the examples and from your answers to the exercise we observe some
very important characteristics of inferences:

\begin{itemize}
\item
  Some inferences can be made exactly, that is, {\emph{without
  uncertainty}}: it is possible to say whether the object of the
  inference is true or false. Other inferences, instead, involve an
  uncertainty.
\item
  {\emph{All inferences are based on some data and information}}, which
  may be explicitly expressed or only implicitly understood.
\item
  An inference can be about something \emph{past}, but based on
  \emph{present or future} data and information: inferences can show
  {\emph{all sorts of temporal relations}}.
\item
  An inference can be {\emph{essentially unrepeatable}}, because it's
  about something unrepeatable or based on unrepeatable data and
  information.
\item
  The data and information on which an inference is based can actually
  be unknown; that is, they can be only momentarily contemplated as
  real. Such an inference is said to be based on {\textbf{hypothetical
  reasoning}}.
\item
  The object of an inference can actually be something already known to
  be false or not real: the inference tries to assess it in the case
  that some data or information had been different. Such an inference is
  said to be based on {\textbf{counterfactual reasoning}}.
\end{itemize}

\hypertarget{basic-elements-of-an-inference}{%
\section{Basic elements of an
inference}\label{basic-elements-of-an-inference}}

Let us already introduce the basic mathematical notation for inferences.
We have seen that every inference has an ``object'' (what is to be
assessed) and data and information on which it is based. We call
{\textbf{proposal}}\footnote{Johnson's (1924) terminology. Keynes (1921)
  uses ``conclusion''. Modern textbooks do not seem to use any
  specialized term.} the object of the inference, and
{\textbf{conditional}}\footnote{Modern terminology. Other terms used:
  ``evidence'', ``premise'', ``supposal''.} what the inference is based
upon. We separate them with a vertical
bar\footnote{Originally a
  \href{https://dictionary.cambridge.org/dictionary/english/solidus}{solidus},
  introduced by Keynes (1921).}~~{``\(\pmb{\nonscript\:\big\vert\nonscript\:\mathopen{}}\)'',}~~which
can be pronounced \emph{given} or \emph{conditional on}: \[
\textit{[proposal]}\ \pmb{\nonscript\:\Big\vert\nonscript\:\mathopen{}}\ 
\textit{[conditional]}
\]

\marginnote{\begin{footnotesize}

Again: \emph{terminology doesn't matter} (although it's useful). What
matters is that we understand the properties and uses of these notions.

\end{footnotesize}}

\hfill\break

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

There are now two important tasks ahead of us. First, we want to
introduce a flexible and enough general mathematical representation for
the objects and the bases of an inference. Second, we want to know what
are the rules for making correct inferences.

\hypertarget{sentences}{%
\chapter{Sentences}\label{sentences}}

\providecommand{\ul}{\uline}
\renewcommand*{\|}[1][]{\nonscript\:#1\vert\nonscript\:\mathopen{}}
\providecommand*{\pr}[1]{\textsf{\small`#1'}}
\renewcommand*{\pr}[1]{\textsf{\small`#1'}}
\providecommand*{\prq}[1]{\textsf{\small #1}}
\renewcommand*{\prq}[1]{\textsf{\small #1}}
\providecommand{\se}[1]{\mathsfit{#1}}
\renewcommand{\se}[1]{\mathsfit{#1}}
\providecommand{\p}{\mathrm{p}}
\renewcommand{\p}{\mathrm{p}}
\renewcommand{\P}{\mathrm{P}}
\definecolor{quarto-callout-note-color}{HTML}{4477AA}
\definecolor{quarto-callout-note-color-frame}{HTML}{4477AA}
\definecolor{quarto-callout-important-color}{HTML}{AA3377}
\definecolor{quarto-callout-important-color-frame}{HTML}{AA3377}
\definecolor{quarto-callout-warning-color}{HTML}{EE6677}
\definecolor{quarto-callout-warning-color-frame}{HTML}{EE6677}
\definecolor{quarto-callout-tip-color}{HTML}{228833}
\definecolor{quarto-callout-tip-color-frame}{HTML}{228833}
\definecolor{quarto-callout-caution-color}{HTML}{CCBB44}
\definecolor{quarto-callout-caution-color-frame}{HTML}{CCBB44}

We have seen that an inference involves at the very least two things:
the object of the inference (\emph{proposal}), and the data,
information, or hypotheses on which the inference is based
(\emph{conditional}).

We also observed that wildly different ``items'' can be the object of an
inference or the information on which the inference is based:
measurement results, decision outcomes, hypotheses, not-real events,
assumptions, data and information of all kinds (for example, images). In
fact, such variety in some cases can make it difficult to pinpoint what
an inference is about or what is it based on.

Is there a general, flexible, yet precise way of representing all these
kinds of ``items''?

\hypertarget{the-central-components-of-knowledge-representation}{%
\section{The central components of knowledge
representation}\label{the-central-components-of-knowledge-representation}}

When speaking of ``data'', what comes to mind to many people is
basically numbers or collections of numbers. Maybe numbers, then, could
be used to represent all the variety of items exemplified above. This
option, however, turns out to be too restrictive.

I give you this number: {``\(8\)'',} saying that it is ``data''. But
what is it about? You, as an agent, can hardly call this number a piece
of information, because you have no clue what to do with it. Instead, if
I tell you: ``\href{https://solarsystem.nasa.gov/planets/overview}{The
number of official planets in the solar system is 8}'', then we can say
that I've given you data. So ``data'' is not just numbers: a number is
not ``data'' unless there's an additional verbal, non-numeric context
accompanying it, even if only implicitly. Sure, we could represent this
meta-data information as numbers too; but this move would only shift the
problem one level up: we would need an auxiliary verbal context
explaining what the meta-data numbers are about.

Data can, moreover, be completely non-numeric. A clinician saying ``The
patient has fully recovered from the disease'' (we imagine to know who's
the patient and what was the disease) is giving us a piece of
information that we could further use, for instance, to make prognoses
about other, similar patients. The clinician's statement surely is
``data'', but essentially non-numeric data. Sure, in some situations we
can represent it as ``1'', while ``0'' would represent ``not
recovered''; but the opposite convention could also be used, or the
numbers ``0.3'' and ``174''. These numbers have intrinsically nothing to
do with the clinician's ``recovery'' data.

But the examples above actually reveal the answer to our needs. In the
examples we expressed the data by means of \emph{sentences}. Clearly any
measurement result, decision outcome, hypothesis, not-real event,
assumption, data, and any piece of information can be expressed by a
sentence.

We shall therefore use {\textbf{sentences}}, also called
{\textbf{propositions}} or \textbf{statements},\footnote{These three
  terms are not always equivalent in formal logic, but here we'll use
  them as synonyms.} to represent and communicate all the kinds of
``items'' that can be the proposal or conditional of an inference. In
some cases we can of course summarize a sentence by a number, as a
shorthand, when the full meaning of the sentence is understood.\\
\strut \\

\emph{Sentences are the central components of knowledge representation
in AI agents}. For example they appear at the heart of automated control
programs and fault-management systems in NASA spacecrafts.

\marginnote{\begin{footnotesize}

\includegraphics[width=1\textwidth,height=\textheight]{SMART.png} (From
the \emph{SMART} paper)

\end{footnotesize}}

\begin{tcolorbox}[enhanced jigsaw, toptitle=1mm, colback=white, opacityback=0, bottomtitle=1mm, breakable, toprule=.15mm, left=2mm, bottomrule=.15mm, coltitle=black, opacitybacktitle=0.6, colbacktitle=quarto-callout-caution-color!10!white, titlerule=0mm, colframe=quarto-callout-caution-color-frame, title={\faIcon{book} Reading}, arc=.35mm, leftrule=.75mm, rightrule=.15mm]

\begin{itemize}
\tightlist
\item
  §\,7.1 in
  \href{https://hvl.instructure.com/courses/25074/modules/items/660089}{\emph{Artificial
  Intelligence}}.
\item
  Take a \emph{quick look} at these:

  \begin{itemize}
  \tightlist
  \item
    \href{https://hdl.handle.net/2014/45618}{\emph{SMART: A
    propositional logic-based trade analysis and risk assessment tool
    for a complex mission}}
  \item
    around p.\,22 in
    \href{https://www.nasa.gov/sites/default/files/637606main_day_1-michel_ingham.pdf}{\emph{No
    More Band-Aids: Integrating FM into the Onboard Execution
    Architecture}}
  \item
    §\,2.1 in
    \href{http://doi.org/10.1016/j.artint.2014.11.003}{\emph{Deliberation
    for autonomous robots: A survey}}
  \item
    part\,IV in
    \href{https://hvl.instructure.com/courses/25074/modules/items/668587}{\emph{Model-based
    programming of intelligent embedded systems and robotic space
    explorers}}
  \end{itemize}
\end{itemize}

\end{tcolorbox}

\hypertarget{identifying-and-working-with-sentences}{%
\section{Identifying and working with
sentences}\label{identifying-and-working-with-sentences}}

But what is a sentence, more exactly? The everyday meaning of this word
will work for us, even though there are more precise definitions -- and
still a lot of research in logic an artificial intelligence on how to
define and use sentences. We shall adopt this useful definition:

\marginnote{\begin{footnotesize}

\begin{tcolorbox}[enhanced jigsaw, toptitle=1mm, colback=white, opacityback=0, bottomtitle=1mm, breakable, toprule=.15mm, left=2mm, bottomrule=.15mm, coltitle=black, opacitybacktitle=0.6, colbacktitle=quarto-callout-tip-color!10!white, titlerule=0mm, colframe=quarto-callout-tip-color-frame, title={\faIcon{rocket} For the extra curious}, arc=.35mm, leftrule=.75mm, rightrule=.15mm]

\href{https://plato.stanford.edu/archives/win2020/entries/propositions}{Propositions}

\end{tcolorbox}

\end{footnotesize}}

\begin{tcolorbox}[enhanced jigsaw, toptitle=1mm, colback=white, opacityback=0, bottomtitle=1mm, breakable, toprule=.15mm, left=2mm, bottomrule=.15mm, coltitle=black, opacitybacktitle=0.6, colbacktitle=quarto-callout-note-color!10!white, titlerule=0mm, colframe=quarto-callout-note-color-frame, title={}, arc=.35mm, leftrule=.75mm, rightrule=.15mm]

{A ``sentence'' is a verbal message for which we can determine whether
it is \texttt{true} or \texttt{false}, at least in principle and in such
a way that all interested receivers of the message would agree.}

\end{tcolorbox}

For instance, in most engineering contexts the phrase ``{This valve will
operate for at least two months}'' is a sentence; whereas the phrase
``{Apples are much tastier than pears}'' is not, because it's a matter
of personal taste -- there's no objective criterion to determine its
truth or falsity (however, the phrase ``{Rita finds apples tastier than
pears}'' could be a sentence; its truth is found by asking Rita). In a
data-science context, the phrase ``{The neural-network algorithm has
better performance than the random-forest one}'' is \emph{not} a
sentence unless we have objectively specified what ``\emph{better}''
means, for example by using a particular comparison metric.

Some expressions in fact, even involving technical terms, may appear to
be sentences at first, but a deeper analysis may reveal that they are
not. A famous example is the sentence ``{The two events (at different
spatial locations) are simultaneous}''. Einstein showed that there's no
physical way to determine whether such an expression is true or false.
Its truth turns out to be a matter of convention (also in Newtonian
mechanics). The Theory of Relativity was born from this observation.

\marginnote{\begin{footnotesize}

\begin{tcolorbox}[enhanced jigsaw, toptitle=1mm, colback=white, opacityback=0, bottomtitle=1mm, breakable, toprule=.15mm, left=2mm, bottomrule=.15mm, coltitle=black, opacitybacktitle=0.6, colbacktitle=quarto-callout-tip-color!10!white, titlerule=0mm, colframe=quarto-callout-tip-color-frame, title={\faIcon{rocket} For the extra curious}, arc=.35mm, leftrule=.75mm, rightrule=.15mm]

\href{https://einsteinpapers.press.princeton.edu/vol2-trans/154}{\emph{On
the electrodynamics of moving bodies}}.

\end{tcolorbox}

\end{footnotesize}}

One sentence can be expressed by many different phrases and in different
languages. For instance, ``{The temperature is 248.15\,K}'',
``{Temperaturen ligger på minus 25 grader}'', and ``{25\,°C is the value
of the temperature}'' all represent the \emph{same} sentence.

A sentence can contain numbers, pictures, and graphs.

Working with sentences, and keeping in mind that inference is about
sentences, is important in several respects:

First, it leads to \textbf{clarity} in engineering problems and makes
them more \textbf{goal-oriented}. A data engineer must acquire
information and convey information. ``Acquiring information'' does not
simply consist in making measurements or counting something: the
engineer must understand \emph{what} is being measured and \emph{why}.
If data is gathered from third parties, the engineer must ask what
exactly the data mean and how they were acquired. In designing and
engineering a solution, it is important to understand what information
or outcomes the end user exactly wants. The ``what'', ``why'', ``how''
are expressed by sentences. A data engineer will often ask ``\emph{wait,
what do you mean by that?}''. This question is not just an unofficial
parenthesis in the official data-transfer workflow between the engineer
and someone else. It is an integral part of that workflow: it means that
some information has not been completely transferred yet.

Second, it is extremely important in AI and machine-learning design. A
(human) engineer may proceed informally when drawing inferences, without
worrying about ``sentences'' unless a need for disambiguation arises. A
data engineer who's \emph{designing} or \emph{programming} an algorithm
that will do inferences automatically, must instead be unambiguous and
cover beforehand all possible cases that the algorithm will face.

\hfill\break

We agree that {\emph{the proposal and the conditional of an inference
have to be sentences}}. This means that the proposal of the inference
must be something that can only be true or false. Many inferences,
especially when they concern numerical measurements, are actually
collections of inferences. For example, an inference about the result of
rolling a die actually consists of six separate inferences with the
proposals \[
\begin{aligned}
&\textsf{\small`The result of the roll is 1'}
\\
&\textsf{\small`The result of the roll is 2'}
\\
&\dotso
\\
&\textsf{\small`The result of the roll is 6'}
\end{aligned}
\]

Later on we shall see how to work with more complex inferences without
thinking about this detail. In real applications it can be useful, on
some occasions, to pause and reduce an inference to its basic set of
\texttt{true}/\texttt{false} inferences; this analysis may reveal
contradictions in our inference. A simple way to do this is to reduce
the complex inference into a set of yes/no questions.

This kind of analysis is also important in information-theoretic
situations: the {\textbf{information content}} provided by an inference,
when measured in \emph{Shannons}, is related to the minimal amount of
yes/no questions that the inference answers.

\begin{tcolorbox}[enhanced jigsaw, toptitle=1mm, colback=white, opacityback=0, bottomtitle=1mm, breakable, toprule=.15mm, left=2mm, bottomrule=.15mm, coltitle=black, opacitybacktitle=0.6, colbacktitle=quarto-callout-caution-color!10!white, titlerule=0mm, colframe=quarto-callout-caution-color-frame, title={\faIcon{user-edit} Exercise}, arc=.35mm, leftrule=.75mm, rightrule=.15mm]

Rewrite each inference scenario of §~\ref{sec-inference-scenarios} in a
formal way, as one or more inferences \[
\textit{[proposal]}\ \pmb{\nonscript\:\Big\vert\nonscript\:\mathopen{}}\ \textit{[conditional]}
\] where proposal and conditional are well-defined sentences.

In ambiguous cases, use your judgement and motivate your choices.

\end{tcolorbox}

\hypertarget{notation}{%
\section{Notation}\label{notation}}

Writing full sentences would take up \emph{a lot} of space. Even an
expression such as ``{The speed is 10\,m/s}'' is not a sentence,
strictly speaking, because it leaves unspecified the speed of what, when
it was measured and in which frame of reference, what we mean by
``speed'', how the unit ``m/s'' is defined, and so on.

Typically we leave the full content of a sentence to be understood from
the context, and we denote the sentence by a simple expression such as
the one above, \[
\textsf{\small The speed is 10\,m/s}
\] or even more compactly introducing physical symbols: \[
v = 10\,\mathrm{m/s}
\] where \(v\) is a physical variable denoting the speed; or even
writing simply \[
10\,\mathrm{m/s}
\]

In some problems it's useful to introduce symbols to denote sentences.
In these notes we'll use sans-serif italic letters:
{\(\mathsfit{A},\mathsfit{B},\mathsfit{a},\mathsfit{b},\dotsc\),},
possibly with sub- or super-scripts. For instance, the sentence ``{The
speed is 10\,m/s}'' could be denoted by the symbol
\(\mathsfit{S}_{10}\). We abbreviate such a definition like this: \[
\mathsfit{S}_{10} \coloneqq \textsf{\small`The speed is 10\,m/s'}
\] which means ``the symbol \(\mathsfit{S}_{10}\) is defined to be the
sentence {\(\textsf{\small`The speed is 10\,m/s'}\)''.}

\begin{tcolorbox}[enhanced jigsaw, toptitle=1mm, colback=white, opacityback=0, bottomtitle=1mm, breakable, toprule=.15mm, left=2mm, bottomrule=.15mm, coltitle=black, opacitybacktitle=0.6, colbacktitle=quarto-callout-warning-color!10!white, titlerule=0mm, colframe=quarto-callout-warning-color-frame, title={\faIcon{exclamation-circle} We must be wary of how much we shorten
sentences}, arc=.35mm, leftrule=.75mm, rightrule=.15mm]

Consider these three: \[
\begin{aligned}
&\textsf{\small`The speed is measured to be 10\,m/s'}
\\
&\textsf{\small`The speed is set to 10\,m/s'}
\\
&\textsf{\small`The speed is reported, by a third party, to be 10\,m/s'}
\end{aligned}
\] The quantity ``10\,m/s'' is the same in all three sentences, but
their meanings are very different. They represent different kinds of
data. These differences greatly affect any inference about or from these
data. For instance, in the third case an engineer may not take the
indirectly-reported speed ``10\,m/s'' at face value, unlike the first
case. In a scenario where all three sentences can occur, it would be
ambiguous to simply write {``\(v = 10\,\mathrm{m/s}\)''}: would the
equal-sign mean ``measured'', ``set'', or ``indirectly reported''?

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, toptitle=1mm, colback=white, opacityback=0, bottomtitle=1mm, breakable, toprule=.15mm, left=2mm, bottomrule=.15mm, coltitle=black, opacitybacktitle=0.6, colbacktitle=quarto-callout-caution-color!10!white, titlerule=0mm, colframe=quarto-callout-caution-color-frame, title={\faIcon{user-edit} Exercise}, arc=.35mm, leftrule=.75mm, rightrule=.15mm]

How would you denote the three sentences above, to make their
differences clear?

\end{tcolorbox}

\hypertarget{connecting-sentences}{%
\section{Connecting sentences}\label{connecting-sentences}}

\hypertarget{atomic-sentences}{%
\subsection{Atomic sentences}\label{atomic-sentences}}

In analysing the measurement results, decision outcomes, hypotheses,
assumptions, data and information that enter into an inference problem,
it is convenient to find a collection of \textbf{basic sentences} or,
using a more technical term, {\textbf{atomic sentences}} out of which
all other sentences of interest can be constructed. These atomic
sentences often represent elementary pieces of information in the
problem.

Consider for instance the following complex sentence, which could appear
in our assembly-line scenario:

\begin{quote}
``The electronic component is still whole after the shock test and the
subsequent heating test. The voltage reported in the final power test is
either 90\,mV or 110\,mV.''
\end{quote}

In this statement we can identify at least four atomic sentences, which
we denote by these symbols: \[\begin{aligned}
\mathsfit{s} &\coloneqq \textsf{\small`The component is whole after the shock test'}
\\
\mathsfit{h} &\coloneqq \textsf{\small`The component is whole after the heating test'}
\\
\mathsfit{v}_{90} &\coloneqq \textsf{\small`The power-test voltage reading is 90\,mV'}
\\
\mathsfit{v}_{110} &\coloneqq \textsf{\small`The power-test voltage reading is 110\,mV'}
\end{aligned}
\]

The inference may actually require additional atomic sentences. For
instance, it might become necessary to consider atomic sentences with
other values for the reported voltage, such as \[\begin{aligned}
\mathsfit{v}_{110} &\coloneqq \textsf{\small`The power-test voltage reading is 100\,mV'}
\\
\mathsfit{v}_{80} &\coloneqq \textsf{\small`The power-test voltage reading is 80\,mV'}
\end{aligned}\] and so on.

\hypertarget{connectives}{%
\subsection{Connectives}\label{connectives}}

How do we construct complex sentences, like the one above, out of atomic
sentences?

We consider three ways: one operation to change a sentence into another
related to it, and two operations to combine two or more sentences
together. These operations are called {\textbf{connectives}}; you may
have encountered them already in Boolean algebra. Our natural language
offers many more operations to combine sentences, but these three
connectives turn out to be all we need in virtually all engineering and
data-science problems:

\begin{tcolorbox}[enhanced jigsaw, toptitle=1mm, colback=white, opacityback=0, bottomtitle=1mm, breakable, toprule=.15mm, left=2mm, bottomrule=.15mm, coltitle=black, opacitybacktitle=0.6, colbacktitle=quarto-callout-note-color!10!white, titlerule=0mm, colframe=quarto-callout-note-color-frame, title={}, arc=.35mm, leftrule=.75mm, rightrule=.15mm]

\begin{description}
\tightlist
\item[{Not:~~\(\lnot\)}]
example: \[
\lnot \mathsfit{s} = \textsf{\small`The component is broken after the shock test'}
\]
\item[{And:~~\(\land\)}]
example: \[
\mathsfit{s} \land \mathsfit{h} = \textsf{\small`The component is whole after the shock and heating tests'}
\]
\item[{Or:~~\(\lor\)}]
example: \[
\mathsfit{v}_{90} \lor \mathsfit{v}_{110} = \textsf{\small`The power-test voltage reading is 90\,mV, or 110\,mV, or both'}
\]
\end{description}

\end{tcolorbox}

These connectives can be applied multiple times, to form increasingly
complex sentences.

\begin{tcolorbox}[enhanced jigsaw, toptitle=1mm, colback=white, opacityback=0, bottomtitle=1mm, breakable, toprule=.15mm, left=2mm, bottomrule=.15mm, coltitle=black, opacitybacktitle=0.6, colbacktitle=quarto-callout-warning-color!10!white, titlerule=0mm, colframe=quarto-callout-warning-color-frame, title={\faIcon{exclamation-circle} Important subtleties of the connectives:}, arc=.35mm, leftrule=.75mm, rightrule=.15mm]

\begin{itemize}
\item
  There is \emph{no strict correspondence} between the words ``not'',
  ``and'', ``or'' in natural language and the three connectives. For
  instance the \texttt{and} connective could correspond to the words
  ``but'' or ``whereas'', or just to a comma ``\,,\,''.
\item
  \texttt{Not} means not some kind of complementary quality, but the
  denial. For
  instance,~~\(\lnot\textsf{\small`The chair is black'}\)~~generally
  does not mean~~{\(\textsf{\small`The chair is white'}\)\,,}~~
  (although in some situations these two sentences could amount to the
  same thing).

  It's always best to \emph{declare explicitly what the \texttt{not} of
  a sentence concretely means}. In our example we take \[
    \lnot\textsf{\small`The component is whole'} \coloneqq \textsf{\small`The component is broken'}
    \] But in other examples the negation of ``being whole'' could
  comprise several different conditions. A good guideline is to always
  state the \texttt{not} of a sentence in \emph{positive} terms.
\item
  \texttt{Or} does not exclude that both the sentences it connects can
  be true. So in our
  example~~\(\mathsfit{v}_{90} \lor \mathsfit{v}_{110}\)~~does not
  exclude, a priori, that the reported voltage could be both 90\,mV and
  110\,mV. (There is a connective for that: ``exclusive-or'', but it can
  be constructed out of the three we already have.)
\end{itemize}

\end{tcolorbox}

From the last remark we see that the sentence \[
\textsf{\small`The power-test voltage reading is 90\,mV or 110\,mV'}
\] does \emph{not} correspond to
~~{\(\mathsfit{v}_{90} \lor \mathsfit{v}_{110}\)\,.}~~It is implicitly
understood that a voltage reading cannot yield two different values at
the same time. Convince yourself that the correct way to write that
sentence is this: \[
(\mathsfit{v}_{90} \lor \mathsfit{v}_{110})
\land
\lnot(\mathsfit{v}_{90} \land \mathsfit{v}_{110})
\]

Finally, the full complex sentence of the present example can be written
in symbols as follows:

\begin{quote}
``{The electronic component is still whole after the shock test} and
{the subsequent heating test}. {The voltage reported in the final power
test is} either {90\,mV} or {110\,mV}.''
\end{quote}

\[
\textcolor[RGB]{102,204,238}{\mathsfit{s}} \land \textcolor[RGB]{34,136,51}{\mathsfit{h}} \land
(\textcolor[RGB]{238,102,119}{\mathsfit{v}_{90}} \lor \textcolor[RGB]{170,51,119}{\mathsfit{v}_{110}})
\land
\lnot
(\textcolor[RGB]{238,102,119}{\mathsfit{v}_{90}} \land \textcolor[RGB]{170,51,119}{\mathsfit{v}_{110}})
\]

\hfill\break

\begin{tcolorbox}[enhanced jigsaw, toptitle=1mm, colback=white, opacityback=0, bottomtitle=1mm, breakable, toprule=.15mm, left=2mm, bottomrule=.15mm, coltitle=black, opacitybacktitle=0.6, colbacktitle=quarto-callout-caution-color!10!white, titlerule=0mm, colframe=quarto-callout-caution-color-frame, title={\faIcon{book} Reading}, arc=.35mm, leftrule=.75mm, rightrule=.15mm]

Just take a quick look at §\,7.4.1 in
\href{https://hvl.instructure.com/courses/25074/modules/items/660089}{\emph{Artificial
Intelligence}} and note the similarities with what we've just learned.
In these notes we follow a faster approach leading directly to
probability logic.

\end{tcolorbox}

\hypertarget{if-then}{%
\section{\texorpdfstring{``If\ldots{}
then\ldots{}''}{``If\ldots{} then\ldots''}}\label{if-then}}

Sentences expressing data and information in natural language also
appear connected with \emph{if\ldots{} then\ldots{}}. For instance:
``{If the voltage reading is 200\,mV, then the component is
defective}''. This kind of expression actually indicates that the
following inference \[
\textsf{\small`The component is defective'} \nonscript\:\big\vert\nonscript\:\mathopen{} \textsf{\small`The voltage reading is 200\,mV'}
\] is \texttt{true}.

This kind of information is very important because it often is the
starting point from which to arrive at the final inferences we're
interested in. We shall discuss it more in detail in the next sections.

\begin{tcolorbox}[enhanced jigsaw, toptitle=1mm, colback=white, opacityback=0, bottomtitle=1mm, breakable, toprule=.15mm, left=2mm, bottomrule=.15mm, coltitle=black, opacitybacktitle=0.6, colbacktitle=quarto-callout-warning-color!10!white, titlerule=0mm, colframe=quarto-callout-warning-color-frame, title={\faIcon{exclamation-circle} Careful}, arc=.35mm, leftrule=.75mm, rightrule=.15mm]

There is a connective in logic, called
``\href{https://plato.stanford.edu/entries/logic-propositional/\#MateCond}{material
conditional}'', which is also often translated as ``if\ldots{}
then\ldots{}''. But it is not the same as the inference relation
discussed above. ``If\ldots{} then\ldots{}'' in natural language usually
denotes an inference rather than a material conditional.

Research is still ongoing on these topics. If you are curious and in for
a headache, look over
\href{https://plato.stanford.edu/entries/logic-conditionals}{\emph{The
logic of conditionals}}.

\end{tcolorbox}

\hfill\break

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

We are now equipped with all the notions and symbolic notation to deal
with our next task: learning the rules for drawing correct inferences.

\hypertarget{sec-truth-inference}{%
\chapter{Truth inference}\label{sec-truth-inference}}

\providecommand{\ul}{\uline}
\renewcommand*{\|}[1][]{\nonscript\:#1\vert\nonscript\:\mathopen{}}
\providecommand*{\pr}[1]{\textsf{\small`#1'}}
\renewcommand*{\pr}[1]{\textsf{\small`#1'}}
\providecommand*{\prq}[1]{\textsf{\small #1}}
\renewcommand*{\prq}[1]{\textsf{\small #1}}
\providecommand{\se}[1]{\mathsfit{#1}}
\renewcommand{\se}[1]{\mathsfit{#1}}
\providecommand{\p}{\mathrm{p}}
\renewcommand{\p}{\mathrm{p}}
\renewcommand{\P}{\mathrm{P}}
\definecolor{quarto-callout-note-color}{HTML}{4477AA}
\definecolor{quarto-callout-note-color-frame}{HTML}{4477AA}
\definecolor{quarto-callout-important-color}{HTML}{AA3377}
\definecolor{quarto-callout-important-color-frame}{HTML}{AA3377}
\definecolor{quarto-callout-warning-color}{HTML}{EE6677}
\definecolor{quarto-callout-warning-color-frame}{HTML}{EE6677}
\definecolor{quarto-callout-tip-color}{HTML}{228833}
\definecolor{quarto-callout-tip-color-frame}{HTML}{228833}
\definecolor{quarto-callout-caution-color}{HTML}{CCBB44}
\definecolor{quarto-callout-caution-color-frame}{HTML}{CCBB44}

\newcommand*{\ys}{\se{s}}
\newcommand*{\yh}{\se{h}}
\newcommand*{\yf}{\se{f}}
\newcommand*{\yI}{\se{I}}
\providecommand{\tru}{\mathrm{T}}

\hypertarget{a-trivial-inference}{%
\section{A trivial inference}\label{a-trivial-inference}}

Consider again the assembly-line scenario of §~\ref{sec-intro}, and
suppose that an inspector has the following information about an
electric component:

\begin{quote}
This electric component had an early failure (within a year of use). If
an electric component fails early, then at production it didn't pass
either the heating test or the shock test. This component passed the
shock test.
\end{quote}

The inspector wants to assess whether the component did not pass the
heating test.

From these data and information given, the conclusion is that the
component \emph{for sure} did not pass the heating test. This conclusion
is certain, and also trivial. But how did we obtain it? Which rules did
we follow to arrive at it from the given data?

{\emph{Formal logic}}, with its \emph{deduction systems}, is the huge
field that formalizes and makes rigorous the rules that a rational
person or an artificial intelligence should use in drawing \emph{sure}
inferences like the one above. We'll now get a glimpse of it, as a
trampoline for jumping towards more general and \emph{uncertain}
inferences.

\hypertarget{analysis-and-representation-of-the-problem}{%
\section{Analysis and representation of the
problem}\label{analysis-and-representation-of-the-problem}}

First let's analyse our simple problem and represent it with more
compact symbols.

We can introduce the following atomic sentences and symbols: \[
\begin{aligned}
\mathsfit{h}&\coloneqq \textsf{\small`The component passed the heating test'}
\\
\mathsfit{s}&\coloneqq \textsf{\small`The component passed the shock test'}
\\
\mathsfit{f}&\coloneqq \textsf{\small`The component had an early failure'}
\\
\mathsfit{I}&\coloneqq \textsf{\small (all other implicit background information)}
\end{aligned}
\]

The inference that the inspector wants to draw can be compactly written:

\[
\lnot\mathsfit{h}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{s}\land \mathsfit{f}\land \mathsfit{I}
\]

\hypertarget{truth-inference-rules}{%
\section{Truth-inference rules}\label{truth-inference-rules}}

Formal logic gives us sets of rules for correctly drawing sure
inferences, that is, inferences where the truth or falsity of the
proposal can be exactly determined -- \emph{when such inferences are
possible}. These rules can be formulated in different ways, leading to a
\href{https://plato.stanford.edu/archives/spr2023/entries/natural-deduction}{wide
variety of deduction systems}. The picture here on the margin, for
instance, shows how a proof of how our inference would look like, using
the so-called sequent calculus.

\begin{marginfigure}

{\centering \includegraphics[width=1\textwidth,height=\textheight]{failure_sequent.png}

}

\caption{The bottom formula is our conclusion. Each line denotes the
application of an inference rule. The two formulae with no line above
are our initial, known inference, and a tautology.}

\end{marginfigure}

\hfill\break

One important point is that deduction systems don't lead to inferences
out of nothing: {\emph{in order to draw an inference, we must always
start from some other inferences that are already known}}. This is one
of the central points of logic, which you may have already heard about.
It is sometimes stated in terms of \emph{axioms} and \emph{theorems}: in
order to prove some theorem, we must always start from some
axioms.\footnote{There actually are ``inferences'' that can be drawn
  without requiring other ones; but they are all trivial
  \emph{tautologies}, such as the conclusion ``this component failed
  early, or it didn't''. They are of little use in a real problem; but
  are important nevertheless, because they reflect the core of the
  inference rules.}

\hfill\break

We can compactly encode all inference rules in the following way. First,
represent \texttt{true} by the number \texttt{1}, and \texttt{false} by
\texttt{0}. Second, symbolically write that conclusion \(C\) is
\texttt{true}, given assumptions \(A\), as follows: \[
\mathrm{T}(C \nonscript\:\vert\nonscript\:\mathopen{} A) = 1 \ .
\] or with \texttt{0} if it's \texttt{false}.

What are the data available to the inspector? One is that the component
failed, {\(\mathsfit{f}\);} another is that the component passed the
shock test, {\(\mathsfit{s}\).} We already included both in the
conditional of the inference above. The inspector also has another piece
of information, which consists in a \emph{known} inference: ``if a
component fails early, then it didn't pass either the heating test or
the shock test''. We write the fact that this inference is known as
follows: \[
\mathrm{T}(\lnot\mathsfit{h}\lor \lnot\mathsfit{s}\nonscript\:\vert\nonscript\:\mathopen{} \mathsfit{f}\land \mathsfit{I}) = 1
\]

\begin{itemize}
\item
  The component can either come from the production line in Oslo, or
  from the one in Rome.
\item
  If the component is defective, it cannot come from Oslo.
\item
  The component is found to be defective.
\end{itemize}

The question is: from which production line does the component come
from?

The answer is obvious: from the Rome line. But how could we draw this
obvious and sure inference? Which rules did we follow? Did we make any
hidden assumptions, or use information that wasn't explicitly mentioned?

Logic is the huge field that formalizes and makes rigorous the rules
that a rational person or an artificial intelligence should use in
drawing sure inferences. We'll get a glimpse of it here, as a trampoline
for jumping towards the more general inferences that we need in
data-driven engineering problems.

\hypertarget{analysis-of-the-problem}{%
\subsection{Analysis of the problem}\label{analysis-of-the-problem}}

Let's write down the basic sentences that constitute our data and the
inferences we want to draw. We identify three basic sentences, which we
can represent by these symbols:

\begin{itemize}
\item
  \(o \coloneqq \textsf{\small`The component comes from the Oslo line'}\)
\item
  \(r \coloneqq \textsf{\small`The component comes from the Rome line'}\)
\item
  \(d \coloneqq \textsf{\small`The component is defective'}\)
\end{itemize}

Obviously the inspector possesses even more information which is
implicitly understood. It's clear, for instance, that the component
cannot come from both Oslo and Rome. Let's denote this information with

\begin{itemize}
\tightlist
\item
  \(I \coloneqq{}\)(a long collection of sentences explaining all other
  implicitly understood information).\\
\end{itemize}

With the sentences above we can express more complex details and
hypotheses appearing in the inspector's problem, in particular:

\begin{itemize}
\item
  \(o \lor r = \textsf{\small`The component comes from either the Oslo line or the Rome line'}\)
\item
  \(\lnot(o \land r) = \textsf{\small`The component cannot come from both the Oslo and the Rome lines'}\)
\item
  \$ \lnot o
  \coloneqq \textsf{\small`The component does not come from the Oslo line'}\$
\end{itemize}

\hypertarget{data-assumptions-desired-conclusions}{%
\subsection{Data, assumptions, desired
conclusions}\label{data-assumptions-desired-conclusions}}

The inspector knows for certain the following facts:

\begin{itemize}
\item
  \(o \lor r\),
  \(\textsf{\small`The component comes from either the Oslo line or the Rome line'}\)
\item
  \(\lnot(o \land r)\),
  \(\textsf{\small`The component cannot come from both the Oslo and the Rome lines'}\)
\item
  \(d\), \(\textsf{\small`The component is defective'}\)
\item
  \(I\), all remaining implicit information
\end{itemize}

We \texttt{and} them all together: \[
d \land (o \lor r) \land \lnot (o \land r) \land I \ .
\]

The inspector knows, moreover, this hypothetical consequence:

\begin{itemize}
\item
  \(\lnot o \nonscript\:\vert\nonscript\:\mathopen{} d \land (o \lor r) \land \lnot (o \land r) \land I\),
  if the component is defective, it cannot come from the Oslo production
  line.
\item
\end{itemize}

\hypertarget{background-information-and-conditional}{%
\section{Background information and
conditional}\label{background-information-and-conditional}}

\hfill\break

\hypertarget{truth-inference-rules-1}{%
\section{Truth-inference rules}\label{truth-inference-rules-1}}

Deduction systems in formal logic give us a set of rules for making
correct inferences, that is, for correctly determining whether the
conclusions of interest are true or false. These rules are represented
in a
\href{https://plato.stanford.edu/archives/spr2023/entries/natural-deduction}{wide
variety of ways}, as steps leading from one conclusion to another one.
The picture here on the margin, for instance, shows how a proof of our
inference would look like, using the so-called sequent calculus.

\begin{marginfigure}

{\centering \includegraphics[width=1\textwidth,height=\textheight]{umbrella_inference_sequent.png}

}

\caption{The bottom formula is our conclusion; the formulae above it
represent steps in the proof. Each line denotes the application of an
inference rule. The two formulae with no line above are our two
assumptions.}

\end{marginfigure}

\hfill\break

We can compactly encode all inference rules in the following way. First,
represent \texttt{true} by the number \texttt{1}, and \texttt{false} by
\texttt{0}. Second, symbolically write that conclusion \(C\) is
\texttt{true}, given assumptions \(A\), as follows: \[
\mathrm{T}(C \nonscript\:\vert\nonscript\:\mathopen{} A) = 1 \ .
\] or with \texttt{0} if it's \texttt{false}.

The rules of truth inference are then encoded by the following
equations, which must always hold for any sentences \(A,B,C\), no matter
whether they are basic or complex:

\begin{figure*}

\begin{description}
\tightlist
\item[Rule for ``not'':]
\begin{equation}\protect\hypertarget{eq-t-not}{}{\mathrm{T}(\lnot A \nonscript\:\vert\nonscript\:\mathopen{} B) 
+ \mathrm{T}(A \nonscript\:\vert\nonscript\:\mathopen{} B)
= 1}\label{eq-t-not}\end{equation}
\item[Rule for ``and'':]
\begin{equation}\protect\hypertarget{eq-t-and}{}{
\mathrm{T}(A \land B \nonscript\:\vert\nonscript\:\mathopen{} C) 
= \mathrm{T}(A \nonscript\:\vert\nonscript\:\mathopen{} B \land C) \cdot
\mathrm{T}(B \nonscript\:\vert\nonscript\:\mathopen{} C) 
= \mathrm{T}(B \nonscript\:\vert\nonscript\:\mathopen{} A \land C) \cdot
\mathrm{T}(A \nonscript\:\vert\nonscript\:\mathopen{} C)
}\label{eq-t-and}\end{equation}
\item[Rule for ``or'':]
\begin{equation}\protect\hypertarget{eq-t-or}{}{\mathrm{T}(A \lor B \nonscript\:\vert\nonscript\:\mathopen{} C) 
= \mathrm{T}(A \nonscript\:\vert\nonscript\:\mathopen{} C) +
\mathrm{T}(B \nonscript\:\vert\nonscript\:\mathopen{} C) 
- \mathrm{T}(A \land B \nonscript\:\vert\nonscript\:\mathopen{} C)
}\label{eq-t-or}\end{equation}
\item[Rule of self-consistency:]
\begin{equation}\protect\hypertarget{eq-t-unity}{}{\mathrm{T}(A \nonscript\:\vert\nonscript\:\mathopen{} A \land C) 
= 1
}\label{eq-t-unity}\end{equation}
\end{description}

\end{figure*}

\hfill\break

Let's see how the inference rule (\textbf{?@eq-example-rule}), for
example, is encoded in these equations. The rule starts with saying that
\(a \land b\) is \texttt{true} according to \(D\). This means that
\(\mathrm{T}(a \land b \nonscript\:\vert\nonscript\:\mathopen{} D)=1\).
But, by rule (\ref{eq-t-and}), we must then have
\(\mathrm{T}(b \nonscript\:\vert\nonscript\:\mathopen{} a \land D) \cdot \mathrm{T}(a \nonscript\:\vert\nonscript\:\mathopen{} D) = 1\).
This can only happen if both
\(\mathrm{T}(b \nonscript\:\vert\nonscript\:\mathopen{} a \land D)\) and
\(\mathrm{T}(a \nonscript\:\vert\nonscript\:\mathopen{} D)\) are equal
to \(1\). So we can conclude that
\(\mathrm{T}(a \nonscript\:\vert\nonscript\:\mathopen{} D)=1\), which is
exactly the conclusion under the line in rule
(\textbf{?@eq-example-rule}).

\begin{tcolorbox}[enhanced jigsaw, toptitle=1mm, colback=white, opacityback=0, bottomtitle=1mm, breakable, toprule=.15mm, left=2mm, bottomrule=.15mm, coltitle=black, opacitybacktitle=0.6, colbacktitle=quarto-callout-caution-color!10!white, titlerule=0mm, colframe=quarto-callout-caution-color-frame, title={\faIcon{user-edit} Exercise}, arc=.35mm, leftrule=.75mm, rightrule=.15mm]

Try to prove our initial inference

\[
\frac{
(b \lor r) \land \lnot (b \land r) \nonscript\:\vert\nonscript\:\mathopen{} D
\qquad
\lnot r \nonscript\:\vert\nonscript\:\mathopen{} D
}{
b\nonscript\:\vert\nonscript\:\mathopen{} D
}
\]

using the basic rules (\ref{eq-t-not}, \ref{eq-t-and}, \ref{eq-t-or},
\ref{eq-t-unity}). Remember that you can use each rule as many times as
you like, and that there is not only one way of constructing a proof.

\end{tcolorbox}

\hypertarget{logical-ai-agents-and-their-limitations}{%
\section{Logical AI agents and their
limitations}\label{logical-ai-agents-and-their-limitations}}

The basic rules above are also the rules that a logical
artificial-intelligent agent should follow.

\begin{tcolorbox}[enhanced jigsaw, toptitle=1mm, colback=white, opacityback=0, bottomtitle=1mm, breakable, toprule=.15mm, left=2mm, bottomrule=.15mm, coltitle=black, opacitybacktitle=0.6, colbacktitle=quarto-callout-caution-color!10!white, titlerule=0mm, colframe=quarto-callout-caution-color-frame, title={\faIcon{book} Reading}, arc=.35mm, leftrule=.75mm, rightrule=.15mm]

\href{https://hvl.instructure.com/courses/25074/modules/items/660089}{Ch.~7
in \emph{Artificial Intelligence}}

\end{tcolorbox}

Many -- if not most -- inference problems that a data engineer must face
are, however, of the \emph{uncertain} kind: it is not possible to surely
infer the truth of some data, and the truth of some initial data may not
be known either. In the next chapter we shall see how to generalize the
logic rules to uncertain situations.

\begin{tcolorbox}[enhanced jigsaw, toptitle=1mm, colback=white, opacityback=0, bottomtitle=1mm, breakable, toprule=.15mm, left=2mm, bottomrule=.15mm, coltitle=black, opacitybacktitle=0.6, colbacktitle=quarto-callout-tip-color!10!white, titlerule=0mm, colframe=quarto-callout-tip-color-frame, title={\faIcon{rocket} For the extra curious}, arc=.35mm, leftrule=.75mm, rightrule=.15mm]

Our cursory visit of formal logic only showed a microscopic part of this
vast field. The study of logic rules continues still today, with many
exciting developments and applications. Feel free take a look at
\href{https://hvl.instructure.com/courses/25074/modules/items/661036}{\emph{Logic
in Computer Science}},
\href{https://hvl.instructure.com/courses/25074/modules/items/661146}{\emph{Mathematical
Logic for Computer Science}},
\href{https://plato.stanford.edu/archives/spr2023/entries/natural-deduction}{Natural
Deduction Systems in Logic}

\end{tcolorbox}

\hypertarget{probability-inference}{%
\chapter{Probability inference}\label{probability-inference}}

\providecommand{\ul}{\uline}
\renewcommand*{\|}[1][]{\nonscript\:#1\vert\nonscript\:\mathopen{}}
\providecommand*{\pr}[1]{\textsf{\small`#1'}}
\renewcommand*{\pr}[1]{\textsf{\small`#1'}}
\providecommand*{\prq}[1]{\textsf{\small #1}}
\renewcommand*{\prq}[1]{\textsf{\small #1}}
\providecommand{\se}[1]{\mathsfit{#1}}
\renewcommand{\se}[1]{\mathsfit{#1}}
\providecommand{\p}{\mathrm{p}}
\renewcommand{\p}{\mathrm{p}}
\renewcommand{\P}{\mathrm{P}}
\definecolor{quarto-callout-note-color}{HTML}{4477AA}
\definecolor{quarto-callout-note-color-frame}{HTML}{4477AA}
\definecolor{quarto-callout-important-color}{HTML}{AA3377}
\definecolor{quarto-callout-important-color-frame}{HTML}{AA3377}
\definecolor{quarto-callout-warning-color}{HTML}{EE6677}
\definecolor{quarto-callout-warning-color-frame}{HTML}{EE6677}
\definecolor{quarto-callout-tip-color}{HTML}{228833}
\definecolor{quarto-callout-tip-color-frame}{HTML}{228833}
\definecolor{quarto-callout-caution-color}{HTML}{CCBB44}
\definecolor{quarto-callout-caution-color-frame}{HTML}{CCBB44}

\hypertarget{when-truth-isnt-known-probability}{%
\section{When truth isn't known:
probability}\label{when-truth-isnt-known-probability}}

In most real-life and engineering situations we don't know the truth or
falsity of sentences and hypotheses that interest us. But this doesn't
mean that nothing can be said or done in such situations.

When we cross a busy city street we look left and right to check whether
any cars are approaching. We typically don't look up to check whether
something is falling from the sky. Yet, couldn't it be \texttt{false}
that cars are approaching? and couldn't it be \texttt{true} that
\href{https://www.aerotime.aero/articles/32818-cessna-door-falls-off-lands-in-parking-lot}{some
object is falling from the sky}? Of course both events are possible.
Then why do we look left and right, but not up?

The main reason\footnote{We shall see later that one more factor enters
  the explanation.} is that we \emph{believe strongly} that cars might
be approaching, \emph{believe very weakly} that some object might be
falling from the sky. In other words, we consider the first occurrence
to be very \emph{probable}; the second, extremely improbable.

We shall take the notion of \textbf{probability} as intuitively
understood (just as we did with the notion of truth). Terms equivalent
for ``probability'' are \emph{degree of belief}, \emph{plausibility},
\emph{credibility}.

\begin{tcolorbox}[enhanced jigsaw, left=2mm, bottomrule=.15mm, colback=white, arc=.35mm, opacityback=0, colframe=quarto-callout-important-color-frame, rightrule=.15mm, breakable, leftrule=.75mm, toprule=.15mm]

\textbf{}\vspace{2mm}

\faIcon{exclamation-circle} In technical discourse, \emph{likelihood}
means something different and is \emph{not} a synonym of
``probability'', as we'll explain later.

\end{tcolorbox}

Probabilities are quantified between \texttt{0} and \texttt{1}, or
equivalently between \texttt{0\%} and \texttt{100\%}. Assigning to a
sentence a probability \texttt{1} is the same as saying that it is
\texttt{true}; and a probability \texttt{0}, that it is \texttt{false}.
A probability of \texttt{0.5} represents a belief completely symmetric
with respect to truth and falsity.

It is important to emphasize and agree on some facts about
probabilities:

\begin{itemize}
\item
  \textbf{Probabilities are assigned to \emph{sentences}}. Consider an
  engineer working on a problem of electric-power distribution in a
  specific geographical region. At a given moment the engineer may
  believe with \texttt{75\%} probability that the measured average power
  output in the next hour will be 100~MW. The \texttt{75\%} probability
  is assigned not to the quantity ``100~MW'', but to the \emph{sentence}
  \[
  \textsf{\small`The measured average power output in the next hour will be 100\,MW'}
  \] This difference is extremely important. Consider the alternative
  sentence \[
  \textsf{\small`The average power output in the next hour will be \emph{set} to 100\,MW'}
  \] the quantity is the same, but the meaning is very different. The
  probability can therefore be very different (if the engineer is the
  person deciding the output, the probability is \texttt{100\%}). The
  probability depends not only on a number, but on what it's being done
  with that number -- measuring, setting, third-party reporting, and so
  on. Often we still write simply
  \(\textsf{\small`\(\mathsf{O = 100\,W}\)'}\) or even just
  \(\textsf{\small`100\,W'}\), provided that the full sentence behind
  the shorthand is understood.
\item
  \textbf{Probabilities are agent- and context-dependent}. A coin is
  tossed, comes down heads, and is quickly hidden from view. Alice sees
  that it landed heads-up. Bob instead doesn't manage to see the outcome
  and has no clue. Alice considers the sentence
  \(\textsf{\small`Coin came down heads'}\) to be \texttt{true}, that
  is, to have \texttt{100\%} probability. Bob considers the same
  sentence to have \texttt{50\%} probability.

  Note how Alice and Bob assign two different probabilities to the same
  sentence; yet both assignments are completely rational. If Bob
  assigned \texttt{100\%} to \(\textsf{\small`heads'}\), we would
  suspect that he had seen the outcome after all; if he assigned
  \texttt{0\%} to \(\textsf{\small`heads'}\), we would consider that
  groundless and silly. We would be baffled if Alice assigned
  \texttt{50\%} to \(\textsf{\small`heads'}\), because she saw the
  outcome was actually heads; we would hypothesize that she feels unsure
  about what she saw.

  An omniscient agent would know the truth or falsity of every sentence,
  and assign only probabilities \texttt{0} or \texttt{1}. Some authors
  speak of ``\emph{actual} (but unknown) probabilities''; if there were
  ``actual'' probabilities, they would be all \texttt{0} or \texttt{1},
  and it would be pointless to speak about probabilities at all -- every
  inference would be a truth inference.
\item
  \textbf{Probabilities are not frequencies}. The fraction of defective
  mechanical components to total components produced per year in some
  factory is a quantity that can be physically measured and would be
  agreed upon by every agent. It is a \emph{frequency}, not a degree of
  belief or probability. It is important to understand the difference
  between them, to avoid making sub-optimal decisions; we shall say more
  about this difference later. Frequencies can be unknown to some
  agents, probabilities cannot be unknown (but can be difficult to
  calculate). Be careful when you read authors speaking of an ``unknown
  probability''; either they actually mean ``unknown frequency'', or a
  probability that has to be calculated (it's ``unknown'' in the same
  sense that the value of \(1-0.7 \cdot 0.2/(1-0.3)\) is unknown to you
  right now).
\item
  \textbf{Probabilities are not physical properties}. Whether a tossed
  coin lands heads up or tails up is fully determined by the initial
  conditions (position, orientation, momentum, rotational momentum) of
  the toss and the boundary conditions (air velocity and pressure)
  during the flight. The same is true for all macroscopic engineering
  phenomena (even quantum phenomena have never been proved to be
  non-deterministic, and there are
  \href{https://doi.org/10.48550/arXiv.quant-ph/9504010}{deterministic
  and experimentally consistent} mathematical representations of quantum
  theory). So we cannot measure a probability using some physical
  apparatus; and the mechanisms underlying any engineering problem boil
  down to physical laws, not to probabilities.
\end{itemize}

\begin{tcolorbox}[enhanced jigsaw, toptitle=1mm, colback=white, opacityback=0, bottomtitle=1mm, breakable, toprule=.15mm, left=2mm, bottomrule=.15mm, coltitle=black, opacitybacktitle=0.6, colbacktitle=quarto-callout-caution-color!10!white, titlerule=0mm, colframe=quarto-callout-caution-color-frame, title={\faIcon{book} Reading}, arc=.35mm, leftrule=.75mm, rightrule=.15mm]

\href{https://hvl.instructure.com/courses/25074/modules/items/661553}{\emph{Dynamical
Bias in the Coin Toss}}

\end{tcolorbox}

These facts are not just a matter of principle. They have important
practical consequences. A data engineer who is not attentive to the
source of the data (measured? set? reported, and so maybe less
trustworthy?), or who does not carefully assess the context of a
probability, or who mixes it up with something else, or who does not
take advantage (when possible) of the physics involved in the
engineering problem, will design a system with sub-optimal
performance\footnote{This fact can be mathematically proven.} -- or even
cause deaths.

\hypertarget{no-new-building-blocks}{%
\section{No new building blocks}\label{no-new-building-blocks}}

In discussing \protect\hyperlink{sec-truth-inference}{truth-inference}
we introduced notations such as
\(\mathrm{T}(a \nonscript\:\vert\nonscript\:\mathopen{} b \land D)\),
which stands for the truth-value \texttt{0} or \texttt{1} of sentence
\(a\) in the context of data \(D\) and supposing (even if only
hypothetically) sentence \(b\) to be true. We can simply extend this
notation to probability-values, using a \(\mathrm{P}\) instead of
\(\mathrm{T}\):
\[\mathrm{P}(a \nonscript\:\vert\nonscript\:\mathopen{} b \land D) \in [0,1]\]
represents the probability or degree of belief in sentence \(a\) in the
context of data \(D\) and supposing also sentence \(b\) to be true. Keep
in mind that both \(a\) and \(b\) could be complex sentences (for
instance \(a = (\lnot c \lor d) \land e\)). Note that truth-values are
included as the special cases\texttt{1} or \texttt{0}: \[
\mathrm{P}(a \nonscript\:\vert\nonscript\:\mathopen{} b \land D) = 0\text{ or }1
\quad\Longleftrightarrow\quad
\mathrm{T}(a \nonscript\:\vert\nonscript\:\mathopen{} b \land D) = 0\text{ or }1
\]

\hypertarget{probability-inference-rules}{%
\section{Probability-inference
rules}\label{probability-inference-rules}}

Extending our truth-inference notation to probability-inference notation
has been straightforward. But how do we draw inferences when
probabilities are involved?

Consider the inference about my umbrella in a more uncertain situation:

\begin{figure*}

\[
\frac{
\mathrm{P}(\textsf{\small`My umbrella is either blue or red'}\nonscript\:\vert\nonscript\:\mathopen{}D)=1\quad
\mathrm{P}(\textsf{\small`My umbrella is not red'} \nonscript\:\vert\nonscript\:\mathopen{} D)=0.5
}{
\mathrm{P}(\textsf{\small`My umbrella is blue'} \nonscript\:\vert\nonscript\:\mathopen{} D) = \mathord{?}
}
\]

\end{figure*}

or more compactly, using the symbols we introduced earlier, \[
\frac{
\mathrm{P}\bigl[(b \lor r) \land \lnot (b \land r)\nonscript\:\vert\nonscript\:\mathopen{}D\bigr]=1\quad
\mathrm{P}(\lnot r\nonscript\:\vert\nonscript\:\mathopen{} D)=0.5
}{
\mathrm{P}( b \nonscript\:\vert\nonscript\:\mathopen{} D) = \mathord{?}
}
\] This says, above the line, that: according to our data \(D\) my
umbrella is either blue or red (and can't be both), with full certainty;
and according to our data we have no preferential beliefs on whether my
umbrella is not red. What should then be the probability of my umbrella
being blue, according to our data?

Intuitively that probability should be \texttt{50\%}:
\(\mathrm{P}( b \nonscript\:\vert\nonscript\:\mathopen{} D)=0.5\). But
which rules did we follow in arriving at this probability? More
generally, which rules should we follow in assigning new probabilities
from given ones?

The amazing result is that \emph{the rules for truth-inference, formulae
(\ref{eq-t-not}, \ref{eq-t-or}, \ref{eq-t-and}, \ref{eq-t-unity}),
extend also to probability-inference}. The only difference is that they
now hold for all values in the range \([0,1]\), rather than only values
\(0\) and \(1\).

This important result was taken more or less for granted at least since
Laplace in the 1700s. But was formally proven for the first time in the
1940s by R.~T.~Cox; the proof has been refined since then. What kind of
proof is it? It shows that if we don't follow the rules we arrive at
illogical conclusions; we'll show some examples later.

Here are the fundamental rules of probability inference. In these rules,
all probabilities can have values in the range
\(\mathrm{P}() \in [0,1]\), and the symbols \(a,b,D\) represent
sentences of any complexity:

\begin{figure*}

\begin{tcolorbox}[enhanced jigsaw, toptitle=1mm, colback=white, opacityback=0, bottomtitle=1mm, breakable, toprule=.15mm, left=2mm, bottomrule=.15mm, coltitle=black, opacitybacktitle=0.6, colbacktitle=quarto-callout-note-color!10!white, titlerule=0mm, colframe=quarto-callout-note-color-frame, title={\faIcon{landmark}~~~THE FUNDAMENTAL LAWS OF
INFERENCE~~~\faIcon{landmark}}, arc=.35mm, leftrule=.75mm, rightrule=.15mm]

\begin{description}
\tightlist
\item[``Not'' \(\boldsymbol{\lnot}\) rule]
\[\mathrm{P}(\lnot a \nonscript\:\vert\nonscript\:\mathopen{} D) 
+ \mathrm{P}(a \nonscript\:\vert\nonscript\:\mathopen{} D)
= 1\]\\
\item[``And'' \(\boldsymbol{\land}\) rule]
\[
\mathrm{P}(a \land b \nonscript\:\vert\nonscript\:\mathopen{} D) 
= \mathrm{P}(a \nonscript\:\vert\nonscript\:\mathopen{} b \land D) \cdot
\mathrm{P}(b \nonscript\:\vert\nonscript\:\mathopen{} D) 
= \mathrm{P}(b \nonscript\:\vert\nonscript\:\mathopen{} a \land D) \cdot
\mathrm{P}(a \nonscript\:\vert\nonscript\:\mathopen{} D) 
\]\\
\item[``Or'' \(\boldsymbol{\lor}\) rule]
\[\mathrm{P}(a \lor b \nonscript\:\vert\nonscript\:\mathopen{} D) 
= \mathrm{P}(a \nonscript\:\vert\nonscript\:\mathopen{} D) +
\mathrm{P}(b \nonscript\:\vert\nonscript\:\mathopen{} D) 
- \mathrm{P}(a \land b \nonscript\:\vert\nonscript\:\mathopen{} D)
\]\\
\item[Self-consistency rule]
\[\mathrm{P}(a \nonscript\:\vert\nonscript\:\mathopen{} a \land D) 
= 1
\]
\end{description}

\end{tcolorbox}

\end{figure*}

It is amazing that \textbf{ALL} inference is nothing else but a repeated
application of these four rules -- billions of times or more, in some
inferences. All machine-learning algorithms are just applications or
approximations of these rules. Methods that you may have heard about in
statistics are just specific applications of these rules. Truth
inferences are also special applications of these rules. Most of this
course is, at bottom, just a study of how to apply these rules in
particular kinds of problems.

\begin{tcolorbox}[enhanced jigsaw, toptitle=1mm, colback=white, opacityback=0, bottomtitle=1mm, breakable, toprule=.15mm, left=2mm, bottomrule=.15mm, coltitle=black, opacitybacktitle=0.6, colbacktitle=quarto-callout-caution-color!10!white, titlerule=0mm, colframe=quarto-callout-caution-color-frame, title={\faIcon{book} Reading}, arc=.35mm, leftrule=.75mm, rightrule=.15mm]

\begin{itemize}
\item
  \href{https://hvl.instructure.com/courses/25074/modules/items/660094}{\emph{Probability,
  Frequency and Reasonable Expectation}}
\item
  Ch.~2 of
  \href{https://hvl.instructure.com/courses/25074/modules/items/660390}{\emph{Bayesian
  Logical Data Analysis for the Physical Sciences}}
\item
  §§~1.0--1.2 of
  \href{https://hvl.instructure.com/courses/25074/modules/items/661040}{\emph{Data
  Analysis}}
\item
  Feel free to skim through §§~2.0--2.4 of
  \href{https://hvl.instructure.com/courses/25074/modules/items/660090}{\emph{Probability
  Theory}}
\end{itemize}

\end{tcolorbox}

\hypertarget{how-the-inference-rules-are-used}{%
\section{How the inference rules are
used}\label{how-the-inference-rules-are-used}}

The fundamental rules represent, first of all, constraints of logical
consistency among probabilities. If we have probabilities
\(\mathrm{P}(a\nonscript\:\vert\nonscript\:\mathopen{}D)=0.7\),
\(\mathrm{P}(b\nonscript\:\vert\nonscript\:\mathopen{}a\land D)=0.1\),
\(\mathrm{P}(a\land b\nonscript\:\vert\nonscript\:\mathopen{}D)=0.2\),
then there's an inconsistency somewhere, because these values violate
the and-rule:~~\(0.2 \ne 0.1 \cdot 0.7\).~~In this case we must find the
inconsistency and solve it. Since probabilities are quantified by real
numbers, however, it's possible and acceptable to have slight
discrepancies owing to numerical round-off errors.

The rules also imply more general constraints. For example we must
\emph{always} have \begin{gather*}
\mathrm{P}(a\land b \nonscript\:\vert\nonscript\:\mathopen{}D) \le \min\bigl\{\mathrm{P}(a\nonscript\:\vert\nonscript\:\mathopen{}D),\  \mathrm{P}(b\nonscript\:\vert\nonscript\:\mathopen{}D)\bigr\}
\\
\mathrm{P}(a\lor b \nonscript\:\vert\nonscript\:\mathopen{}D) \ge \max\bigl\{\mathrm{P}(a\nonscript\:\vert\nonscript\:\mathopen{}D),\  \mathrm{P}(b\nonscript\:\vert\nonscript\:\mathopen{}D)\bigr\}
\end{gather*}

\begin{tcolorbox}[enhanced jigsaw, toptitle=1mm, colback=white, opacityback=0, bottomtitle=1mm, breakable, toprule=.15mm, left=2mm, bottomrule=.15mm, coltitle=black, opacitybacktitle=0.6, colbacktitle=quarto-callout-caution-color!10!white, titlerule=0mm, colframe=quarto-callout-caution-color-frame, title={\faIcon{user-edit} Exercise}, arc=.35mm, leftrule=.75mm, rightrule=.15mm]

Try to prove the two constraints above

\end{tcolorbox}

The main use of the rules in concrete applications is for calculating
new probabilities from given ones. The calculated probabilities will be
automatically consistent. For each equation shown in the rules we can
calculate one probability given the remaining ones in the equation, with
some special cases when values of \(0\) or \(1\) appear.

For example, if we have
\(\mathrm{P}(a \land b\nonscript\:\vert\nonscript\:\mathopen{} D)=0.2\)
and \(\mathrm{P}(a\nonscript\:\vert\nonscript\:\mathopen{}D)=0.7\), from
the and-rule we can find
\(\mathrm{P}(b\nonscript\:\vert\nonscript\:\mathopen{} a \land D)\):
\begin{multline*}
\underbracket{\color[RGB]{34,136,51}\mathrm{P}(a \land b \nonscript\:\vert\nonscript\:\mathopen{} D)}_{0.2}
= {\color[RGB]{238,102,119}\mathrm{P}(b \nonscript\:\vert\nonscript\:\mathopen{} a \land D)} \cdot
\underbracket{\color[RGB]{34,136,51}\mathrm{P}(a \nonscript\:\vert\nonscript\:\mathopen{} D)}_{0.7}
\\[1em]
\Longrightarrow\quad
{\color[RGB]{238,102,119}\mathrm{P}(b\nonscript\:\vert\nonscript\:\mathopen{} a \land D)} = 
\frac{\color[RGB]{34,136,51}
\mathrm{P}(a\land b \nonscript\:\vert\nonscript\:\mathopen{} D)
}{\color[RGB]{34,136,51}
\mathrm{P}(a\nonscript\:\vert\nonscript\:\mathopen{}D)
} = \frac{0.2}{0.7} 
\approx 0.2857
\end{multline*}\\

Let us now solve the umbrella inference from the previous section.
Starting from \[
\mathrm{P}\bigl[(b \lor r) \land \lnot (b \land r)\nonscript\:\vert\nonscript\:\mathopen{}D\bigr]=1 \ ,
\quad
\mathrm{P}(\lnot r\nonscript\:\vert\nonscript\:\mathopen{} D)=0.5
\] we arrive at \[
\mathrm{P}( b \nonscript\:\vert\nonscript\:\mathopen{} D) = 0.5
\]

by following from top to bottom the steps depicted here:

\includesvg{umbrella_inference2.svg}

@@ example medical diagnosis

\hypertarget{derived-rules}{%
\subsection{Derived rules}\label{derived-rules}}

The rules above are in principle all we need to use. But from them it is
possible to derive some additional shortcut rules that are automatically
consistent with the fundamental ones.

First, it is possible to show that all rules you may know from Boolean
algebra are a consequence of the fundamental rules. For example, we can
always make the following convenient replacements anywhere in a
probability expression: \[
\begin{gathered}
A \land A = A \lor A = A
\qquad
\lnot\lnot A = A
\\[1ex]
A\land B = B \land A
\qquad
A \lor B = B \lor A
\\[1ex]
\lnot (A \land B) = \lnot A \lor \lnot B
\qquad
\lnot (A \lor B) = \lnot A \land \lnot B
\\[1ex]
A \land (B \lor C) = (A \land B) \lor (A \land C)
\\[1ex]
A \lor (B \land C) = (A \lor B) \land (A \lor C)
\end{gathered}
\]

Two other derived rules are used extremely often, so we treat them
separately.

\hypertarget{law-of-total-probability-or-extension-of-the-conversation}{%
\section{Law of total probability or ``extension of the
conversation''}\label{law-of-total-probability-or-extension-of-the-conversation}}

\hypertarget{bayess-theorem}{%
\section{Bayes's theorem}\label{bayess-theorem}}

\begin{marginfigure}

{\centering \includegraphics{bayes_big-bang.jpg}

}

\caption{Bayes's theorem guest-starring in
\href{https://www.imdb.com/title/tt0898266/}{\emph{The Big Bang
Theory}}}

\end{marginfigure}

\hypertarget{consequences-of-not-following-the-rules}{%
\section{consequences of not following the
rules,}\label{consequences-of-not-following-the-rules}}

@@ §12.2.3 of AI

\begin{itemize}
\item
  \emph{Exercise: \href{The_Monty_Hall_problem-exercise.pdf}{Monty-Hall
  problem \& variations}}
\item
  \emph{Exercise: clinical test \& diagnosis}
\end{itemize}

\hypertarget{common-points-of-certain-and-uncertain-inference}{%
\section{Common points of certain and uncertain
inference}\label{common-points-of-certain-and-uncertain-inference}}

\begin{quote}
\emph{No premises? No conclusions!}
\end{quote}

\begin{tcolorbox}[enhanced jigsaw, toptitle=1mm, colback=white, opacityback=0, bottomtitle=1mm, breakable, toprule=.15mm, left=2mm, bottomrule=.15mm, coltitle=black, opacitybacktitle=0.6, colbacktitle=quarto-callout-important-color!10!white, titlerule=0mm, colframe=quarto-callout-important-color-frame, title={\faIcon{exclamation-circle} Differences in terminology}, arc=.35mm, leftrule=.75mm, rightrule=.15mm]

\begin{itemize}
\item
  Some texts speak of the probability of a ``random\footnotemark{}
  variable'', or more precisely of the probability that a random
  variable takes on a particular value. As you notice, we have just
  expressed that idea by means of a \emph{sentence}. The viewpoint and
  terminology of random variables is a special case of that of
  sentences. As already discussed, in concrete applications it is
  important to know how a variable ``takes on'' a value: for example it
  could be directly measured, indirectly reported, or purposely set.
  Thinking in terms of sentences, rather than of random variables,
  allows us to account for these important differences.
\item
  Some texts speak of the probability of an ``event''. For all purposes
  an ``event'' is just what's expressed in a sentence.
\end{itemize}

It's a question for sociology of science why some people keep on using
less flexible points of view or terminologies. Probably they just
memorize them as students and then a fossilization process sets in.

\end{tcolorbox}

\footnotetext{What does ''random'' mean? Good luck finding an
understandable and non-circular definition in texts that use that word.
In these notes, if the word ''random'' is ever used, it means
''unpredictable'' or ''unsystematic''.}

\hypertarget{data-and-information}{%
\chapter{Data and information}\label{data-and-information}}

\hypertarget{kinds-of-data}{%
\section{Kinds of data}\label{kinds-of-data}}

\hypertarget{binary}{%
\subsection{Binary}\label{binary}}

\hypertarget{nominal}{%
\subsection{Nominal}\label{nominal}}

\hypertarget{ordinal}{%
\subsection{Ordinal}\label{ordinal}}

\hypertarget{continuous}{%
\subsection{Continuous}\label{continuous}}

\begin{itemize}
\item
  unbounded
\item
  bounded
\item
  censored
\end{itemize}

\hypertarget{complex-data}{%
\subsection{Complex data}\label{complex-data}}

2D, 3D, images, graphs, etc.

\hypertarget{soft-data}{%
\subsection{``Soft'' data}\label{soft-data}}

\begin{itemize}
\item
  orders of magnitude
\item
  physical bounds
\end{itemize}

\hypertarget{data-transformations}{%
\section{Data transformations}\label{data-transformations}}

\begin{itemize}
\item
  log
\item
  probit
\item
  logit
\end{itemize}

\hypertarget{allocation-of-uncertainty-among-possible-data-values-probability-distributions}{%
\chapter{Allocation of uncertainty among possible data values:
probability
distributions}\label{allocation-of-uncertainty-among-possible-data-values-probability-distributions}}

\hypertarget{the-difference-between-statistics-and-probability-theory}{%
\section{The difference between Statistics and Probability
Theory}\label{the-difference-between-statistics-and-probability-theory}}

\emph{Statistics} is the study of collective properties of collections
of data. It does not imply that there is any uncertainty.

\emph{Probability theory} is the quantification and propagation of
uncertainty. It does not imply that we have collections of data.

\hypertarget{whats-distributed}{%
\section{What's ``distributed''?}\label{whats-distributed}}

Difference between distribution of probability and distribution of (a
collection of) data.

\hypertarget{distributions-of-probability}{%
\section{Distributions of
probability}\label{distributions-of-probability}}

\hypertarget{representations}{%
\subsection{Representations}\label{representations}}

\begin{itemize}
\item
  Density function
\item
  Histogram
\item
  Scatter plot
\end{itemize}

Behaviour of representations under transformations of data.

\hypertarget{summaries-of-distributions-of-probability}{%
\section{Summaries of distributions of
probability}\label{summaries-of-distributions-of-probability}}

\hypertarget{location}{%
\subsection{Location}\label{location}}

Median, mean

\hypertarget{dispersion-or-range}{%
\subsection{Dispersion or range}\label{dispersion-or-range}}

Quantiles \& quartiles, interquartile range, median absolute deviation,
standard deviation, half-range

\hypertarget{resolution}{%
\subsection{Resolution}\label{resolution}}

Differential entropy

\hypertarget{behaviour-of-summaries-under-transformations-of-data-and-errors-in-data}{%
\subsection{Behaviour of summaries under transformations of data and
errors in
data}\label{behaviour-of-summaries-under-transformations-of-data-and-errors-in-data}}

\hypertarget{outliers-and-out-of-population-data}{%
\section{Outliers and out-of-population
data}\label{outliers-and-out-of-population-data}}

(Warnings against tail-cutting and similar nonsense-practices)

\hypertarget{marginal-and-conditional-distributions-of-probability}{%
\section{Marginal and conditional distributions of
probability}\label{marginal-and-conditional-distributions-of-probability}}

\hypertarget{collecting-and-sampling-data}{%
\section{Collecting and sampling
data}\label{collecting-and-sampling-data}}

\hypertarget{representative-samples}{%
\subsection{``Representative'' samples}\label{representative-samples}}

Size of minimal representative sample = (2\^{}entropy)/precision

\begin{itemize}
\tightlist
\item
  \emph{Exercise: data with 14 binary variates, 10000 samples}
\end{itemize}

\hypertarget{unavoidable-sampling-biases}{%
\subsection{Unavoidable sampling
biases}\label{unavoidable-sampling-biases}}

In high dimensions, all datasets are outliers.

Data splits and cross-validation cannot correct sampling biases

\hypertarget{quirks-and-warnings-about-high-dimensional-data}{%
\section{Quirks and warnings about high-dimensional
data}\label{quirks-and-warnings-about-high-dimensional-data}}

\hypertarget{making-decisions}{%
\chapter{Making decisions}\label{making-decisions}}

\hypertarget{decisions-possible-situations-and-consequences}{%
\section{Decisions, possible situations, and
consequences}\label{decisions-possible-situations-and-consequences}}

\hypertarget{gains-and-losses-utilities}{%
\section{Gains and losses: utilities}\label{gains-and-losses-utilities}}

\hypertarget{factors-that-enter-utility-quantification}{%
\subsection{Factors that enter utility
quantification}\label{factors-that-enter-utility-quantification}}

Utilities can rarely be assigned a priori.

\hypertarget{making-decisions-under-uncertainty-maximization-of-expected-utility}{%
\section{Making decisions under uncertainty: maximization of expected
utility}\label{making-decisions-under-uncertainty-maximization-of-expected-utility}}

\hypertarget{the-most-general-inference-problem}{%
\chapter{The most general inference
problem}\label{the-most-general-inference-problem}}



\end{document}
