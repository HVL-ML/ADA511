% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames,x11names}{xcolor}
%
\documentclass[
  a4paper,
  DIV=11,
  numbers=noendperiod,
  oneside]{scrreprt}

\usepackage{amsmath,amssymb}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else  
    % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\usepackage[left=1in,marginparwidth=2.0in,textwidth=4.0in,marginparsep=0.3in]{geometry}
\setlength{\emergencystretch}{3em} % prevent overfull lines
\setcounter{secnumdepth}{2}
% Make \paragraph and \subparagraph free-standing
\ifx\paragraph\undefined\else
  \let\oldparagraph\paragraph
  \renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
  \let\oldsubparagraph\subparagraph
  \renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi


\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother

\KOMAoption{captions}{tableheading}
\usepackage{mathtools}
\usepackage[normalem]{ulem}
\makeatletter
\@ifpackageloaded{tcolorbox}{}{\usepackage[skins,breakable]{tcolorbox}}
\@ifpackageloaded{fontawesome5}{}{\usepackage{fontawesome5}}
\definecolor{quarto-callout-color}{HTML}{909090}
\definecolor{quarto-callout-note-color}{HTML}{0758E5}
\definecolor{quarto-callout-important-color}{HTML}{CC1914}
\definecolor{quarto-callout-warning-color}{HTML}{EB9113}
\definecolor{quarto-callout-tip-color}{HTML}{00A047}
\definecolor{quarto-callout-caution-color}{HTML}{FC5300}
\definecolor{quarto-callout-color-frame}{HTML}{acacac}
\definecolor{quarto-callout-note-color-frame}{HTML}{4582ec}
\definecolor{quarto-callout-important-color-frame}{HTML}{d9534f}
\definecolor{quarto-callout-warning-color-frame}{HTML}{f0ad4e}
\definecolor{quarto-callout-tip-color-frame}{HTML}{02b875}
\definecolor{quarto-callout-caution-color-frame}{HTML}{fd7e14}
\makeatother
\makeatletter
\makeatother
\makeatletter
\@ifpackageloaded{bookmark}{}{\usepackage{bookmark}}
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\AtBeginDocument{%
\ifdefined\contentsname
  \renewcommand*\contentsname{Table of contents}
\else
  \newcommand\contentsname{Table of contents}
\fi
\ifdefined\listfigurename
  \renewcommand*\listfigurename{List of Figures}
\else
  \newcommand\listfigurename{List of Figures}
\fi
\ifdefined\listtablename
  \renewcommand*\listtablename{List of Tables}
\else
  \newcommand\listtablename{List of Tables}
\fi
\ifdefined\figurename
  \renewcommand*\figurename{Figure}
\else
  \newcommand\figurename{Figure}
\fi
\ifdefined\tablename
  \renewcommand*\tablename{Table}
\else
  \newcommand\tablename{Table}
\fi
}
\@ifpackageloaded{float}{}{\usepackage{float}}
\floatstyle{ruled}
\@ifundefined{c@chapter}{\newfloat{codelisting}{h}{lop}}{\newfloat{codelisting}{h}{lop}[chapter]}
\floatname{codelisting}{Listing}
\newcommand*\listoflistings{\listof{codelisting}{List of Listings}}
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\@ifpackageloaded{subcaption}{}{\usepackage{subcaption}}
\makeatother
\makeatletter
\@ifpackageloaded{tcolorbox}{}{\usepackage[skins,breakable]{tcolorbox}}
\makeatother
\makeatletter
\@ifundefined{shadecolor}{\definecolor{shadecolor}{rgb}{.97, .97, .97}}
\makeatother
\makeatletter
\makeatother
\makeatletter
\@ifpackageloaded{sidenotes}{}{\usepackage{sidenotes}}
\@ifpackageloaded{marginnote}{}{\usepackage{marginnote}}
\makeatother
\makeatletter
\makeatother
\makeatletter
\@ifpackageloaded{fontawesome5}{}{\usepackage{fontawesome5}}
\makeatother
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same} % disable monospaced font for URLs
\hypersetup{
  pdftitle={ADA511:  Data science and data-driven engineering},
  pdfauthor={Steffen Mæland; PierGianLuca Porta Mana},
  colorlinks=true,
  linkcolor={blue},
  filecolor={Maroon},
  citecolor={Blue},
  urlcolor={Blue},
  pdfcreator={LaTeX via pandoc}}

\title{ADA511: Data science and data-driven engineering}
\author{Steffen Mæland \and PierGianLuca Porta Mana}
\date{2023-06-14}

\begin{document}
\maketitle
\ifdefined\Shaded\renewenvironment{Shaded}{\begin{tcolorbox}[borderline west={3pt}{0pt}{shadecolor}, frame hidden, interior hidden, breakable, boxrule=0pt, sharp corners, enhanced]}{\end{tcolorbox}}\fi

\renewcommand*\contentsname{Table of contents}
{
\hypersetup{linkcolor=}
\setcounter{tocdepth}{2}
\tableofcontents
}
\bookmarksetup{startatroot}

\hypertarget{preface}{%
\chapter*{Preface}\label{preface}}
\addcontentsline{toc}{chapter}{Preface}

\markboth{Preface}{Preface}

\hfill\break
\hfill\break
\hfill\break
\hfill\break
\hfill\break
\hfill\break

\emph{Science is built up with facts, as a house is with stones. But a
collection of facts is no more a science than a heap of stones is a
house.} ~~~~{(H. Poincaré)}

**WARNING: THIS IS A WORKING DRAFT. TEXT WILL CHANGE A LOT. MANY
PASSAGES ARE JUST TEMPORARY, INCOHERENT, AND DISJOINTED.

To be written.

\begin{itemize}
\item
  Difference between car mechanic and automotive engineer
\item
  ``Engineering based on data'' is just how engineering and science in
  general have been in the past 400 years or so. Nothing new there.
\item
  The amount of available data has changed. This may lead to a reduction
  -- or in some cases an increase -- in uncertainty, and therefore to
  different solutions.
\item
  Luckily the fundamental theory to deal with large amount of data is
  exactly the same to deal with small amounts. So the foundations
  haven't changed.
\end{itemize}

This course makes you acquainted with the foundations.

\bookmarksetup{startatroot}

\hypertarget{intro}{%
\chapter{Introduction}\label{intro}}

To be written: motivation and structure of this course.

\bookmarksetup{startatroot}

\hypertarget{framework}{%
\chapter{Framework}\label{framework}}

\providecommand{\ul}{\uline}
\renewcommand*{\|}[1][]{\nonscript\:#1\vert\nonscript\:\mathopen{}}
\providecommand*{\pr}[1]{\textsf{\small`#1'}}
\renewcommand*{\pr}[1]{\textsf{\small`#1'}}
\providecommand*{\prq}[1]{\textsf{\small #1}}
\renewcommand*{\prq}[1]{\textsf{\small #1}}
\providecommand{\se}[1]{\mathsfit{#1}}
\renewcommand{\se}[1]{\mathsfit{#1}}
\providecommand{\p}{\mathrm{p}}
\renewcommand{\p}{\mathrm{p}}
\renewcommand{\P}{\mathrm{P}}
\definecolor{quarto-callout-note-color}{HTML}{4477AA}
\definecolor{quarto-callout-note-color-frame}{HTML}{4477AA}
\definecolor{quarto-callout-important-color}{HTML}{AA3377}
\definecolor{quarto-callout-important-color-frame}{HTML}{AA3377}
\definecolor{quarto-callout-warning-color}{HTML}{EE6677}
\definecolor{quarto-callout-warning-color-frame}{HTML}{EE6677}
\definecolor{quarto-callout-tip-color}{HTML}{228833}
\definecolor{quarto-callout-tip-color-frame}{HTML}{228833}
\definecolor{quarto-callout-caution-color}{HTML}{CCBB44}
\definecolor{quarto-callout-caution-color-frame}{HTML}{CCBB44}

Every data-driven engineering problem is unique. But there are also
similarities among all engineering problems. We are going to learn a
framework that allows us to frame and work out some important aspects of
any data-driven engineering problem, and of any sub-problems into which
a problem can be broken down. This framework is build on notions and on
a set of principles that help us analyse the problem. This set of
principles is important because it mathematically guarantees an optimal
solution to the problem -- within the goals, means, and data into which
we framed the problem.

\hypertarget{our-goal-not-success-but-optimality}{%
\section{Our goal: not ``success'', but
optimality}\label{our-goal-not-success-but-optimality}}

What can we demand of a method for facing engineering problems?

A typical and important aspect in any engineering problem is that there
are several possible decisions, or courses of actions, available. The
question is which one to choose. Making a particular decision will lead
to some consequences, which could get us close to the desired goal but
also lead to something else, possibly undesirable. Making a decision is
often difficult because \textbf{its consequences are not known with
certainty, given the information and data available} in the problem. We
may lack information and data about past or present details, about
future events and responses, and so on. Yet a decision has to made
nevertheless. This is what we call a {\textbf{decision problem under
uncertainty}} or {\textbf{under risk}}, or simply a ``decision problem''
for short.

By definition, in a decision problem under uncertainty there is
generally no method to \emph{determine} the decision that will surely
lead to the desired consequence (if such a method existed, then the
problem would not be one of deciding under uncertainty). Therefore, if
there is a method to deal with decision problems, its goal cannot be the
determination of the \emph{successful} decision. This also means that a
priori we cannot blame an engineer for making an unsuccessful decision
in a situation of uncertainty.

Imagine two persons, Henry and Tina, who must bet on ``heads'' or
``tails'' under the following conditions (and who otherwise don't get
any special thrill from betting):

\begin{itemize}
\tightlist
\item
  if the bet is ``heads'' and the coin lands ``heads'', the person wins
  a \emph{small} amount of money; but if it lands ``tails'', they lose a
  \emph{large} amount of money.
\item
  if the bet is ``tails'' and the coin lands ``tails'', the person
  \emph{wins} a small amount of money; if it lands ``heads'', they lose
  the same \emph{small} amount of money.
\end{itemize}

Henry chooses the first bet, on ``heads''. Tina chooses the second bet,
on ``tails''. The coin comes down ``heads''. So Henry wins the small
amount of money, while Tina loses it small amount. What would we say
about their decisions?

Henry's decision was lucky, and yet \emph{irrational}: he risked losing
much more money than in the second bet, without any possibility of
winning more. Tina's decision was unlucky, and yet \emph{rational}: the
possibility and amount of winning was the same in the two bets, and she
chose the bet with the least amount of loss. We expect that any person
making Henry's decision in similar, future bets will eventually lose
more money than any person making Tina's decision.

This example shows two points. First, ``success'' is generally not a
good criterion to judge a decision under uncertainty. Second, even if
there is no method to determine which decision is successful, there
seems to be a method to determine which decision is rational or
{\textbf{optimal}}, given the particular gains, losses, and
uncertainties involved in the decision problem.

Such a method indeed does exist, and its explanation and use will be the
core of the present notes.

Let us emphasize, however, that we are not giving up on ``success'', or
trading it for ``optimality''. Indeed we'll find that \textbf{the method
automatically leads to the \emph{successful} decision} in problems where
uncertainty is not present or is irrelevant. It's a win-win. It's
important to keep this point in mind:

\begin{figure*}

\begin{tcolorbox}[enhanced jigsaw, bottomrule=.15mm, leftrule=.75mm, opacitybacktitle=0.6, breakable, toptitle=1mm, coltitle=black, title={}, rightrule=.15mm, left=2mm, colframe=quarto-callout-note-color-frame, bottomtitle=1mm, arc=.35mm, titlerule=0mm, toprule=.15mm, opacityback=0, colback=white, colbacktitle=quarto-callout-note-color!10!white]

{Aiming to find the solutions that are \emph{successful} can make us
\emph{fail} to find those that are optimal when the successful ones
cannot be determined.}

{Aiming to find the solutions that are \emph{optimal} makes us
automatically find those that are \emph{successful} when those can be
determined.}

\end{tcolorbox}

\end{figure*}

We shall later witness this fact with our own eyes, and will take it up
again in the discussion of some misleading techniques to evaluate
machine-learning algorithms.

\hfill\break

There are other important aspects in engineering problems, besides the
one of making decisions under uncertainty. For instance the
\emph{discovery} or the \emph{invention} of new technologies and
solutions. These aspects can barely be planned or decided; but their
fruits, once available, should be handled and used optimally -- thus
leading to a decision problem.

Artificial intelligence is proving to be a valuable aid in these more
creative aspects too. This kind of use of AI is outside the scope of the
present notes. Some aspects of this creativity-assisting use, however,
do fall within the domain of the present notes. A pattern-searching
algorithm, for example, can be optimized by means of the method we are
going to study.

\hypertarget{decision-theory}{%
\section{Decision Theory}\label{decision-theory}}

We want a method that allows an engineer to make optimal decisions in
uncertain situations, and successful decisions in situations with no
uncertainty. What other kinds of features should such a method have, in
order to be applied to as many kinds of decision problems as possible?

If we find an optimal course of action in regards to some outcome, it
may still happen that the course of action can in practice be realized
in several ways that are equivalent in regard to the outcome, but
inequivalent in regard to time or resources. We thus face a decision
within a decision. In general, a decision problem may involve several
decision sub-problems, in turn involving decision sub-sub-problems, and
so on.

The main engineering goal itself could be to design and build an
automated or AI-based device capable of making an optimal decision in a
specific kind of uncertain situations. Think for instance of an
aeronautic engineer designing an autopilot system.

Therefore, to analyse and tackle this kind of problems we would like to
have a framework with the following features:

\begin{itemize}
\item
  it should tell us what's optimal and, when possible, what's successful
\item
  it should take into consideration choices, consequences, costs and
  gains
\item
  it should be able to deal with uncertainties
\item
  it should be susceptible to recursive or modular application, if
  needed
\item
  it should be suited to being used not only for human decision-makers,
  but also for automated or AI devices.
\end{itemize}

A framework with these features exists: it is {\textbf{Decision
Theory}}.

Decision Theory has a long history, going back to Leibniz in the 1600s
and partly even to Aristotle in the −300s, and appearing in its present
form around 1920--1960. What's remarkable about it is that it is not
only \emph{a} framework, but \emph{the} framework we must use. A
logico-mathematical theorem shows that any framework that does not break
basic optimality and rationality criteria has to be equivalent to
Decision Theory (in other words, it can use different technical
terminology and rewrite mathematical operations in a different way, but
it boils down to the same notions and operations of Decision Theory). So
if you wanted to invent and use another framework, then either (a) it
would lead to some irrational or illogical consequences, or (b) it would
lead to results identical to Decision Theory's. Many frameworks that you
are probably familiar with, such as optimization theory, are just
specific applications or particular cases of Decision Theory.

Decision Theory can be roughly divided into two main parts:
{\textbf{Probability Theory}}, which deals with information, data,
uncertainty, inference; and {\textbf{Utility Theory}}, which deals with
actions, consequences, gain and loss, decisions. We shall get acquainted
with Decision Theory step by step, introducing its main ideas and
notions as they become necessary.

\hypertarget{anatomy-of-a-decision-problem}{%
\section{Anatomy of a decision
problem}\label{anatomy-of-a-decision-problem}}

An extremely important -- and surprisingly often neglected -- first step
in every engineering problem is to define exactly what the problem is.
This means, in particular, to specify unambiguously the goals, the
available data and information, the available decisions or courses of
action, the hypotheses of interest.

Decision theory analyses any problem in terms of nested or sequential
basic decision problems, each of which is framed in terms of these
elements:

\marginnote{\begin{footnotesize}

\begin{tcolorbox}[enhanced jigsaw, bottomrule=.15mm, leftrule=.75mm, opacitybacktitle=0.6, breakable, toptitle=1mm, coltitle=black, title={\faIcon{seedling}}, rightrule=.15mm, left=2mm, colframe=quarto-callout-tip-color-frame, bottomtitle=1mm, arc=.35mm, titlerule=0mm, toprule=.15mm, opacityback=0, colback=white, colbacktitle=quarto-callout-tip-color!10!white]

Remember: What matters is to be able to identify these elements in a
concrete engineering problem, understanding their role. Their technical
names don't matter.

\end{tcolorbox}

\end{footnotesize}}

\begin{itemize}
\item
  {\textbf{Agent}}, and {\textbf{background}} or {\textbf{prior
  information}}: the agent is the person or device that has to make an
  optimal decision. An agent has some specific background information
  and data that are used and taken for granted in the decision-making
  process. Since different agents typically have different background
  information, we shall somehow conflate them.
\item
  {\textbf{Decisions}} or {\textbf{courses of actions}}: the choices
  available to the agent.
\item
  {\textbf{Assumptions}}: data and information that are known, or
  temporarily imagined to be known, to the agent. Assumptions are
  different from background information because the latter is never used
  for hypothetical or counterfactual reasoning -- a difference that will
  become clear shortly.
\item
  {\textbf{Outcomes}}: hypotheses, conjectures, or actual facts that the
  agent wishes to assess; often they depend on the possible decisions.
\item
  {\textbf{Probabilities}}: forecasting the outcomes given the
  assumptions, and the uncertainty of these forecasts.
\item
  {\textbf{Utilities}}: the gains and losses involved in making each
  possible decision.
\end{itemize}

Together with the ``assumptions'' and ``outcomes'' it is also useful to
keep in mind two more, somewhat different elements:

\begin{itemize}
\item
  {\textbf{Knowns}}: the data and information that are actually known to
  the agent.
\item
  {\textbf{Unknowns}}: hypotheses, conjectures, and situations whose
  truth or falsity are actually unknown to the agent.
\end{itemize}

The basic idea is that the agent will {\textbf{infer}} the outcomes
given the assumptions, with some degree of {\textbf{uncertainty}}. From
these inferences it will determine the {\textbf{optimal}} decision.

A basic decision problem and some of its elements can be graphically
represented in a diagram like this:

\begin{figure*}

{\centering \includegraphics[width=1\textwidth,height=\textheight]{index_files/mediabag/decision_tree.pdf}

}

\end{figure*}

It has one \emph{decision node}, usually represented by a square
\faIcon{square}, from which the available decisions depart as lines.
Each decision leads to an \emph{uncertainty node}, usually represented
by a circle \faIcon{circle}, from which the possible outcomes depart as
lines. Each outcome leads to a particular utility value. The uncertainty
of each outcome is quantified by a probability, which depends on the
assumptions common to the problem and, often, on the decision.

\faIcon{exclamation-circle}~~A priori there isn't any particular
temporal order among decisions, outcomes, and even assumptions. In some
cases an outcome happens after a decision; for instance, you pick an
umbrella, and then it rains. In other cases the outcome already happened
before the decision; for instance, a clinician decides to treat a
patient who might have a disease, but the disease, if present, was
already there before the clinician's decision. The difference between
decisions and outcomes is not one of time, but of control: decisions are
under our control; outcomes are not and are generally uncertain.

\begin{tcolorbox}[enhanced jigsaw, bottomrule=.15mm, leftrule=.75mm, opacitybacktitle=0.6, breakable, toptitle=1mm, coltitle=black, title={Example}, rightrule=.15mm, left=2mm, colframe=quarto-callout-note-color-frame, bottomtitle=1mm, arc=.35mm, titlerule=0mm, toprule=.15mm, opacityback=0, colback=white, colbacktitle=quarto-callout-note-color!10!white]

\begin{quote}
A particular kind of electronic component is produced on an assembly
line. At the end of the line, an automated inspection device makes some
tests on every newly produced component. The tests give an uncertain
forecast of whether the component would fail within less than a year of
use, or after a year.

Depending on the test results, the automated inspector approves the
component, or discards it. An approved component is sold, leading to
some net monetary gain if it works for at least a year; but leading to a
net loss if it fails within a year, owing to damage and warranty
refunds. A discarded component doesn't lead to any gain or loss.\\
\end{quote}

A decision problem is involved in this process: one for every new
component that arrives at the automated inspector. The elements of the
problem can be identified as follows:

\begin{itemize}
\tightlist
\item
  \emph{Agent} and \emph{background information}: the automated
  inspector (and indirectly the engineer who designed and programmed
  it), and its builtin knowledge base.
\item
  \emph{Decisions}: approve the new electronic component, or discard it.
\item
  \emph{Assumptions}: the values obtained from the tests.
\item
  \emph{Outcomes}: three possible ones: (1) failure of the component
  within a year, (2) survival of the component for longer than a year,
  (3) destruction of the component. Either of the first two outcomes can
  happen if the component is sold; the third outcome happens if the
  component is discarded.
\item
  \emph{Probabilities}: the quantified forecast of failure within a year
  if the component were sold. If the component is discarded, there's
  nothing to forecast.
\item
  \emph{Utilities}: The gains or losses to be had if the component is
  sold and doesn't fail within a year, if it's sold and fails, and if
  it's discarded.
\end{itemize}

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, bottomrule=.15mm, leftrule=.75mm, opacitybacktitle=0.6, breakable, toptitle=1mm, coltitle=black, title={Exercise}, rightrule=.15mm, left=2mm, colframe=quarto-callout-caution-color-frame, bottomtitle=1mm, arc=.35mm, titlerule=0mm, toprule=.15mm, opacityback=0, colback=white, colbacktitle=quarto-callout-caution-color!10!white]

Suppose that a new component arrives at the inspector. Tests give a
\texttt{10\%} probability of failure within a year, and \texttt{90\%}
otherwise, if the component is approved. If the component is approved,
it will be sold for a net gain of \texttt{1\$} if it works for a year,
but for a net \emph{loss} of \texttt{5\$} if it fails instead. If the
component is discarded, there won't be any net gain or loss.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Sketch the diagram for this basic decision problem.
\item
  Should the automated inspector \texttt{approve} or \texttt{discard}
  this new component? Try to make a decision on intuitive grounds,
  trying to interpret what the probabilities and utilities given above
  could mean. What kind of background information did you use?
\end{enumerate}

\end{tcolorbox}

Some of the decision-problem elements listed above may themselves need
to be analysed by a decision sub-problem. For instance, the utilities
could depend on uncertain factors: thus we have a decision sub-problem
to determine the optimal values to be used for the utilities of the main
problem. This is an example of the modular character of decision theory.

The elements above must be identified unambiguously in every decision
problem. The analysis into these elements greatly helps in making the
problem and its solution well-defined. Suppose someone (probably a
politician) says: ``We must solve the energy crisis by reducing energy
consumption or producing more energy''. This person has effectively said
\emph{nothing whatsoever}. By definition the ``energy crisis'' is the
problem that energy production doesn't meet demand. So this person has
only said ``we would like the problem to be solved'', without specifying
any solution. A decision-theory approach to this problem requires us to
specify which concrete courses of action should be taken for reducing
consumption or increasing productions, and what their costs, gains, and
probable outcomes would be.

\marginnote{\begin{footnotesize}

\begin{tcolorbox}[enhanced jigsaw, bottomrule=.15mm, leftrule=.75mm, opacitybacktitle=0.6, breakable, toptitle=1mm, coltitle=black, title={\faIcon{book-open} For the curious}, rightrule=.15mm, left=2mm, colframe=quarto-callout-tip-color-frame, bottomtitle=1mm, arc=.35mm, titlerule=0mm, toprule=.15mm, opacityback=0, colback=white, colbacktitle=quarto-callout-tip-color!10!white]

See MacKay's options-vs-costs rational analysis in
\href{https://www.withouthotair.com}{Sustainable Energy -- without the
hot air}

\end{tcolorbox}

\end{footnotesize}}

An advantage of decision theory is that its application \emph{forces} us
to make sense of an engineering problem. A useful procedure is to
formulate the general problem in terms of the elements above,
identifying them clearly. If the definition of any of the terms involves
uncertainty of further decisions, then we analyse it in turn as a
decision sub-problem, and so on.

\bookmarksetup{startatroot}

\hypertarget{first-building-blocks}{%
\chapter{First building blocks}\label{first-building-blocks}}

\providecommand{\ul}{\uline}
\renewcommand*{\|}[1][]{\nonscript\:#1\vert\nonscript\:\mathopen{}}
\providecommand*{\pr}[1]{\textsf{\small`#1'}}
\renewcommand*{\pr}[1]{\textsf{\small`#1'}}
\providecommand*{\prq}[1]{\textsf{\small #1}}
\renewcommand*{\prq}[1]{\textsf{\small #1}}
\providecommand{\se}[1]{\mathsfit{#1}}
\renewcommand{\se}[1]{\mathsfit{#1}}
\providecommand{\p}{\mathrm{p}}
\renewcommand{\p}{\mathrm{p}}
\renewcommand{\P}{\mathrm{P}}
\definecolor{quarto-callout-note-color}{HTML}{4477AA}
\definecolor{quarto-callout-note-color-frame}{HTML}{4477AA}
\definecolor{quarto-callout-important-color}{HTML}{AA3377}
\definecolor{quarto-callout-important-color-frame}{HTML}{AA3377}
\definecolor{quarto-callout-warning-color}{HTML}{EE6677}
\definecolor{quarto-callout-warning-color-frame}{HTML}{EE6677}
\definecolor{quarto-callout-tip-color}{HTML}{228833}
\definecolor{quarto-callout-tip-color-frame}{HTML}{228833}
\definecolor{quarto-callout-caution-color}{HTML}{CCBB44}
\definecolor{quarto-callout-caution-color-frame}{HTML}{CCBB44}

We shall first discuss how to represent and work with the \emph{agent}
and \emph{background information}, \emph{assumptions}, \emph{outcomes},
\emph{probability} elements, leaving the \emph{decisions} and
\emph{utilities} to later.

\hypertarget{agents}{%
\section{Agents}\label{agents}}

The agent is the person or device that has to make a choice between
different decisions. An agent possesses a specific set of background
information and data, a specific set of available decisions, and can
incur specific gains or losses dependent on the outcomes of the
available decisions.

\marginnote{\begin{footnotesize}

We'll use the neutral pronouns \emph{it}/\emph{its} when referring to an
agent, since an agent could be a person or a machine.

\end{footnotesize}}

It is important to identify the agent or agents involved in a problem,
because each one will generally have different data, or different
available decisions, or different gains and losses. A person buying an
insurance policy from an insurance company is an example of decision
problem with two agents, the person and the company, that have roughly
the same data and a common decision (buy-sell) that is optimal for both.
The optimality comes from the fact that the two agents have very
different gains and losses for their various decisions.

\begin{tcolorbox}[enhanced jigsaw, bottomrule=.15mm, leftrule=.75mm, opacitybacktitle=0.6, breakable, toptitle=1mm, coltitle=black, title={\faIcon{book-open} Reading}, rightrule=.15mm, left=2mm, colframe=quarto-callout-caution-color-frame, bottomtitle=1mm, arc=.35mm, titlerule=0mm, toprule=.15mm, opacityback=0, colback=white, colbacktitle=quarto-callout-caution-color!10!white]

§~1.1.4 in
\href{https://hvl.instructure.com/courses/25074/modules/items/660089}{\emph{Artificial
Intelligence}}

\end{tcolorbox}

\hypertarget{notation}{%
\subsection{Notation}\label{notation}}

When necessary, agents are typically denoted by capital letters:
{\(A, B,\dotsc\).} But we'll rarely need symbols for them.

\hypertarget{assumptions-outcomes-knowns-unknowns}{%
\section{Assumptions \& outcomes, knowns \&
unknowns}\label{assumptions-outcomes-knowns-unknowns}}

\hypertarget{assumptions}{%
\subsection{Assumptions}\label{assumptions}}

The ``assumptions'' often include all or part of the data and
information that the agent knows. There is a difference between
``assumptions'' and ``knowns'', however. In approaching a decision
problem, and especially when considering decision sub-problems of a
larger problem, the agent must often make \textbf{hypothetical} or
\textbf{counterfactual} reasonings.

Consider for instance an aeronautics problem where it must be decided
whether to replace the fuel currently employed in a particular aircraft
model, with a newly produced fuel type. To assess the outcome of
employing the new fuel, the engineer must momentarily imagine that the
new fuel is actually used and then assess thermodynamic, environmental,
and economic outcomes of this imagined situation. This is an example of
\emph{hypothetical reasoning}. Hypothetical reasoning is sometimes
assisted by performing experiments in restricted and controlled
conditions, in which the new fuel is really used. Such supporting
experiments, however, may not be viable, and in any case they are not
full reflections of the hypothetical situation.

The engineer may also have data from another, smaller aircraft model in
which the new fuel was ultimately \emph{not} used, and may try to assess
what the outcomes of the new fuel would have been \emph{if it had been
replaced} in that model, maybe because they are easier to assess in that
case. This is an example of \emph{counterfactual reasoning}.

In either instance, the engineer sets up a decision problem in which the
assumptions consist of a combination of real data and of a situation
that in the hypotetical case is only imagined, and in the counterfactual
case never happened. Both kinds of reasoning are staples of scientific
research.

\hypertarget{outcomes}{%
\subsection{Outcomes}\label{outcomes}}

The ``outcomes'' often include all or part of the hypotheses or
conjectures whose truths are unknown to the agent and that the agent
would like to assess. But outcomes may also include known data.
Similarly to ``assumptions'' and ``knowns'', there's a difference
between ``outcomes'' and ``unknowns''.

Consider a data engineer testing, in controlled conditions, the
responses of a new machine-learning algorithms. This is an example of
decision problem about a decision agent. The algorithm infers the truth
of a particular outcome. In the test, this truth is unknown to the
algorithm itself, but it is known to the engineer. More generally, we
shall see that an agent may have to assess the truth of a known outcome,
given a unknown assumption, as a temporary step in a more general
inference.

\hypertarget{sentences}{%
\section{Sentences}\label{sentences}}

\hypertarget{how-to-represent-assumptions-outcomes-decisions}{%
\subsection{How to represent assumptions, outcomes,
decisions?}\label{how-to-represent-assumptions-outcomes-decisions}}

Is there a flexible and general way of representing assumptions,
outcomes, knowns, unknowns, data, information, hypotheses; and, later,
also outcomes and decisions?

When speaking of ``data'', what comes to mind to many people is
basically numbers or collections of numbers. So numbers could perhaps be
used to representing assumptions etc. This option turns out to be too
limiting, however.

I give you this number: {\(8\),} saying that it is ``data''. But what is
it about? As a decision agent, you can hardly call this number a piece
of information, because you have no clue what to do with it. Instead, if
I tell you:
``\emph{\href{https://solarsystem.nasa.gov/planets/overview}{The number
of official planets in the solar system is 8}}'', then we can say that
I've given you data. So ``data'' is not just numbers: a number is not
``data'' unless there's some verbal, non-numeric context accompanying it
-- even if this context is only implicitly understood. Note that
representing this meta-data information as numbers only shifts the
problem one level up: we would need auxiliary verbal context explaining
what the meta-data numbers are about.

Data can, moreover, also be completely non-numeric. A clinician saying
``\emph{The patient has fully recovered from the disease}'' (we imagine
to know who's the patient and what was the disease) is giving us a piece
of information that we could further use, for instance, to make
prognoses about other, similar patients. The clinician's statement
surely is ``data'', but essentially non-numeric data. In some situations
we can represent it as ``1'', while ``0'' would represent ``not
recovered''; yet the opposite convention could also be used, showing
that these numbers have really nothing to do with the clinician's data.

But the examples above actually reveal the answer to our needs. In the
examples we expressed the data by means of {\textbf{sentences}}. Clearly
any piece of information, hypothesis, outcome, decision can be expressed
by a sentence. We shall therefore use sentences, also called
\emph{propositions} or \emph{statements}\footnote{These three terms are
  not always equivalent in Formal Logic, but here we'll use them as
  synonyms.}, to represent and communicate assumptions, outcomes,
knowns, unknowns, data, information, hypotheses, and decisions. In some
cases we can of course summarize a sentence by a number, as a shorthand,
when the full meaning of the sentence is understood.

But \emph{what is a sentence}? The everyday meaning of this word will
work for us, even though there is still a lot of research in logic an
artificial intelligence on how to define and use sentences. We shall
adopt this useful definition:

\marginnote{\begin{footnotesize}

\begin{tcolorbox}[enhanced jigsaw, bottomrule=.15mm, leftrule=.75mm, opacitybacktitle=0.6, breakable, toptitle=1mm, coltitle=black, title={\faIcon{book-open} For the curious
\href{https://plato.stanford.edu/archives/win2020/entries/propositions}{Propositions}}, rightrule=.15mm, left=2mm, colframe=quarto-callout-tip-color-frame, bottomtitle=1mm, arc=.35mm, titlerule=0mm, toprule=.15mm, opacityback=0, colback=white, colbacktitle=quarto-callout-tip-color!10!white]

\end{tcolorbox}

\end{footnotesize}}

\begin{tcolorbox}[enhanced jigsaw, bottomrule=.15mm, leftrule=.75mm, opacitybacktitle=0.6, breakable, toptitle=1mm, coltitle=black, title={}, rightrule=.15mm, left=2mm, colframe=quarto-callout-note-color-frame, bottomtitle=1mm, arc=.35mm, titlerule=0mm, toprule=.15mm, opacityback=0, colback=white, colbacktitle=quarto-callout-note-color!10!white]

{A ``sentence'' is a verbal message for which we can determine whether
it is \texttt{true} or \texttt{false}, at least in principle and in such
a way that all interested receivers of the message would agree.}

\end{tcolorbox}

For instance, in most engineering contexts the phrase ``This valve will
operate for at least two months'' is a sentence; whereas the phrase
``Apples are much tastier than pears'' is not, because it's a matter of
personal taste -- there's no objective criterion to determine its truth
or falsity. However, the phrase ``Rita finds apples tastier than pears''
could be a sentence.

Note that a sentence can contain numbers, and even pictures and graphs:
this possibility is not excluded from the definition above.

The use of sentences in our framework has important practical
consequences:

\begin{itemize}
\item
  \textbf{Clarity, analysis, goal-orientation}. A data engineer must
  acquire information and convey information. Acquiring information is
  not simply making some measurement or counting something: the engineer
  must understand \emph{what} is being measured and \emph{why}. If data
  is gathered from third parties, the engineer must ask what exactly the
  data mean and how they were acquired. In designing and engineering a
  solution, it is important to understand what information or outcomes
  the end user exactly wants. A data engineer will often ask ``wait,
  what do you mean by that?''; this question is not just an unofficial
  parenthesis in the official data-transfer workflow between the
  engineer and someone else. It is an integral part of that workflow; it
  means that the data has not been completely transferred yet.
\item
  \textbf{Artificial Intelligence}. Sentences are the central components
  of knowledge representation and inference in artificial-intelligence
  agents.
\end{itemize}

\begin{tcolorbox}[enhanced jigsaw, bottomrule=.15mm, leftrule=.75mm, opacitybacktitle=0.6, breakable, toptitle=1mm, coltitle=black, title={\faIcon{book-open} Reading}, rightrule=.15mm, left=2mm, colframe=quarto-callout-caution-color-frame, bottomtitle=1mm, arc=.35mm, titlerule=0mm, toprule=.15mm, opacityback=0, colback=white, colbacktitle=quarto-callout-caution-color!10!white]

§~7.1 in
\href{https://hvl.instructure.com/courses/25074/modules/items/660089}{\emph{Artificial
Intelligence}}

\end{tcolorbox}

\hypertarget{notation-1}{%
\subsubsection{Notation}\label{notation-1}}

We'll denote sentences by sans-serif italic letters:
\(\mathsfit{A},\mathsfit{B},\mathsfit{a},\mathsfit{b},\dotsc\) For
example, \[
\mathsfit{O} \coloneqq \textsf{\small`The power output is 100 W'}
\] means that the symbol \(\mathsfit{O}\) stands for the sentence above.
Often we shall simply write sentences in abbreviated form, when their
full meaning is understood from the context; for example
{``\(O = 100\,\mathrm{W}\)''} or even just {``\(100\,\mathrm{W}\)''} for
the sentence above.

We'll next see how more complex sentences are built from simpler ones.
No matter whether complex or simple, any sentence can be represented by
symbols like the ones above.

\hypertarget{combining-sentences}{%
\section{Combining sentences}\label{combining-sentences}}

\hypertarget{basic-sentences}{%
\subsection{Basic sentences}\label{basic-sentences}}

In analysing the assumptions and outcomes of a decision problem it is
convenient to find a collection of {\textbf{basic sentences}}\footnote{A
  more technical term is \emph{atomic sentences}.} out of which all
other sentences of interest can be constructed. Often these basic
sentences represent elementary pieces of information in the problem.

Consider for instance the following sentence which could appear in our
earlier assembly-line problem:

\begin{quote}
``The electronic component is still whole after the shock test and the
subsequent heating test. The voltage reported in the power test is
either 90\,mV or 110\,mV.''
\end{quote}

In our example the statement above represents data, that is, it's the
description of a factual situation. But keep in mind that in a different
problem -- say, one where it need to be assessed whether the component
is still whole -- the same statement could represent a hypothesis, that
is, one possible state of affairs among other possible ones.

In the statement above we can identify at least four basic sentences,
which we denote by convenient symbols: \begin{align*}
\mathsfit{s} &\coloneqq \textsf{\small`The component is whole after the shock test'}
\\
\mathsfit{h} &\coloneqq \textsf{\small`The component is whole after the heating test'}
\\
\mathsfit{v}_{90} &\coloneqq \textsf{\small`The power-test voltage reading is 90\,mV'}
\\
\mathsfit{v}_{110} &\coloneqq \textsf{\small`The power-test voltage reading is 110\,mV'}
\end{align*}

The decision problem may actually require more basic sentences than just
these. For instance, it might become necessary to consider basic
sentences with other values for the reported voltage, such as
\[\begin{aligned}
\mathsfit{v}_{110} &\coloneqq \textsf{\small`The power-test voltage reading is 100\,mV'}
\\
\mathsfit{v}_{80} &\coloneqq \textsf{\small`The power-test voltage reading is 80\,mV'}
\end{aligned}\] and so on.

There may also be other basic sentences coming from data or hypotheses
that aren't stated explicitly because obvious. Yet they may have to be
spelled out. An example in our decision problem is the sentence \[
\textsf{\small`The electronic component cannot be broken after the shock test and whole after the subsequent heating test'}
\] which must necessarily be true for physical reasons.

\hypertarget{connectives}{%
\subsection{Connectives}\label{connectives}}

How do we construct the initial data sentence, and more complex
sentences out of simpler ones in general?

We consider one way or operation to change a sentence into another
related to it, and two ways or operations to combine two or more
sentences together. These operations are called {\textbf{connectives}}.
Our natural language offer many more operations to combine sentences,
but these three turn out to be all we need in virtually all engineering
problems. The three connectives and their symbols are:

\begin{description}
\tightlist
\item[{Not:~~\(\lnot\)}]
for example, \[
\lnot \mathsfit{s} = \textsf{\small`The component is broken after the shock test'}
\]
\item[{And:~~\(\land\)}]
for example, \[
\mathsfit{s} \land \mathsfit{h} = \textsf{\small`The component is whole after the shock and heating tests'}
\]
\item[{Or:~~\(\lor\)}]
for example, \[
\mathsfit{v}_{90} \lor \mathsfit{v}_{110} = \textsf{\small`The power-test voltage reading is 90\,mV, or 110\,mV, or both'}
\]
\end{description}

\hfill\break

The connectives can be applied multiple times, to form increasingly
complex sentences.

\faIcon{exclamation-circle}~~Note some important subtleties of the
connectives:

\begin{itemize}
\item
  There is no strict correspondence between the words ``not'', ``and'',
  ``or'' in natural language and the three connectives. For instance the
  \texttt{and} connective could correspond to the words ``but'' or
  ``whereas'', or just to a comma ``\,,\,''.
\item
  \texttt{Not} doesn't mean some kind of complementary quality, but only
  the negation. For
  instance,~~\(\lnot\textsf{\small`The chair is black'}\)~~does not
  mean~~{\(\textsf{\small`The chair is white'}\)\,,}~~ although in some
  situations these two sentences could amount to the same thing.
\item
  It's best to always declare explicitly what the \texttt{not} of a
  sentence concretely means. In our example, we
  take~~\(\lnot\textsf{\small`The component is whole'}\)~~to
  mean~~{\(\textsf{\small`The component is broken'}\)\,.}~~But in other
  examples the negation of ``being whole'' could comprise several
  different conditions. A good guideline is to always state the
  \texttt{not} of a sentence in \emph{positive} terms.
\item
  \texttt{Or} does not exclude that both the sentences it connects can
  be true. So in our
  example~~\(\mathsfit{v}_{90} \lor \mathsfit{v}_{110}\)~~does not
  exclude, a priori, that the reported voltage could be both 90\,mV and
  110\,mV. (There is a connective for that: ``exclusive-or'', but it can
  be constructed out of the three we already have.)
\end{itemize}

From the last remark we see that the sentence \[
\textsf{\small`The power-test voltage reading is 90\,mV or 110\,mV'}
\] does \emph{not} correspond to
~~{\(\mathsfit{v}_{90} \lor \mathsfit{v}_{110}\)\,.}~~It is implicitly
clear that a voltage reading cannot yield two different values at the
same time. Convince yourself that the correct way to write that sentence
is this: \[
(\mathsfit{v}_{90} \lor \mathsfit{v}_{110})
\land
\lnot(\mathsfit{v}_{90} \land \mathsfit{v}_{110})
\]

Finally, the full data statement of our present example can be written
in symbols as follows: \[
\mathsfit{s} \land \mathsfit{h} \land
(\mathsfit{v}_{90} \lor \mathsfit{v}_{110})
\land
\lnot(\mathsfit{v}_{90} \land \mathsfit{v}_{110})
\]

\hypertarget{distinguishing-assumptions-and-outcomes}{%
\section{Distinguishing assumptions and
outcomes}\label{distinguishing-assumptions-and-outcomes}}

Now we know how to represent arbitrarily complex sentences and express
them in symbols. Let's introduce a way to clearly distinguish sentences
that constitute the \emph{assumptions} from those that constitute the
\emph{outcome} in a basic decision problem. In our assembly-line
example, suppose that assumptions are the statement discussed in the
previous section. The outcome to be inferred is expressed by this
sentence: \[
\mathsfit{f} \coloneqq \textsf{\small`The component will fail within a year'}
\]

To distinguish assumptions and outcomes we can simply use a vertical
bar,\footnote{Notation in formal logic uses the symbols~~{'' \(\models\)
  ''}~~or~~{``\,\(\vdash\)\,'',}~~and writes assumptions on the
  \emph{left}, outcomes on the \emph{right}. We use the notation used in
  probability logic.}
like~~{``\(\color[RGB]{68,119,170}\pmb{\nonscript\:\big\vert\nonscript\:\mathopen{}}\)''~:}

\begin{itemize}
\tightlist
\item
  on its \emph{left} side we write the sentence representing the
  \emph{outcome},
\item
  on its \emph{right} side we write the sentences that make up our
  \emph{assumptions}, \texttt{and}-ed together:
\end{itemize}

\[
\textit{\small outcome} \pmb{\nonscript\:\big\vert\nonscript\:\mathopen{}} \textit{\small assumptions}
\]

So in our example we write: \[
f \nonscript\:\Big\vert\nonscript\:\mathopen{}
\mathsfit{s} \land \mathsfit{h} \land
(\mathsfit{v}_{90} \lor \mathsfit{v}_{110})
\land
\lnot(\mathsfit{v}_{90} \land \mathsfit{v}_{110})
\]

The collection of assumptions on the right side of the bar
{``\(\pmb{\nonscript\:\big\vert\nonscript\:\mathopen{}}\)''} is called
the {\textbf{conditional}}. The expression above is read\\
{``\(\mathsfit{c}_{2,90}\)~~ \emph{given}~~
\(\mathsfit{t}_{1,50} \land \mathsfit{t}_{2,50} \land\dotsb\)''}\\
or\\
{``\(\mathsfit{c}_{2,90}\)~~ \emph{conditional on}~~
\(\mathsfit{t}_{1,50} \land \mathsfit{t}_{2,50} \land\dotsb\)''.}

\hfill\break

We are now equipped with all the notions and symbolic notation to deal
with our first concrete goal: drawing uncertain inferences.

\hypertarget{inferences-certain-and-uncertain}{%
\section{Inferences: certain and
uncertain}\label{inferences-certain-and-uncertain}}

In a decision problem we have a set of different outcomes that we want
to assess given the same assumptions: \[\begin{aligned}
\textit{\small outcome\,1} &\pmb{\nonscript\:\big\vert\nonscript\:\mathopen{}} \textit{\small assumptions}
\\
\textit{\small outcome\,2} &\pmb{\nonscript\:\big\vert\nonscript\:\mathopen{}} \textit{\small assumptions}
\\
\textit{\small outcome\,3} &\pmb{\nonscript\:\big\vert\nonscript\:\mathopen{}} \textit{\small assumptions}
\\
\dotso&
\end{aligned}\]

The first goal in a decision problem is to assess these outcomes. What
do we mean by ``assess''? We cannot demand that the truth or falsity of
the outcomes be determined with certainty.

\bookmarksetup{startatroot}

\hypertarget{inference}{%
\chapter{Inference}\label{inference}}

\providecommand{\ul}{\uline}
\renewcommand*{\|}[1][]{\nonscript\:#1\vert\nonscript\:\mathopen{}}
\providecommand*{\pr}[1]{\textsf{\small`#1'}}
\renewcommand*{\pr}[1]{\textsf{\small`#1'}}
\providecommand*{\prq}[1]{\textsf{\small #1}}
\renewcommand*{\prq}[1]{\textsf{\small #1}}
\providecommand{\se}[1]{\mathsfit{#1}}
\renewcommand{\se}[1]{\mathsfit{#1}}
\providecommand{\p}{\mathrm{p}}
\renewcommand{\p}{\mathrm{p}}
\renewcommand{\P}{\mathrm{P}}
\definecolor{quarto-callout-note-color}{HTML}{4477AA}
\definecolor{quarto-callout-note-color-frame}{HTML}{4477AA}
\definecolor{quarto-callout-important-color}{HTML}{AA3377}
\definecolor{quarto-callout-important-color-frame}{HTML}{AA3377}
\definecolor{quarto-callout-warning-color}{HTML}{EE6677}
\definecolor{quarto-callout-warning-color-frame}{HTML}{EE6677}
\definecolor{quarto-callout-tip-color}{HTML}{228833}
\definecolor{quarto-callout-tip-color-frame}{HTML}{228833}
\definecolor{quarto-callout-caution-color}{HTML}{CCBB44}
\definecolor{quarto-callout-caution-color-frame}{HTML}{CCBB44}

\hypertarget{what-is-inference}{%
\section{What is inference?}\label{what-is-inference}}

The first core problem in all data-driven engineering applications --
and in daily life too -- is to \emph{draw inferences}, that is, acquire
information. We may wish to acquire information out of simple curiosity,
or for some specific engineering reason or goal, as we'll discuss later.
Examples:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  We'd like to know whether it'll rain today, so we can decide whether
  to get an umbrella or rain clothes.
\end{enumerate}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\item
  A clinician would like to know which disease affects a patient, so as
  to decide for the optimal treatment.
\item
  The X-player of this game of Xs~\&~Os:
  \includegraphics[width=0.05\textwidth,height=\textheight]{XsOs.png}
  needs to know where put the next {\textbf{X}} in order to win.
\item
  The computer of a self-driving car needs to know whether a particular
  patch of colours in the visual field is a person, so as to slow down
  the car and stop.
\item
  In order to launch a rocket to the Moon, a rocket engineer needs to
  know, within two significant digits,
  \href{http://nasaphysics.cet.edu/escape-velocity.html}{how much is the
  velocity \(\sqrt{2\,G\,M/r\,}\)}, where
  \(G=6.67 \cdot 10^{-11}\,\mathrm{m^3\,s^{-2}\,kg^{-1}}\), and
  \(M = 5.97 \cdot 10^{24}\,\mathrm{kg}\) and
  \(r = 6.37 \cdot 10^{6}\,\mathrm{m}\) are the mass and radius of the
  Earth.
\item
  We'd like to know whether the rolled die will show \faIcon{dice-six},
  so we can win a bet.
\item
  An
  \href{https://aerospaceamerica.aiaa.org/features/a-i-in-the-cockpit}{aircraft's
  autopilot system} needs to predict how much the
  \href{https://www.grc.nasa.gov/www/k-12/VirtualAero/BottleRocket/airplane/roll.html}{aircraft's
  roll} will change by increasing the right wing's
  \href{https://www.grc.nasa.gov/www/k-12/VirtualAero/BottleRocket/airplane/incline.html}{angle
  of attack} by 0.1~rad.
\item
  An archaeologist would like to know whether the fossil bone just dug
  out belonged to a Tyrannosaurus rex.
\item
  An automated system in an assembly line needs to predict whether an
  electric component of a widget will fail within the next two years.
\end{enumerate}

Note how each of these inferences boils down to determining whether some
sentences are true or false. In example 1. we want to know whether the
sentence \(\textsf{\small`It rains today'}\) is true or not. In example
2. the clinician wants to know which of the sentences
\(\textsf{\small`The patient has pneumonia'}\),
\(\textsf{\small`The patient has asthma'}\),
\(\textsf{\small`The patient has bronchitis'}\), and so on, are true
(several can be true at the same time). In example 5. the rocket
engineer wants to know which among the sentences
\(\textsf{\small`The velocity is 0.010\,m/s'}\),
\(\textsf{\small`The velocity is 0.011\,m/s'}\), \ldots,
\(\textsf{\small`The velocity is 130\,m/s'}\), and so on, is true. The
sentences that underlie an inference can be extremely many and complex,
and yet we must have an idea of what they are (otherwise, do we really
know what our inference is about?).

\begin{tcolorbox}[enhanced jigsaw, bottomrule=.15mm, leftrule=.75mm, opacitybacktitle=0.6, breakable, toptitle=1mm, coltitle=black, title={Exercise}, rightrule=.15mm, left=2mm, colframe=quarto-callout-caution-color-frame, bottomtitle=1mm, arc=.35mm, titlerule=0mm, toprule=.15mm, opacityback=0, colback=white, colbacktitle=quarto-callout-caution-color!10!white]

Try to identify which sentences underlie the other example inferences
above.

\end{tcolorbox}

\hypertarget{certain-and-uncertain-inference}{%
\section{Certain and uncertain
inference}\label{certain-and-uncertain-inference}}

The example inferences above present very different levels of
difficulty.

Inferences 3. and 5. are special because they can actually be drawn
\emph{exactly}, that is, we really find out which of their underlying
sentences are true and false. In example 3. it is trivial that putting
the next {\textbf{X}} in the mid-right slot makes the X-player win. In
example 5. a couple of mathematical operations show that the sentence
\(\textsf{\small`The velocity is 11\,km/s'}\) is true. When we can
obtain the data we want from the data we have by using
``only''\footnote{``Only'' in quotation marks because the logical
  analysis and operations leading to the answer can still be
  computationally very expensive.} logic and mathematical operations,
our inference is \emph{certain}, also called a ``deduction''; in these
notes we shall call it a \emph{truth inference}. But every deduction can
be basically drawn by repeatedly applying the rules of logic.

The other example inferences cannot be drawn exactly, in the sense that
we cannot know for sure whether all their underlying sentences are true
or false. But this doesn't mean that we cannot say anything whatsoever.
In example 6. we consider the sentence
\(\textsf{\small`The die shows six pips'}\) to be more likely false than
true. In example 2. the clinician might be quite sure about the disease,
after observing the symptoms. On the other hand, in example 1. we might
really have no clue whether \(\textsf{\small`It rains today'}\) will
turn out to be true or false. These inferences are \emph{uncertain}.
Certain inferences can be considered as a limit case of uncertain ones,
in which the uncertainty vanishes or is extremely small.

To draw certain inferences, we follow the rules of Logic. What rules do
we follow to draw uncertain inferences?

\bookmarksetup{startatroot}

\hypertarget{sec-truth-inference}{%
\chapter{Truth inference}\label{sec-truth-inference}}

\providecommand{\ul}{\uline}
\renewcommand*{\|}[1][]{\nonscript\:#1\vert\nonscript\:\mathopen{}}
\providecommand*{\pr}[1]{\textsf{\small`#1'}}
\renewcommand*{\pr}[1]{\textsf{\small`#1'}}
\providecommand*{\prq}[1]{\textsf{\small #1}}
\renewcommand*{\prq}[1]{\textsf{\small #1}}
\providecommand{\se}[1]{\mathsfit{#1}}
\renewcommand{\se}[1]{\mathsfit{#1}}
\providecommand{\p}{\mathrm{p}}
\renewcommand{\p}{\mathrm{p}}
\renewcommand{\P}{\mathrm{P}}
\definecolor{quarto-callout-note-color}{HTML}{4477AA}
\definecolor{quarto-callout-note-color-frame}{HTML}{4477AA}
\definecolor{quarto-callout-important-color}{HTML}{AA3377}
\definecolor{quarto-callout-important-color-frame}{HTML}{AA3377}
\definecolor{quarto-callout-warning-color}{HTML}{EE6677}
\definecolor{quarto-callout-warning-color-frame}{HTML}{EE6677}
\definecolor{quarto-callout-tip-color}{HTML}{228833}
\definecolor{quarto-callout-tip-color-frame}{HTML}{228833}
\definecolor{quarto-callout-caution-color}{HTML}{CCBB44}
\definecolor{quarto-callout-caution-color-frame}{HTML}{CCBB44}

\hypertarget{building-blocks}{%
\section{Building blocks}\label{building-blocks}}

Consider the following trivial problem. An inspector examines an
electronic component out of a production line. The information available
to the inspector is the following:

\begin{itemize}
\item
  The component can either come from the production line in Oslo, or
  from the one in Rome.
\item
  If the component is defective, it cannot come from Oslo.
\item
  The component is found to be defective.
\end{itemize}

The question is: from which production line does the component come
from?

The answer is obvious: from the Rome line. But how could we draw this
obvious and sure inference? Which rules did we follow? Did we make any
hidden assumptions, or use information that wasn't explicitly mentioned?

Logic is the huge field that formalizes and makes rigorous the rules
that a rational person or an artificial intelligence should use in
drawing sure inferences. We'll get a glimpse of it here, as a trampoline
for jumping towards the more general inferences that we need in
data-driven engineering problems.

\hypertarget{analysis-of-the-problem}{%
\subsection{Analysis of the problem}\label{analysis-of-the-problem}}

Let's write down the basic sentences that constitute our data and the
inferences we want to draw. We identify three basic sentences, which we
can represent by these symbols:

\begin{itemize}
\item
  \(o \coloneqq \textsf{\small`The component comes from the Oslo line'}\)
\item
  \(r \coloneqq \textsf{\small`The component comes from the Rome line'}\)
\item
  \(d \coloneqq \textsf{\small`The component is defective'}\)
\end{itemize}

Obviously the inspector possesses even more information which is
implicitly understood. It's clear, for instance, that the component
cannot come from both Oslo and Rome. Let's denote this information with

\begin{itemize}
\tightlist
\item
  \(I \coloneqq{}\)(a long collection of sentences explaining all other
  implicitly understood information).\\
\end{itemize}

With the sentences above we can express more complex details and
hypotheses appearing in the inspector's problem, in particular:

\begin{itemize}
\item
  \(o \lor r = \textsf{\small`The component comes from either the Oslo line or the Rome line'}\)
\item
  \(\lnot(o \land r) = \textsf{\small`The component cannot come from both the Oslo and the Rome lines'}\)
\item
  \$ \lnot o
  \coloneqq \textsf{\small`The component does not come from the Oslo line'}\$
\end{itemize}

\hypertarget{data-assumptions-desired-conclusions}{%
\subsection{Data, assumptions, desired
conclusions}\label{data-assumptions-desired-conclusions}}

The inspector knows for certain the following facts:

\begin{itemize}
\item
  \(o \lor r\),
  \(\textsf{\small`The component comes from either the Oslo line or the Rome line'}\)
\item
  \(\lnot(o \land r)\),
  \(\textsf{\small`The component cannot come from both the Oslo and the Rome lines'}\)
\item
  \(d\), \(\textsf{\small`The component is defective'}\)
\item
  \(I\), all remaining implicit information
\end{itemize}

We \texttt{and} them all together: \[
d \land (o \lor r) \land \lnot (o \land r) \land I \ .
\]

The inspector knows, moreover, this hypothetical consequence:

\begin{itemize}
\item
  \(\lnot o \nonscript\:\vert\nonscript\:\mathopen{} d \land (o \lor r) \land \lnot (o \land r) \land I\),
  if the component is defective, it cannot come from the Oslo production
  line.
\item
\end{itemize}

\hypertarget{background-information-and-conditional}{%
\section{Background information and
conditional}\label{background-information-and-conditional}}

\hfill\break

\hypertarget{truth-inference-rules}{%
\section{Truth-inference rules}\label{truth-inference-rules}}

Deduction systems in formal logic give us a set of rules for making
correct inferences, that is, for correctly determining whether the
conclusions of interest are true or false. These rules are represented
in a
\href{https://plato.stanford.edu/archives/spr2023/entries/natural-deduction}{wide
variety of ways}, as steps leading from one conclusion to another one.
The picture here on the margin, for instance, shows how a proof of our
inference would look like, using the so-called sequent calculus.

\begin{marginfigure}

{\centering \includegraphics[width=1\textwidth,height=\textheight]{umbrella_inference_sequent.png}

}

\caption{The bottom formula is our conclusion; the formulae above it
represent steps in the proof. Each line denotes the application of an
inference rule. The two formulae with no line above are our two
assumptions.}

\end{marginfigure}

\hfill\break

We can compactly encode all inference rules in the following way. First,
represent \texttt{true} by the number \texttt{1}, and \texttt{false} by
\texttt{0}. Second, symbolically write that conclusion \(C\) is
\texttt{true}, given assumptions \(A\), as follows: \[
\mathrm{T}(C \nonscript\:\vert\nonscript\:\mathopen{} A) = 1 \ .
\] or with \texttt{0} if it's \texttt{false}.

The rules of truth inference are then encoded by the following
equations, which must always hold for any sentences \(A,B,C\), no matter
whether they are basic or complex:

\begin{figure*}

\begin{description}
\tightlist
\item[Rule for ``not'':]
\begin{equation}\protect\hypertarget{eq-t-not}{}{\mathrm{T}(\lnot A \nonscript\:\vert\nonscript\:\mathopen{} B) 
+ \mathrm{T}(A \nonscript\:\vert\nonscript\:\mathopen{} B)
= 1}\label{eq-t-not}\end{equation}
\item[Rule for ``and'':]
\begin{equation}\protect\hypertarget{eq-t-and}{}{
\mathrm{T}(A \land B \nonscript\:\vert\nonscript\:\mathopen{} C) 
= \mathrm{T}(A \nonscript\:\vert\nonscript\:\mathopen{} B \land C) \cdot
\mathrm{T}(B \nonscript\:\vert\nonscript\:\mathopen{} C) 
= \mathrm{T}(B \nonscript\:\vert\nonscript\:\mathopen{} A \land C) \cdot
\mathrm{T}(A \nonscript\:\vert\nonscript\:\mathopen{} C)
}\label{eq-t-and}\end{equation}
\item[Rule for ``or'':]
\begin{equation}\protect\hypertarget{eq-t-or}{}{\mathrm{T}(A \lor B \nonscript\:\vert\nonscript\:\mathopen{} C) 
= \mathrm{T}(A \nonscript\:\vert\nonscript\:\mathopen{} C) +
\mathrm{T}(B \nonscript\:\vert\nonscript\:\mathopen{} C) 
- \mathrm{T}(A \land B \nonscript\:\vert\nonscript\:\mathopen{} C)
}\label{eq-t-or}\end{equation}
\item[Rule of self-consistency:]
\begin{equation}\protect\hypertarget{eq-t-unity}{}{\mathrm{T}(A \nonscript\:\vert\nonscript\:\mathopen{} A \land C) 
= 1
}\label{eq-t-unity}\end{equation}
\end{description}

\end{figure*}

\hfill\break

Let's see how the inference rule (\textbf{?@eq-example-rule}), for
example, is encoded in these equations. The rule starts with saying that
\(a \land b\) is \texttt{true} according to \(D\). This means that
\(\mathrm{T}(a \land b \nonscript\:\vert\nonscript\:\mathopen{} D)=1\).
But, by rule (\ref{eq-t-and}), we must then have
\(\mathrm{T}(b \nonscript\:\vert\nonscript\:\mathopen{} a \land D) \cdot \mathrm{T}(a \nonscript\:\vert\nonscript\:\mathopen{} D) = 1\).
This can only happen if both
\(\mathrm{T}(b \nonscript\:\vert\nonscript\:\mathopen{} a \land D)\) and
\(\mathrm{T}(a \nonscript\:\vert\nonscript\:\mathopen{} D)\) are equal
to \(1\). So we can conclude that
\(\mathrm{T}(a \nonscript\:\vert\nonscript\:\mathopen{} D)=1\), which is
exactly the conclusion under the line in rule
(\textbf{?@eq-example-rule}).

\begin{tcolorbox}[enhanced jigsaw, bottomrule=.15mm, leftrule=.75mm, opacitybacktitle=0.6, breakable, toptitle=1mm, coltitle=black, title={\faIcon{pen} Exercise}, rightrule=.15mm, left=2mm, colframe=quarto-callout-caution-color-frame, bottomtitle=1mm, arc=.35mm, titlerule=0mm, toprule=.15mm, opacityback=0, colback=white, colbacktitle=quarto-callout-caution-color!10!white]

Try to prove our initial inference

\[
\frac{
(b \lor r) \land \lnot (b \land r) \nonscript\:\vert\nonscript\:\mathopen{} D
\qquad
\lnot r \nonscript\:\vert\nonscript\:\mathopen{} D
}{
b\nonscript\:\vert\nonscript\:\mathopen{} D
}
\]

using the basic rules (\ref{eq-t-not}, \ref{eq-t-and}, \ref{eq-t-or},
\ref{eq-t-unity}). Remember that you can use each rule as many times as
you like, and that there is not only one way of constructing a proof.

\end{tcolorbox}

\hypertarget{logical-ai-agents-and-their-limitations}{%
\section{Logical AI agents and their
limitations}\label{logical-ai-agents-and-their-limitations}}

The basic rules above are also the rules that a logical
artificial-intelligent agent should follow.

\begin{tcolorbox}[enhanced jigsaw, bottomrule=.15mm, leftrule=.75mm, opacitybacktitle=0.6, breakable, toptitle=1mm, coltitle=black, title={\faIcon{book-open} Reading}, rightrule=.15mm, left=2mm, colframe=quarto-callout-caution-color-frame, bottomtitle=1mm, arc=.35mm, titlerule=0mm, toprule=.15mm, opacityback=0, colback=white, colbacktitle=quarto-callout-caution-color!10!white]

\href{https://hvl.instructure.com/courses/25074/modules/items/660089}{Ch.~7
in \emph{Artificial Intelligence}}

\end{tcolorbox}

Many -- if not most -- inference problems that a data engineer must face
are, however, of the \emph{uncertain} kind: it is not possible to surely
infer the truth of some data, and the truth of some initial data may not
be known either. In the next chapter we shall see how to generalize the
logic rules to uncertain situations.

\begin{tcolorbox}[enhanced jigsaw, bottomrule=.15mm, leftrule=.75mm, opacitybacktitle=0.6, breakable, toptitle=1mm, coltitle=black, title={\faIcon{rocket} For the extra curious}, rightrule=.15mm, left=2mm, colframe=quarto-callout-tip-color-frame, bottomtitle=1mm, arc=.35mm, titlerule=0mm, toprule=.15mm, opacityback=0, colback=white, colbacktitle=quarto-callout-tip-color!10!white]

Our cursory visit of formal logic only showed a microscopic part of this
vast field. The study of logic rules continues still today, with many
exciting developments and applications. Feel free take a look at
\href{https://hvl.instructure.com/courses/25074/modules/items/661036}{\emph{Logic
in Computer Science}},
\href{https://hvl.instructure.com/courses/25074/modules/items/661146}{\emph{Mathematical
Logic for Computer Science}},
\href{https://plato.stanford.edu/archives/spr2023/entries/natural-deduction}{Natural
Deduction Systems in Logic}

\end{tcolorbox}

\bookmarksetup{startatroot}

\hypertarget{probability-inference}{%
\chapter{Probability inference}\label{probability-inference}}

\providecommand{\ul}{\uline}
\renewcommand*{\|}[1][]{\nonscript\:#1\vert\nonscript\:\mathopen{}}
\providecommand*{\pr}[1]{\textsf{\small`#1'}}
\renewcommand*{\pr}[1]{\textsf{\small`#1'}}
\providecommand*{\prq}[1]{\textsf{\small #1}}
\renewcommand*{\prq}[1]{\textsf{\small #1}}
\providecommand{\se}[1]{\mathsfit{#1}}
\renewcommand{\se}[1]{\mathsfit{#1}}
\providecommand{\p}{\mathrm{p}}
\renewcommand{\p}{\mathrm{p}}
\renewcommand{\P}{\mathrm{P}}
\definecolor{quarto-callout-note-color}{HTML}{4477AA}
\definecolor{quarto-callout-note-color-frame}{HTML}{4477AA}
\definecolor{quarto-callout-important-color}{HTML}{AA3377}
\definecolor{quarto-callout-important-color-frame}{HTML}{AA3377}
\definecolor{quarto-callout-warning-color}{HTML}{EE6677}
\definecolor{quarto-callout-warning-color-frame}{HTML}{EE6677}
\definecolor{quarto-callout-tip-color}{HTML}{228833}
\definecolor{quarto-callout-tip-color-frame}{HTML}{228833}
\definecolor{quarto-callout-caution-color}{HTML}{CCBB44}
\definecolor{quarto-callout-caution-color-frame}{HTML}{CCBB44}

\hypertarget{when-truth-isnt-known-probability}{%
\section{When truth isn't known:
probability}\label{when-truth-isnt-known-probability}}

In most real-life and engineering situations we don't know the truth or
falsity of sentences and hypotheses that interest us. But this doesn't
mean that nothing can be said or done in such situations.

When we cross a busy city street we look left and right to check whether
any cars are approaching. We typically don't look up to check whether
something is falling from the sky. Yet, couldn't it be \texttt{false}
that cars are approaching? and couldn't it be \texttt{true} that
\href{https://www.aerotime.aero/articles/32818-cessna-door-falls-off-lands-in-parking-lot}{some
object is falling from the sky}? Of course both events are possible.
Then why do we look left and right, but not up?

The main reason\footnote{We shall see later that one more factor enters
  the explanation.} is that we \emph{believe strongly} that cars might
be approaching, \emph{believe very weakly} that some object might be
falling from the sky. In other words, we consider the first occurrence
to be very \emph{probable}; the second, extremely improbable.

We shall take the notion of \textbf{probability} as intuitively
understood (just as we did with the notion of truth). Terms equivalent
for ``probability'' are \emph{degree of belief}, \emph{plausibility},
\emph{credibility}.

\begin{tcolorbox}[enhanced jigsaw, bottomrule=.15mm, leftrule=.75mm, toprule=.15mm, breakable, left=2mm, colframe=quarto-callout-important-color-frame, colback=white, arc=.35mm, opacityback=0, rightrule=.15mm]

\textbf{}\vspace{2mm}

\faIcon{exclamation-circle} In technical discourse, \emph{likelihood}
means something different and is \emph{not} a synonym of
``probability'', as we'll explain later.

\end{tcolorbox}

Probabilities are quantified between \texttt{0} and \texttt{1}, or
equivalently between \texttt{0\%} and \texttt{100\%}. Assigning to a
sentence a probability \texttt{1} is the same as saying that it is
\texttt{true}; and a probability \texttt{0}, that it is \texttt{false}.
A probability of \texttt{0.5} represents a belief completely symmetric
with respect to truth and falsity.

It is important to emphasize and agree on some facts about
probabilities:

\begin{itemize}
\item
  \textbf{Probabilities are assigned to \emph{sentences}}. Consider an
  engineer working on a problem of electric-power distribution in a
  specific geographical region. At a given moment the engineer may
  believe with \texttt{75\%} probability that the measured average power
  output in the next hour will be 100~MW. The \texttt{75\%} probability
  is assigned not to the quantity ``100~MW'', but to the \emph{sentence}
  \[
  \textsf{\small`The measured average power output in the next hour will be 100\,MW'}
  \] This difference is extremely important. Consider the alternative
  sentence \[
  \textsf{\small`The average power output in the next hour will be \emph{set} to 100\,MW'}
  \] the quantity is the same, but the meaning is very different. The
  probability can therefore be very different (if the engineer is the
  person deciding the output, the probability is \texttt{100\%}). The
  probability depends not only on a number, but on what it's being done
  with that number -- measuring, setting, third-party reporting, and so
  on. Often we still write simply
  \(\textsf{\small`\(\mathsf{O = 100\,W}\)'}\) or even just
  \(\textsf{\small`100\,W'}\), provided that the full sentence behind
  the shorthand is understood.
\item
  \textbf{Probabilities are agent- and context-dependent}. A coin is
  tossed, comes down heads, and is quickly hidden from view. Alice sees
  that it landed heads-up. Bob instead doesn't manage to see the outcome
  and has no clue. Alice considers the sentence
  \(\textsf{\small`Coin came down heads'}\) to be \texttt{true}, that
  is, to have \texttt{100\%} probability. Bob considers the same
  sentence to have \texttt{50\%} probability.

  Note how Alice and Bob assign two different probabilities to the same
  sentence; yet both assignments are completely rational. If Bob
  assigned \texttt{100\%} to \(\textsf{\small`heads'}\), we would
  suspect that he had seen the outcome after all; if he assigned
  \texttt{0\%} to \(\textsf{\small`heads'}\), we would consider that
  groundless and silly. We would be baffled if Alice assigned
  \texttt{50\%} to \(\textsf{\small`heads'}\), because she saw the
  outcome was actually heads; we would hypothesize that she feels unsure
  about what she saw.

  An omniscient agent would know the truth or falsity of every sentence,
  and assign only probabilities \texttt{0} or \texttt{1}. Some authors
  speak of ``\emph{actual} (but unknown) probabilities''; if there were
  ``actual'' probabilities, they would be all \texttt{0} or \texttt{1},
  and it would be pointless to speak about probabilities at all -- every
  inference would be a truth inference.
\item
  \textbf{Probabilities are not frequencies}. The fraction of defective
  mechanical components to total components produced per year in some
  factory is a quantity that can be physically measured and would be
  agreed upon by every agent. It is a \emph{frequency}, not a degree of
  belief or probability. It is important to understand the difference
  between them, to avoid making sub-optimal decisions; we shall say more
  about this difference later. Frequencies can be unknown to some
  agents, probabilities cannot be unknown (but can be difficult to
  calculate). Be careful when you read authors speaking of an ``unknown
  probability''; either they actually mean ``unknown frequency'', or a
  probability that has to be calculated (it's ``unknown'' in the same
  sense that the value of \(1-0.7 \cdot 0.2/(1-0.3)\) is unknown to you
  right now).
\item
  \textbf{Probabilities are not physical properties}. Whether a tossed
  coin lands heads up or tails up is fully determined by the initial
  conditions (position, orientation, momentum, rotational momentum) of
  the toss and the boundary conditions (air velocity and pressure)
  during the flight. The same is true for all macroscopic engineering
  phenomena (even quantum phenomena have never been proved to be
  non-deterministic, and there are
  \href{https://doi.org/10.48550/arXiv.quant-ph/9504010}{deterministic
  and experimentally consistent} mathematical representations of quantum
  theory). So we cannot measure a probability using some physical
  apparatus; and the mechanisms underlying any engineering problem boil
  down to physical laws, not to probabilities.
\end{itemize}

\begin{tcolorbox}[enhanced jigsaw, bottomrule=.15mm, leftrule=.75mm, opacitybacktitle=0.6, breakable, toptitle=1mm, coltitle=black, title={\faIcon{book-open} Reading}, rightrule=.15mm, left=2mm, colframe=quarto-callout-caution-color-frame, bottomtitle=1mm, arc=.35mm, titlerule=0mm, toprule=.15mm, opacityback=0, colback=white, colbacktitle=quarto-callout-caution-color!10!white]

\href{https://hvl.instructure.com/courses/25074/modules/items/661553}{\emph{Dynamical
Bias in the Coin Toss}}

\end{tcolorbox}

These facts are not just a matter of principle. They have important
practical consequences. A data engineer who is not attentive to the
source of the data (measured? set? reported, and so maybe less
trustworthy?), or who does not carefully assess the context of a
probability, or who mixes it up with something else, or who does not
take advantage (when possible) of the physics involved in the
engineering problem, will design a system with sub-optimal
performance\footnote{This fact can be mathematically proven.} -- or even
cause deaths.

\hypertarget{no-new-building-blocks}{%
\section{No new building blocks}\label{no-new-building-blocks}}

In discussing \protect\hyperlink{sec-truth-inference}{truth-inference}
we introduced notations such as
\(\mathrm{T}(a \nonscript\:\vert\nonscript\:\mathopen{} b \land D)\),
which stands for the truth-value \texttt{0} or \texttt{1} of sentence
\(a\) in the context of data \(D\) and supposing (even if only
hypothetically) sentence \(b\) to be true. We can simply extend this
notation to probability-values, using a \(\mathrm{P}\) instead of
\(\mathrm{T}\):
\[\mathrm{P}(a \nonscript\:\vert\nonscript\:\mathopen{} b \land D) \in [0,1]\]
represents the probability or degree of belief in sentence \(a\) in the
context of data \(D\) and supposing also sentence \(b\) to be true. Keep
in mind that both \(a\) and \(b\) could be complex sentences (for
instance \(a = (\lnot c \lor d) \land e\)). Note that truth-values are
included as the special cases\texttt{1} or \texttt{0}: \[
\mathrm{P}(a \nonscript\:\vert\nonscript\:\mathopen{} b \land D) = 0\text{ or }1
\quad\Longleftrightarrow\quad
\mathrm{T}(a \nonscript\:\vert\nonscript\:\mathopen{} b \land D) = 0\text{ or }1
\]

\hypertarget{probability-inference-rules}{%
\section{Probability-inference
rules}\label{probability-inference-rules}}

Extending our truth-inference notation to probability-inference notation
has been straightforward. But how do we draw inferences when
probabilities are involved?

Consider the inference about my umbrella in a more uncertain situation:

\begin{figure*}

\[
\frac{
\mathrm{P}(\textsf{\small`My umbrella is either blue or red'}\nonscript\:\vert\nonscript\:\mathopen{}D)=1\quad
\mathrm{P}(\textsf{\small`My umbrella is not red'} \nonscript\:\vert\nonscript\:\mathopen{} D)=0.5
}{
\mathrm{P}(\textsf{\small`My umbrella is blue'} \nonscript\:\vert\nonscript\:\mathopen{} D) = \mathord{?}
}
\]

\end{figure*}

or more compactly, using the symbols we introduced earlier, \[
\frac{
\mathrm{P}\bigl[(b \lor r) \land \lnot (b \land r)\nonscript\:\vert\nonscript\:\mathopen{}D\bigr]=1\quad
\mathrm{P}(\lnot r\nonscript\:\vert\nonscript\:\mathopen{} D)=0.5
}{
\mathrm{P}( b \nonscript\:\vert\nonscript\:\mathopen{} D) = \mathord{?}
}
\] This says, above the line, that: according to our data \(D\) my
umbrella is either blue or red (and can't be both), with full certainty;
and according to our data we have no preferential beliefs on whether my
umbrella is not red. What should then be the probability of my umbrella
being blue, according to our data?

Intuitively that probability should be \texttt{50\%}:
\(\mathrm{P}( b \nonscript\:\vert\nonscript\:\mathopen{} D)=0.5\). But
which rules did we follow in arriving at this probability? More
generally, which rules should we follow in assigning new probabilities
from given ones?

The amazing result is that \emph{the rules for truth-inference, formulae
(\ref{eq-t-not}, \ref{eq-t-or}, \ref{eq-t-and}, \ref{eq-t-unity}),
extend also to probability-inference}. The only difference is that they
now hold for all values in the range \([0,1]\), rather than only values
\(0\) and \(1\).

This important result was taken more or less for granted at least since
Laplace in the 1700s. But was formally proven for the first time in the
1940s by R.~T.~Cox; the proof has been refined since then. What kind of
proof is it? It shows that if we don't follow the rules we arrive at
illogical conclusions; we'll show some examples later.

Here are the fundamental rules of probability inference. In these rules,
all probabilities can have values in the range
\(\mathrm{P}() \in [0,1]\), and the symbols \(a,b,D\) represent
sentences of any complexity:

\begin{figure*}

\begin{tcolorbox}[enhanced jigsaw, bottomrule=.15mm, leftrule=.75mm, opacitybacktitle=0.6, breakable, toptitle=1mm, coltitle=black, title={\faIcon{landmark}~~~THE FUNDAMENTAL LAWS OF
INFERENCE~~~\faIcon{landmark}}, rightrule=.15mm, left=2mm, colframe=quarto-callout-note-color-frame, bottomtitle=1mm, arc=.35mm, titlerule=0mm, toprule=.15mm, opacityback=0, colback=white, colbacktitle=quarto-callout-note-color!10!white]

\begin{description}
\tightlist
\item[``Not'' \(\boldsymbol{\lnot}\) rule]
\[\mathrm{P}(\lnot a \nonscript\:\vert\nonscript\:\mathopen{} D) 
+ \mathrm{P}(a \nonscript\:\vert\nonscript\:\mathopen{} D)
= 1\]\\
\item[``And'' \(\boldsymbol{\land}\) rule]
\[
\mathrm{P}(a \land b \nonscript\:\vert\nonscript\:\mathopen{} D) 
= \mathrm{P}(a \nonscript\:\vert\nonscript\:\mathopen{} b \land D) \cdot
\mathrm{P}(b \nonscript\:\vert\nonscript\:\mathopen{} D) 
= \mathrm{P}(b \nonscript\:\vert\nonscript\:\mathopen{} a \land D) \cdot
\mathrm{P}(a \nonscript\:\vert\nonscript\:\mathopen{} D) 
\]\\
\item[``Or'' \(\boldsymbol{\lor}\) rule]
\[\mathrm{P}(a \lor b \nonscript\:\vert\nonscript\:\mathopen{} D) 
= \mathrm{P}(a \nonscript\:\vert\nonscript\:\mathopen{} D) +
\mathrm{P}(b \nonscript\:\vert\nonscript\:\mathopen{} D) 
- \mathrm{P}(a \land b \nonscript\:\vert\nonscript\:\mathopen{} D)
\]\\
\item[Self-consistency rule]
\[\mathrm{P}(a \nonscript\:\vert\nonscript\:\mathopen{} a \land D) 
= 1
\]
\end{description}

\end{tcolorbox}

\end{figure*}

It is amazing that \textbf{ALL} inference is nothing else but a repeated
application of these four rules -- billions of times or more, in some
inferences. All machine-learning algorithms are just applications or
approximations of these rules. Methods that you may have heard about in
statistics are just specific applications of these rules. Truth
inferences are also special applications of these rules. Most of this
course is, at bottom, just a study of how to apply these rules in
particular kinds of problems.

\begin{tcolorbox}[enhanced jigsaw, bottomrule=.15mm, leftrule=.75mm, opacitybacktitle=0.6, breakable, toptitle=1mm, coltitle=black, title={\faIcon{book-open} Reading}, rightrule=.15mm, left=2mm, colframe=quarto-callout-caution-color-frame, bottomtitle=1mm, arc=.35mm, titlerule=0mm, toprule=.15mm, opacityback=0, colback=white, colbacktitle=quarto-callout-caution-color!10!white]

\begin{itemize}
\item
  \href{https://hvl.instructure.com/courses/25074/modules/items/660094}{\emph{Probability,
  Frequency and Reasonable Expectation}}
\item
  Ch.~2 of
  \href{https://hvl.instructure.com/courses/25074/modules/items/660390}{\emph{Bayesian
  Logical Data Analysis for the Physical Sciences}}
\item
  §§~1.0--1.2 of
  \href{https://hvl.instructure.com/courses/25074/modules/items/661040}{\emph{Data
  Analysis}}
\item
  Feel free to skim through §§~2.0--2.4 of
  \href{https://hvl.instructure.com/courses/25074/modules/items/660090}{\emph{Probability
  Theory}}
\end{itemize}

\end{tcolorbox}

\hypertarget{how-the-inference-rules-are-used}{%
\section{How the inference rules are
used}\label{how-the-inference-rules-are-used}}

The fundamental rules represent, first of all, constraints of logical
consistency among probabilities. If we have probabilities
\(\mathrm{P}(a\nonscript\:\vert\nonscript\:\mathopen{}D)=0.7\),
\(\mathrm{P}(b\nonscript\:\vert\nonscript\:\mathopen{}a\land D)=0.1\),
\(\mathrm{P}(a\land b\nonscript\:\vert\nonscript\:\mathopen{}D)=0.2\),
then there's an inconsistency somewhere, because these values violate
the and-rule:~~\(0.2 \ne 0.1 \cdot 0.7\).~~In this case we must find the
inconsistency and solve it. Since probabilities are quantified by real
numbers, however, it's possible and acceptable to have slight
discrepancies owing to numerical round-off errors.

The rules also imply more general constraints. For example we must
\emph{always} have \begin{gather*}
\mathrm{P}(a\land b \nonscript\:\vert\nonscript\:\mathopen{}D) \le \min\bigl\{\mathrm{P}(a\nonscript\:\vert\nonscript\:\mathopen{}D),\  \mathrm{P}(b\nonscript\:\vert\nonscript\:\mathopen{}D)\bigr\}
\\
\mathrm{P}(a\lor b \nonscript\:\vert\nonscript\:\mathopen{}D) \ge \max\bigl\{\mathrm{P}(a\nonscript\:\vert\nonscript\:\mathopen{}D),\  \mathrm{P}(b\nonscript\:\vert\nonscript\:\mathopen{}D)\bigr\}
\end{gather*}

\begin{tcolorbox}[enhanced jigsaw, bottomrule=.15mm, leftrule=.75mm, opacitybacktitle=0.6, breakable, toptitle=1mm, coltitle=black, title={\faIcon{pen} Exercise}, rightrule=.15mm, left=2mm, colframe=quarto-callout-caution-color-frame, bottomtitle=1mm, arc=.35mm, titlerule=0mm, toprule=.15mm, opacityback=0, colback=white, colbacktitle=quarto-callout-caution-color!10!white]

Try to prove the two constraints above

\end{tcolorbox}

The main use of the rules in concrete applications is for calculating
new probabilities from given ones. The calculated probabilities will be
automatically consistent. For each equation shown in the rules we can
calculate one probability given the remaining ones in the equation, with
some special cases when values of \(0\) or \(1\) appear.

For example, if we have
\(\mathrm{P}(a \land b\nonscript\:\vert\nonscript\:\mathopen{} D)=0.2\)
and \(\mathrm{P}(a\nonscript\:\vert\nonscript\:\mathopen{}D)=0.7\), from
the and-rule we can find
\(\mathrm{P}(b\nonscript\:\vert\nonscript\:\mathopen{} a \land D)\):
\begin{multline*}
\underbracket{\color[RGB]{34,136,51}\mathrm{P}(a \land b \nonscript\:\vert\nonscript\:\mathopen{} D)}_{0.2}
= {\color[RGB]{238,102,119}\mathrm{P}(b \nonscript\:\vert\nonscript\:\mathopen{} a \land D)} \cdot
\underbracket{\color[RGB]{34,136,51}\mathrm{P}(a \nonscript\:\vert\nonscript\:\mathopen{} D)}_{0.7}
\\[1em]
\Longrightarrow\quad
{\color[RGB]{238,102,119}\mathrm{P}(b\nonscript\:\vert\nonscript\:\mathopen{} a \land D)} = 
\frac{\color[RGB]{34,136,51}
\mathrm{P}(a\land b \nonscript\:\vert\nonscript\:\mathopen{} D)
}{\color[RGB]{34,136,51}
\mathrm{P}(a\nonscript\:\vert\nonscript\:\mathopen{}D)
} = \frac{0.2}{0.7} 
\approx 0.2857
\end{multline*}\\

Let us now solve the umbrella inference from the previous section.
Starting from \[
\mathrm{P}\bigl[(b \lor r) \land \lnot (b \land r)\nonscript\:\vert\nonscript\:\mathopen{}D\bigr]=1 \ ,
\quad
\mathrm{P}(\lnot r\nonscript\:\vert\nonscript\:\mathopen{} D)=0.5
\] we arrive at \[
\mathrm{P}( b \nonscript\:\vert\nonscript\:\mathopen{} D) = 0.5
\]

by following from top to bottom the steps depicted here:

\includegraphics{index_files/mediabag/umbrella_inference2.pdf}

@@ example medical diagnosis

\hypertarget{derived-rules}{%
\subsection{Derived rules}\label{derived-rules}}

The rules above are in principle all we need to use. But from them it is
possible to derive some additional shortcut rules that are automatically
consistent with the fundamental ones.

First, it is possible to show that all rules you may know from Boolean
algebra are a consequence of the fundamental rules. For example, we can
always make the following convenient replacements anywhere in a
probability expression: \[
\begin{gathered}
A \land A = A \lor A = A
\qquad
\lnot\lnot A = A
\\[1ex]
A\land B = B \land A
\qquad
A \lor B = B \lor A
\\[1ex]
\lnot (A \land B) = \lnot A \lor \lnot B
\qquad
\lnot (A \lor B) = \lnot A \land \lnot B
\\[1ex]
A \land (B \lor C) = (A \land B) \lor (A \land C)
\\[1ex]
A \lor (B \land C) = (A \lor B) \land (A \lor C)
\end{gathered}
\]

Two other derived rules are used extremely often, so we treat them
separately.

\hypertarget{law-of-total-probability-or-extension-of-the-conversation}{%
\section{Law of total probability or ``extension of the
conversation''}\label{law-of-total-probability-or-extension-of-the-conversation}}

\hypertarget{bayess-theorem}{%
\section{Bayes's theorem}\label{bayess-theorem}}

\begin{marginfigure}

{\centering \includegraphics{bayes_big-bang.jpg}

}

\caption{Bayes's theorem guest-starring in
\href{https://www.imdb.com/title/tt0898266/}{\emph{The Big Bang
Theory}}}

\end{marginfigure}

\hypertarget{consequences-of-not-following-the-rules}{%
\section{consequences of not following the
rules,}\label{consequences-of-not-following-the-rules}}

@@ §12.2.3 of AI

\begin{itemize}
\item
  \emph{Exercise: \href{The_Monty_Hall_problem-exercise.pdf}{Monty-Hall
  problem \& variations}}
\item
  \emph{Exercise: clinical test \& diagnosis}
\end{itemize}

\hypertarget{common-points-of-certain-and-uncertain-inference}{%
\section{Common points of certain and uncertain
inference}\label{common-points-of-certain-and-uncertain-inference}}

\begin{quote}
\emph{No premises? No conclusions!}
\end{quote}

\begin{tcolorbox}[enhanced jigsaw, bottomrule=.15mm, leftrule=.75mm, opacitybacktitle=0.6, breakable, toptitle=1mm, coltitle=black, title={\faIcon{exclamation-circle} Differences in terminology}, rightrule=.15mm, left=2mm, colframe=quarto-callout-important-color-frame, bottomtitle=1mm, arc=.35mm, titlerule=0mm, toprule=.15mm, opacityback=0, colback=white, colbacktitle=quarto-callout-important-color!10!white]

\begin{itemize}
\item
  Some texts speak of the probability of a ``random\footnotemark{}
  variable'', or more precisely of the probability that a random
  variable takes on a particular value. As you notice, we have just
  expressed that idea by means of a \emph{sentence}. The viewpoint and
  terminology of random variables is a special case of that of
  sentences. As already discussed, in concrete applications it is
  important to know how a variable ``takes on'' a value: for example it
  could be directly measured, indirectly reported, or purposely set.
  Thinking in terms of sentences, rather than of random variables,
  allows us to account for these important differences.
\item
  Some texts speak of the probability of an ``event''. For all purposes
  an ``event'' is just what's expressed in a sentence.
\end{itemize}

It's a question for sociology of science why some people keep on using
less flexible points of view or terminologies. Probably they just
memorize them as students and then a fossilization process sets in.

\end{tcolorbox}

\footnotetext{What does ''random'' mean? Good luck finding an
understandable and non-circular definition in texts that use that word.
In these notes, if the word ''random'' is ever used, it means
''unpredictable'' or ''unsystematic''.}

\bookmarksetup{startatroot}

\hypertarget{data-and-information}{%
\chapter{Data and information}\label{data-and-information}}

\hypertarget{kinds-of-data}{%
\section{Kinds of data}\label{kinds-of-data}}

\hypertarget{binary}{%
\subsection{Binary}\label{binary}}

\hypertarget{nominal}{%
\subsection{Nominal}\label{nominal}}

\hypertarget{ordinal}{%
\subsection{Ordinal}\label{ordinal}}

\hypertarget{continuous}{%
\subsection{Continuous}\label{continuous}}

\begin{itemize}
\item
  unbounded
\item
  bounded
\item
  censored
\end{itemize}

\hypertarget{complex-data}{%
\subsection{Complex data}\label{complex-data}}

2D, 3D, images, graphs, etc.

\hypertarget{soft-data}{%
\subsection{``Soft'' data}\label{soft-data}}

\begin{itemize}
\item
  orders of magnitude
\item
  physical bounds
\end{itemize}

\hypertarget{data-transformations}{%
\section{Data transformations}\label{data-transformations}}

\begin{itemize}
\item
  log
\item
  probit
\item
  logit
\end{itemize}

\bookmarksetup{startatroot}

\hypertarget{allocation-of-uncertainty-among-possible-data-values-probability-distributions}{%
\chapter{Allocation of uncertainty among possible data values:
probability
distributions}\label{allocation-of-uncertainty-among-possible-data-values-probability-distributions}}

\hypertarget{the-difference-between-statistics-and-probability-theory}{%
\section{The difference between Statistics and Probability
Theory}\label{the-difference-between-statistics-and-probability-theory}}

\emph{Statistics} is the study of collective properties of collections
of data. It does not imply that there is any uncertainty.

\emph{Probability theory} is the quantification and propagation of
uncertainty. It does not imply that we have collections of data.

\hypertarget{whats-distributed}{%
\section{What's ``distributed''?}\label{whats-distributed}}

Difference between distribution of probability and distribution of (a
collection of) data.

\hypertarget{distributions-of-probability}{%
\section{Distributions of
probability}\label{distributions-of-probability}}

\hypertarget{representations}{%
\subsection{Representations}\label{representations}}

\begin{itemize}
\item
  Density function
\item
  Histogram
\item
  Scatter plot
\end{itemize}

Behaviour of representations under transformations of data.

\hypertarget{summaries-of-distributions-of-probability}{%
\section{Summaries of distributions of
probability}\label{summaries-of-distributions-of-probability}}

\hypertarget{location}{%
\subsection{Location}\label{location}}

Median, mean

\hypertarget{dispersion-or-range}{%
\subsection{Dispersion or range}\label{dispersion-or-range}}

Quantiles \& quartiles, interquartile range, median absolute deviation,
standard deviation, half-range

\hypertarget{resolution}{%
\subsection{Resolution}\label{resolution}}

Differential entropy

\hypertarget{behaviour-of-summaries-under-transformations-of-data-and-errors-in-data}{%
\subsection{Behaviour of summaries under transformations of data and
errors in
data}\label{behaviour-of-summaries-under-transformations-of-data-and-errors-in-data}}

\hypertarget{outliers-and-out-of-population-data}{%
\section{Outliers and out-of-population
data}\label{outliers-and-out-of-population-data}}

(Warnings against tail-cutting and similar nonsense-practices)

\hypertarget{marginal-and-conditional-distributions-of-probability}{%
\section{Marginal and conditional distributions of
probability}\label{marginal-and-conditional-distributions-of-probability}}

\hypertarget{collecting-and-sampling-data}{%
\section{Collecting and sampling
data}\label{collecting-and-sampling-data}}

\hypertarget{representative-samples}{%
\subsection{``Representative'' samples}\label{representative-samples}}

Size of minimal representative sample = (2\^{}entropy)/precision

\begin{itemize}
\tightlist
\item
  \emph{Exercise: data with 14 binary variates, 10000 samples}
\end{itemize}

\hypertarget{unavoidable-sampling-biases}{%
\subsection{Unavoidable sampling
biases}\label{unavoidable-sampling-biases}}

In high dimensions, all datasets are outliers.

Data splits and cross-validation cannot correct sampling biases

\hypertarget{quirks-and-warnings-about-high-dimensional-data}{%
\section{Quirks and warnings about high-dimensional
data}\label{quirks-and-warnings-about-high-dimensional-data}}

\bookmarksetup{startatroot}

\hypertarget{making-decisions}{%
\chapter{Making decisions}\label{making-decisions}}

\hypertarget{decisions-possible-situations-and-consequences}{%
\section{Decisions, possible situations, and
consequences}\label{decisions-possible-situations-and-consequences}}

\hypertarget{gains-and-losses-utilities}{%
\section{Gains and losses: utilities}\label{gains-and-losses-utilities}}

\hypertarget{factors-that-enter-utility-quantification}{%
\subsection{Factors that enter utility
quantification}\label{factors-that-enter-utility-quantification}}

Utilities can rarely be assigned a priori.

\hypertarget{making-decisions-under-uncertainty-maximization-of-expected-utility}{%
\section{Making decisions under uncertainty: maximization of expected
utility}\label{making-decisions-under-uncertainty-maximization-of-expected-utility}}

\bookmarksetup{startatroot}

\hypertarget{the-most-general-inference-problem}{%
\chapter{The most general inference
problem}\label{the-most-general-inference-problem}}



\end{document}
