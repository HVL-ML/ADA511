# [A first connection with machine learning]{.red} {#sec-1st-connection-ML}
{{< include macros.qmd >}}
{{< include macros_prob_inference.qmd >}}

In these first chapters we have been developing notions and methods about agents drawing inferences and making decisions, sentences expressing facts and information, and probabilities expressing uncertainty and certainty. Let's draw some first qualitative connections between these notions and notions typically used in machine learning.

A machine-learning algorithm is usually presented in textbooks as something that first "learns" from some training data, and thereafter performs some kind of task -- typically it yields a response or outcome of some kind. More precisely, the training data are instances or examples of the task that the algorithm is expected to perform. These instances have a special status because their details are fully known, whereas new instances, where the algorithm will be applied, have some uncertain elements: typically they have an ideal or optimal outcome, but this outcome is unknown beforehand. The response given by the algorithm in new instances depend on the algorithm's internal architecture and parameters; for brevity we shall just use "architecture" to mean both.

Let's try to rephrase this description from the point of view developed in the past chapters. A machine-learning algorithm is given [known pieces of information (the training data)]{.green}, and then forms some kind of connection with [another piece of information of a similar kind (the outcome in a new application) that was not known beforehand]{.red}. The connection depends on the [algorithm's architecture]{.yellow}.

This has strong similarities to what an agent does when drawing an inference: it uses known pieces of information, expressed by sentences ${\green\se{D}_1}, {\green\se{D}_2}, {\green\dots}, {\green\se{D}_N}$, together with some background or built-in information $\yellow\yI$, in order to calculate the probability of a piece of information of a similar kind, expressed by a sentence $\red\se{D}_{N+1}$:

$$
\P(\red\se{D}_{N+1}\black \| 
\green\se{D}_{N} \land \dotsb \land \se{D}_2 \land \se{D}_1 \black\land {\yellow\yI})
$$


We can thus consider a first *tentative* correspondence:

$$
\P(\underbracket[0ex]{\red\se{D}_{N+1}}_{\mathclap{\red\text{outcome?}}} \| 
\green\underbracket[0ex]{\se{D}_N \land \dotsb \land \se{D}_2 \land \se{D}_1}_{\mathclap{\green\text{training data?}}} 
\black\land \underbracket[0ex]{\yellow\yI}_{\mathrlap{\yellow\uparrow\ \text{architecture?}}})
$$

This correspondence seems convincing with regard to [architecture]{.yellow} and [training data]{.green}: in both cases we're speaking about the use of pre-existing or built-in information, combined with additional one.

But it is less convincing with regarding to the [outcome]{.red}, because an agent gives the probabilities for several possible "outputs", it doesn't just yield one. This indicates that there must be also be some **decision** involved among the possible outcomes.

We'll return to this tentative connection later.
