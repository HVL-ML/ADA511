# A first connection with machine learning {#sec-1st-connection-ML}
{{< include macros.qmd >}}
{{< include macros_prob_inference.qmd >}}

In these first chapters we have been developing notions and methods about agents having to draw inferences and making decisions, sentences expressing facts and information, and probabilities expressing uncertainty and certainty. Let's draw some first qualitative connections between these notions and notions typically used in machine learning.

A machine-learning algorithm is usually presented in textbooks as something that first "learns" from data, and thereafter performs some kind of task -- typically, yielding an output of some kind.

Putting this description in more general terms, such an algorithm uses some [given, known pieces of information (the data used for learning)]{.green}, and then forms some kind of connection with [another piece of information (the output) that was not known beforehand]{.red}. The connection depends on the [algorithm's architecture and internal design (often called "model")]{.yellow}.

This has strong similarities to what an agent does when drawing an inference: it uses some known pieces of information, expressed by sentences ${\green\se{D}_1}, {\green\se{D}_2}, {\green\se{D}_3}, {\green\dots}$, together with some background or built-in information $\yellow\yI$; and then calculates the probability of a particular piece of information, expressed by a sentence $\se{\red O}$:

$$
\P(\se{\red O} \| 
\green\se{D}_1 \land \se{D}_2 \land \se{D}_3 \land \dotsb \black\land {\yellow\yI})
$$


We thus see a *tentative* correspondence here:

$$
\P(\underbracket[0ex]{\se{\red O}}_{\mathllap{\red\text{output?}\ \uparrow}} \| 
\green\underbracket[0ex]{\se{D}_1 \land \se{D}_2 \land \se{D}_3}_{\mathclap{\green\text{learning data?}}}  \land \dotsb
\black\land \underbracket[0ex]{\yellow\yI}_{\mathrlap{\yellow\uparrow\ \text{architecture?}}})
$$

This correspondence is surely spot-on regarding [architecture]{.yellow} and [data]{.green}: in both cases we're speaking about the use of pre-existing or built-in information, combined with additional one.

But the correspondence can't be completely correct regarding the [output]{.red}, because an agent gives the probabilities for several possible "outputs", it doesn't just yield one. This indicates that there must be also be some **decision** involved among the possible outputs.

We'll return to this connection later.
