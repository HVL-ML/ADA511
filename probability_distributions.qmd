# Probability distributions
{{< include macros.qmd >}}

[*(Make sure you're familiar with [§ @sec-data-types] before you begin.)*]{.small style="color: #EE6677;"}

## Distribution of probabilities among values

When an agent is uncertain about what the value of a quantity is, this uncertainty is expressed and quantified by assigning a degree of belief to all the possible cases, conditional on the agent's knowledge. For a temperature measurement, for instance, the cases could be "[The temperature is measured to have value 270 K]{.midgrey}", "[The temperature is measured to have value 271 K]{.midgrey}", and so on. We can abbreviate these sentences, denoting the temperature with $T$, as
$$
T = 270\,\mathrm{m} \ , \qquad
T = 271\,\mathrm{m} \ , \qquad
T = 272\,\mathrm{m} \ , \qquad
\dotsc
$$
We recognize these as *mutually exclusive* and *exhaustive* sentences.

Our belief about the quantity is then expressed by a collection of probabilities, conditional on the agent's state of knowledge $\yI$:
$$
\P(T \mo 270\,\mathrm{K} \| \yI) \ , \quad
\P(T \mo 271\,\mathrm{K} \| \yI) \ , \quad
\P(T \mo 272\,\mathrm{K} \| \yI) \ , \quad
\dotsc
$$
that sum up to one:
$$
\P(T \mo 270\,\mathrm{K} \| \yI) +
\P(T \mo 271\,\mathrm{K} \| \yI) +
\P(T \mo 272\,\mathrm{K} \| \yI) +
\dotsb
= 1
$$
This collection of probabilities is called a [**probability distribution**]{.blue}.

:::{.callout-warning}
## {{< fa exclamation-circle >}} What's "distributed"?
It's the *probability* that's distributed among the possible values, not the quantity, as illustrated in the side picture. The quantity cannot be "distributed": it has one, definite value, which is however unknown to us.
:::

::::{.column-margin}
![](illustration_prob_distr2.png)
::::


:::{.callout-caution}
## {{< fa user-edit >}} Exercise
Consider three sentences $\yX_1, \yX_2, \yX_3$ that are mutually exclusive and exhaustive on conditional [$\yI$,]{.together} that is:
$$
\begin{gathered}
\P(\yX_1 \land \yX_2 \| \yI) =
\P(\yX_1 \land \yX_3 \| \yI) =
\P(\yX_2 \land \yX_3 \| \yI) = 0
\\
\P(\yX_1 \lor \yX_2 \lor \yX_3 \| \yI) = 1
\end{gathered}
$$
Prove, using the fundamental rules of inferences and any derived rules from [§ @sec-probability], that we must then have
$$
\P(\yX_1 \| \yI) + \P(\yX_2 \| \yI) + \P(\yX_3 \| \yI) = 1
$$
:::

Let's see how probability distributions can be represented and visualized. We start with probability distributions over discrete values.

## Representation of discrete probability distributions

A probability distribution over a discrete set of values can obviously be displayed in a table of values and their probabilities. For instance

|*value*| 270 K | 271 K | 272 K | ...|
|-|:-:|:-:|:-:|:-:|
|*probability*|0.1|0.2|0.5|...|

But a graphical representation is often helpful to detect features, peculiarities, and even inconsistencies in one or more probability distributions.

### Histograms and area-based representations

A probability distribution for a nominal, ordinal, and discrete interval quantity can be neatly represented by a [**histogram**]{.blue}.

The possible values are put on a line. For an ordinal or interval quantity, the sequence of values on the line should correspond to their natural order. For a nominal quantity the order is irrelevant.

A rectangle is then drawn above each value. Typically the rectangles are contiguous. The bases of the rectangles are all equal, and the [*areas*]{.blue} of the rectangles are proportional to the probabilities. Since the bases are equal, this implies that the heights of the rectangles are also proportional to the probabilities.

Such kind of drawing can of course be horizontal, vertical, upside-down, and so on, depending on convenience.

Since the probabilities must sum to one, the total area of the rectangles represents the unit of area. So in principle there is no need of writing probability values on some vertical axis, or grid, or similar visual device, because the probability value can be visually read as the ratio of a rectangle area to the total area. An axis or grid can nevertheless be helpful. Alternatively the probabilities can be reported above or below each rectangle.

Nominal quantities do not have any specific order, so their values do not need to be ordered on a line. Other area-based representations, such as pie charts, can also be used for these quantities.

### Curve-based representations





* Density function

* Histogram

* Scatter plot

Behaviour of representations under transformations of data.



## Summaries of distributions of probability

### Location

Median, mean

### Dispersion or range

Quantiles & quartiles, interquartile range, median absolute deviation, standard deviation, half-range

### Resolution

Differential entropy

### Behaviour of summaries under transformations of data and errors in data



## Outliers and out-of-population data

(Warnings against tail-cutting and similar nonsense-practices)



## Marginal and conditional distributions of probability



## Collecting and sampling data

### "Representative" samples

Size of minimal representative sample = (2^entropy)/precision

* _Exercise: data with 14 binary variates, 10000 samples_

### Unavoidable sampling biases

In high dimensions, all datasets are outliers.

Data splits and cross-validation cannot correct sampling biases



## Quirks and warnings about high-dimensional data





