# [Third connection with machine learning]{.red} {#sec-3-connection-ML}
{{< include macros.qmd >}}
{{< include macros_prob_inference.qmd >}}
{{< include macros_connection-3.qmd >}}

In [chapter @sec-2-connection-ML] we made a second *tentative* connection between the notions about probability explored until then, and notions from machine learning. We considered the possibility that a machine-learning algorithm is like an agent that has some [built-in background information (corresponding to the algorithm's architecture)]{.yellow}, has received [pieces of information (corresponding to the data about perfectly known instances of the task, and possibly partial data about a new instance)]{.green}, and is assessing a [not-previously known piece of information (other partial aspects of a new task instance)]{.red}:

$$
\P(\underbracket[0ex]{\red\se{D}_{N+1}}_{\mathclap{\red\text{outcome?}}} \| 
\green\underbracket[0ex]{\se{D}_N \land \dotsb \land \se{D}_2 \land \se{D}_1}_{\mathclap{\green\text{training data?}}} 
\black\land \underbracket[0ex]{\yellow\yI}_{\mathrlap{\yellow\uparrow\ \text{architecture?}}})
$$

The correspondence about [training data]{.green} and [architecture]{.yellow} seems somewhat convincing, the one about [outcome]{.red} needs more exploration.

Having introduced the notion of quantity in the latest chapters [-@sec-quantities-types-basic] and [-@sec-quantities-types-multi], we recognize that training data about a task instance concern some quantity and its value, so they can be expressed by a sentence like $D_i\mo d_i$, where

- $i$ is the instance: $1,2,\dotsc,N$
- $D_i$ describes the kind of data at instance $i$, for example "128 × 128 image with 24-bit colour depth, with a character label"
- $d_i$ is the value of the data at instance $i$, for example the one here at the margin

:::{.column-margin}
![label = "Saitama"](saitama_smile.png){width=128 fig-cap-location="center"}
:::

And similarly for the outcome of a new task instance where the algorithm is applied for real, which we consider as instance $N+1$. So we can rewrite the correspondence above as follows:

$$
\P(\underbracket[0ex]{\red D_{N+1} \mo d_{N+1}}_{\mathclap{\red\text{outcome?}}} \| 
\green\underbracket[0ex]{ D_N \mo d_N \and \dotsb \and  D_2 \mo d_2 \and  D_1 \mo d_1}_{\mathclap{\green\text{training data?}}} 
\black\and \underbracket[0ex]{\yellow\yI}_{\mathrlap{\yellow\uparrow\ \text{architecture?}}})
$$

This kind of inference is what we explored in the "next-three-patients" scenario of [§ @sec-conditional-joint-sim] and some of the following sections. Let's extend this tentative connection even further.

\

It is first necessary to somewhat detach ourselves from the common machine-learning categorization and terminology that we discussed in [chapter @sec-ml-introduction]. They focus on aspects that are secondary to our purpose of [exploring new methods, understanding their foundations, and thinking out of the box](index.html). Distinctions such as "supervised learning" vs "unsupervised learning" are of secondary importance to a data engineer for several reasons:

- {{< fa shuffle >}}\ \ They group together some types of tasks that are actually quite different from an inferential or decision-making viewpoint; and conversely they separate types of tasks that are quite similar.

- {{< fa bullseye >}}\ \ They focus on procedures rather than on purposes. But the important questions for us are: [What do we wish to infer or choose?]{.blue} and [From which kind of information?]{.green} These questions define the problem we want to solve. The procedure may then be chosen depending on the theory, resources and technologies, other contingent factors, and so on.

<!-- It's somewhat like saying that the difference between car and aeroplane is that the latter has wings. Sure -- but *why?* The focus on wings misses the essential difference between these two means of transportation: they operate through different material media and exploit different kinds of physics; that's why the second has wings. -->


We shall introduce a different categorization that tries to focus on different cases of desired information and of available information.


## A task-oriented categorization of some machine-learning problems {#sec-cat-problems}

Let's jot down a convenient categorization of the types of *task* that machine-learning algorithms try to solve. Such a categorization is not meant to be clear-cut; it only provides a starting point from which to examine a new task. Many tasks will fall in between categories: every data-engineering or data-science problem is unique. We consider tasks where multiple "instances" with similar characteristics are involved.

### New instance: given vs generated

A first distinction can be made between

- [{{< fa sign-out-alt >}} {{< fa cube >}}\ \ tasks where an agent must itself *generate* a new instance]{.yellow}

- [{{< fa cube >}} {{< fa question >}}\ \ tasks where a new instance is given to an agent, who must *guess* some of its characteristics]{.green}

An example of the first type of task is image generation: an algorithm is given a collection of images and is asked to generate a new image based on them.

We shall see that these two types of task are actually quite close to each other, from the point of view of Decision Theory and Probability Theory.

:::{.small .midgrey}
The terms "discriminative" and "generative" are sometimes associated in machine learning with the two types of task. This association, however, is quite loose, because some tasks typically called "generative" actually belong to the first type. We shall therefore avoid these or other terms. It's enough to keep in mind the distinction between the two types of task above.
:::


### Guessing: all or some

Focusing on the second type of task (a new instance is given to the agent), we can further divide it into two subtypes:

- [{{< fa regular star >}}\ \ the agent must guess *all* characteristics of the new instance]{.purple}

- [{{< fa star-half-alt >}}\ \ the agent must guess *some* characteristics of the new instance, but can observe other characteristics of the new instance]{.red}

An example of the first subtype of task is the "urgent vs non-urgent" problem of [§ @sec-conditional-joint-sim]: having observed incoming patients, some of which where urgent and some non-urgent, the agent must guess whether the next incoming patient will be urgent or not. No other kinds of information (transport, patient characteristics, and so on) are available for any patient.

We shall call [**predictands**]{.blue}^[literally "what has to be predicted] the characteristics that the agent must guess in a new instance, and [**predictors**]{.blue} those that the agent can observe.^[In machine learning and other fields, the terms "dependent variable", "class" or "label" (for nominal variates) are often used for "predictand"; and the terms "independent variable" or "features" are often used for "predictor".] The first subtype above can be viewed as a special case of the second where all characteristics are predictands, and there are no predictors.

:::{.small .midgrey}
The terms "unsupervised learning" and "supervised learning" are sometimes associated in machine learning with these two subtypes of task. But also in this case the association is loose and can be misleading. "Clustering" tasks, for example, are usually called "unsupervised" but they are examples of the second subtype above, where the agent has some predictors.
:::

### Information available in previous instances

Finally we can further divide the second subtype above into two or three subsubtypes, depending on the information available to the agent about *previous instances*:

- [{{< fa star-half-alt >}} {{< fa star-half-alt >}}\ \ all predictors and predictands of previous instances are known to the agent]{.blue}

- [{{< fa star-half >}} {{< fa star-half >}}\ \ all predictors of previous instances, but not the predictands, are known to the agent]{.lightblue}

- [{{< fa regular star-half >}} {{< fa regular star-half >}}\ \ all predictands of previous instances, but not the predictors, are known to the agent]{.midgrey}

\

An example of the first subsubtype of task is image classification. The agent is for example given the following 128 × 128-pixel images and character-labels from the [One Punch Man](https://onepunchman.fandom.com) series:

![](saitama_images.png){width=100%}

and is then given one new 128 × 128-pixel image:

![](saitama_new.png){width=128 fig-align="center"}

of which it must guess the character-label.

In the example just given, the image is the predictor, the character-label is the predictand.

\

A slight modification of the example above gives us a task of the second subsubtype. A different agent is given the images above, but without labels:

![](saitama_images_nolabels.png){width=100%}

and must then guess some kind of "label" or "group" for the new image above -- and possibly even for the images already given. The kind of "group" requested depends on the specific problem.

In the new example above, the image is still the predictor, and the label or group is the predictand.

:::{.small .midgrey}
The term "supervised learning" typically refer to the first subsubtype above.

The term "unsupervised learning" can refer to the second subsubtype, for instance in "clustering" tasks. In a clustering task, the agent tries to guess which group or "cluster" an instance belong to, given a collection of similar instances, whose groups are not known either. The cluster effectively is the *predictand* quantity. In some cases the agent may want to guess the cluster not only of a new instance, but also of all previous instances.

The third subsubtype is very rarely considered in machine learning, yet it is not an unrealistic task.
:::

The types, subtypes, subsubtypes above are obviously not mutually exclusive or comprehensive. We can easily imagine scenarios where an agent has some predictors \& predictands available about *some* previous instances, but only predictors or only predictands available for other previous instances. This scenario falls in between the three subsubtypes above. In machine learning, hybrid situations like these are categorized as "missing data".


## Flexible categorization from the point of view of probability theory {#sec-categ-probtheory}

The categorization into subtypes and subsubtypes about agent's guesses and available information can actually be presented in a more straightforward and flexible way using probability-theory notation.

### Notation

Let's introduce some symbol conventions to be used in the next chapters. We shall denote with $\bZ$ all quantities of an instance that are of interest to the agent: those to be guessed and those that may be known. The quantities to be guessed in a new instance, that is, the predictands, will be denoted with $\bY$. The quantities that can be observed in a new instance, that is, the predictors, will be denoted with $\bX$. Therefore we have $\bZ = (\bY \and \bX)$. In cases where there are no predictors, $\bX$ is empty and we have $\bZ = \bY$.

$\bZ_i$, $\bY_i$, $\bX_i$ denote all quantities, the predictands, and the predictors for instance #$i$.\ \ As usual we number from $i=1$ to $i=N$ the instances that serve for learning, and $i=N+1$ is the new instance of interest to the agent.

Recall ([§ @sec-basic-elements-inference]) that in the probability notation $\P({\red\boldsymbol{\dotsb}}\|{\green\boldsymbol{\dotsb}} \and \yI)$, the [supposal]{.red} contains what the agent's belief is about, and the [conditional]{.green} contains what's supposed to be known to the agent, together with the background information $\yI$.

\

### [{{< fa regular star >}}]{.purple}\ \ The agent must guess *all* characteristics of the new instance

This kinds of guess is represented by the probability distribution

$$
\P(\red
Z_{N+1}\mo z
\black\|
\green
Z_{N}\mo z_{N}
\and \dotsb \and
Z_{1}\mo z_{1}
\black \and \yI)
$$

for all possible values $\red z$ in the domain of $\red Z_{N+1}$. The specific values $\green z_N, \dotsc, z_1$ of all quantities $\bZ$ for the previous instances are known to the agent.

\

### [{{< fa star-half-alt >}}]{.red}\ \ The agent must guess *some* characteristics of the new instance, but can observe other characteristics of the new instance

This kind of guess is represented by a probability distribution having

$$
\P(\red
Y_{N+1}\mo y
\black\|
\green
X_{N+1}\mo x
\, \and\, 
\dotsb \,
\black \and \yI)
$$

for all possible values $\red y$ in the domain of the predictands $\red Y_{N+1}$. The value $\green x$ of the predictors for the new instance, $\green X_{N+1}$, is known to the agent.

The remaining information contained in the conditional depends on the subsubtype of task discussed above:

\

#### [{{< fa star-half-alt >}} {{< fa star-half-alt >}}]{.blue}\ \ All predictors and predictands of previous instances are known to the agent

This corresponds to the probability distribution

$$
\P(\red
Y_{N+1}\mo y
\black\|
\green
X_{N+1}\mo x
\, \and\, 
Y_{N}\mo y_{N}
\and
X_{N}\mo x_{N}
\and \dotsb \and
Y_{1}\mo y_{1}
\and
X_{1}\mo x_{1}
\black \and \yI)
$$

for all possible $\red y$. All information about predictands and predictors for the previous instances appear in the conditional.

\

#### [{{< fa star-half >}} {{< fa star-half >}}]{.lightblue}\ \ All predictors of previous instances, but not the predictands, are known to the agent

This corresponds to the probability distribution

$$
\P(\red
Y_{N+1}\mo y
\black\|
\green
X_{N+1}\mo x
\, \and\, 
X_{N}\mo x_{N}
\and \dotsb\and
X_{1}\mo x_{1}
\black \and \yI)
$$

for all possible $\red y$. All information about predictors for the previous instances, but not that about the predictands, appear in the conditional.


### More general and hybrid tasks

Consider a task that doesn't fit into any of the types discussed above: The agent wants to guess the predictands for a new instance, say #3, after observing that its predictors have value $\green x$. Of two previous instances, the agent knows the predictor value $\green x_1$ of the first, and the predictand value $\green y_2$ of the second. This task is expressed by the probability

$$
\P(\red
Y_{3}\mo y
\black\|
\green
X_{3}\mo x
\, \and\, 
Y_{2}\mo y_{2}
\and
X_{1}\mo x_{1}
\black \and \yI)
$$

\

:::{.callout-caution}
## {{< fa user-edit >}} Exercises

- Write down the general probability expression for the task of subsubtype "[all predictands of previous instances, but not the predictors, are known to the agent]{.midgrey}".

- What kind of task does the following probability express?:

    $$
\P(\red
Y_{N+1}\mo y_{N+1}
\and \dotsb \and
Y_{1}\mo y_{1}
\black\|
\green
X_{N+1}\mo x_{N+1}
\and \dotsb\and
X_{1}\mo x_{1}
\black \and \yI)
$$
    
	How could you call it, in machine-learning terminology?

:::

## The omnipresence of decision-making in machine learning

Many machine-learning textbooks say that

> in supervised learning the algorithm learns a functional relationship between some kind of input and some kind of output

Such statement is misleading, because it seems to imply that a functional relationship actually exists from input to output, or from predictor to predictand -- it's only waiting to be discovered and "learned". As we discussed in [chapter @sec-ml-introduction], in many important problems and applications this is actually not true: **there isn't any functional relationship between input and output at all**. Even if any possible "noise" were removed, there would still *not* be any functional relationship between the denoised, actual predictor and predictand ([here is an example](steven-seagal-emotion-chart.jpg){.external}).^[This is one more reason why we use the more general terms "predictor" & "predictand", rather that "input" & "output"]

In many important problems there's only a *statistical* relationship between predictands and predictors. In other words, whenever the agent saw a predictor value $\green X\mo x$, the predictand value turned out to be $\green Y\mo y'$ in a given number of instances, but also $\green Y\mo y''$ in a given number of other instances, and so on.

The lack of an actual predictor-predictand function has a very important consequence. If a machine-learning algorithm outputs just *one* predictand value, among the possible ones that are consistent with the predictor, then it means that **the algorithm must choose one of the possibilities**. How is this choice made? This is obviously a **decision-making problem**. As we know from chapters [-@sec-framework] and [-@sec-basic-decisions], the optimal choice is determined by Decision Theory. Its determination requires:

1. the probabilities of the possible predictand values
2. the utilities of the possible choices of values



***To be continued***

