# [Third connection with machine learning]{.red} {#sec-3-connection-ML}
{{< include macros.qmd >}}
{{< include macros_prob_inference.qmd >}}

In [chapter @sec-2-connection-ML] we made a second *tentative* connection between the notions about probability explored until then, and notions from machine learning. We considered the possibility that a machine-learning algorithm is like an agent that has some [built-in background information (corresponding to the algorithm's architecture)]{.yellow}, has received [pieces of information (corresponding to the data about perfectly known instances of the task, and possibly partial data about a new instance)]{.green}, and is assessing a [not-previously known piece of information (other partial aspects of a new task instance)]{.red}:

$$
\P(\underbracket[0ex]{\red\se{D}_{N+1}}_{\mathclap{\red\text{outcome?}}} \| 
\green\underbracket[0ex]{\se{D}_N \land \dotsb \land \se{D}_2 \land \se{D}_1}_{\mathclap{\green\text{training data?}}} 
\black\land \underbracket[0ex]{\yellow\yI}_{\mathrlap{\yellow\uparrow\ \text{architecture?}}})
$$

The correspondence about [training data]{.green} and [architecture]{.yellow} seems somewhat convincing, the one about [outcome]{.red} needs more exploration.

Having introduced the notion of quantity in the latest chapters [-@sec-quantities-types-basic] and [-@sec-quantities-types-multi], we recognize that training data about a task instance concern some quantity and its value, so they can be expressed by a sentence like $D_i\mo d_i$, where

- $i$ is the instance: $1,2,\dotsc,N$
- $D_i$ describes the kind of data at instance $i$, for example "128 × 128 image with 24-bit colour depth, with a character label"
- $d_i$ is the value of the data at instance $i$, for example the one here at the margin

:::{.column-margin}
![label = "Saitama"](saitama_smile.png){width=128 fig-cap-location="center"}
:::

And similarly for the outcome of a new task instance where the algorithm is applied for real, which we consider as instance $N+1$. So we can rewrite the correspondence above as follows:

$$
\P(\underbracket[0ex]{\red D_{N+1} \mo d_{N+1}}_{\mathclap{\red\text{outcome?}}} \| 
\green\underbracket[0ex]{ D_N \mo d_N \and \dotsb \and  D_2 \mo d_2 \and  D_1 \mo d_1}_{\mathclap{\green\text{training data?}}} 
\black\and \underbracket[0ex]{\yellow\yI}_{\mathrlap{\yellow\uparrow\ \text{architecture?}}})
$$

This kind of inference is what we explored in the "next-three-patients" scenario of [§ @sec-conditional-joint-sim] and some of the following sections.

\

Let's extend this tentative connection even further. It may be necessary to somewhat detach ourselves from common machine-learning categorizations or terminology that you learned in [chapter @sec-ml-introduction], because they focus on aspects that are secondary to us. Distinctions such as "supervised learning" vs "unsupervised learning" are of secondary importance to a data engineer for several reasons:

- {{< fa shuffle >}}\ \ They group together some types of tasks that are actually quite different from an inferential or decision-making viewpoint; and conversely they separate types of tasks that are quite similar.

- {{< fa bullseye >}}\ \ They focus on procedures rather than on purposes. The important questions to us are: [What do we wish to infer or choose?]{.blue} and [From which kind of information?]{.green} These questions define the problem we want to solve. The procedure may then be chosen depending on other contingent factors, resources, and so on.

<!-- It's somewhat like saying that the difference between car and aeroplane is that the latter has wings. Sure -- but *why?* The focus on wings misses the essential difference between these two means of transportation: they operate through different material media and exploit different kinds of physics; that's why the second has wings. -->


We shall introduce a different categorization that tries to focus on different cases of desired information and of available information.


## A task-oriented categorization of some machine-learning problems {#sec-cat-problems}

Let's jot down a convenient categorization of the types of *task* that machine-learning algorithms try to solve. Such a categorization is not meant to be clear-cut; it only provides a starting point from which to examine a new task. Many tasks will fall in between categories: every data-engineering or data-science problem is unique. We consider tasks where multiple "instances" with similar characteristics are involved.

### New instance: given vs generated

A first distinction can be made between

- [{{< fa sign-out-alt >}} {{< fa cube >}}\ \ tasks where an agent must itself *generate* a new instance]{.yellow}

- [{{< fa cube >}} {{< fa question >}}\ \ tasks where a new instance is given to an agent, who must *guess* some of its characteristics]{.green}

An example of the first type of task is image generation: an algorithm is given a collection of images and is asked to generate a new image based on them.

We shall see that these two types of task are actually quite close to each other, from the point of view of Decision Theory and Probability Theory.

:::{.small .midgrey}
The terms "discriminative" and "generative" are sometimes associated in machine learning with the two types of task. This association, however, is quite loose, because some tasks typically called "generative" actually belong to the first type. We shall therefore avoid these or other terms. It's enough to keep in mind the distinction between the two types of task above.
:::


### Guessing: all or some

Focusing on the second type of task (a new instance is given to the agent), we can further divide it into two subtypes:

- [{{< fa regular star >}}\ \ the agent must guess *all* characteristics of the new instance]{.purple}

- [{{< fa star-half-alt >}}\ \ the agent must guess *some* characteristics of the new instance, but can observe other characteristics of the new instance]{.red}

An example of the first subtype of task is the "urgent vs non-urgent" problem of [§ @sec-conditional-joint-sim]: having observed incoming patients, some of which where urgent and some non-urgent, the agent must guess whether the next incoming patient will be urgent or not. No other kinds of information (transport, patient characteristics, and so on) are available for any patient.

We shall call [**predictands**]{.blue}^[literally "what has to be predicted] the characteristics that the agent must guess in a new instance, and [**predictors**]{.blue} those that the agent can observe.^[In machine learning and other fields, the terms "dependent variable", "class" or "label" (for nominal variates) are often used for "predictand"; and the terms "independent variable" or "features" are often used for "predictor".] The first subtype above can be viewed as a special case of the second where all characteristics are predictands, and there are no predictors.

:::{.small .midgrey}
The terms "unsupervised learning" and "supervised learning" are sometimes associated in machine learning with these two subtypes of task. But also in this case the association is loose and can be misleading. "Clustering" tasks, for example, are usually called "unsupervised" but they are examples of the second subtype above, where the agent has some predictors.
:::

### Information available in previous instances

Finally we can further divide the second subtype above into two or three subsubtypes, depending on the information available to the agent about *previous instances*:

- [{{< fa star-half-alt >}} {{< fa star-half-alt >}}\ \ all predictors and predictands of previous instances are known to the agent ]{.blue}

- [{{< fa star-half >}} {{< fa star-half >}}\ \ all predictors of previous instances, but not the predictands, are known to the agent]{.lightblue}

- [{{< fa regular star-half >}} {{< fa regular star-half >}}\ \ all predictands of previous instances, but not the predictors, are known to the agent]{.midgrey}

\

An example of the first subsubtype of task is image classification. The agent is for example given the following 128 × 128-pixel images and character-labels from the [One Punch Man](https://onepunchman.fandom.com) series:

![](saitama_images.png){width=100%}

and is then given one new 128 × 128-pixel image:

![](saitama_new.png){width=128 fig-align="center"}

of which it must guess the character-label.

In the example just given, the image is the predictor, the character-label is the predictand.

\

A slight modification of the example above gives us a task of the second subsubtype. A different agent is given the images above, but without labels:

![](saitama_images_nolabels.png){width=100%}

and must then guess some kind of "label" or "group" for the new image above -- and possibly even for the images already given. The kind of "group" requested depends on the specific problem.

In the new example above, the image is still the predictor, and the label or group is the predictand.

\

:::{.small .midgrey}
The term "supervised learning" typically refer to the first subsubtype above.

The term "unsupervised learning" can refer to the second subsubtype, for instance in "clustering" tasks. In a clustering task, the agent tries to guess which group or "cluster" an instance belong to, given a collection of similar instances, whose groups are not known either. The cluster effectively is the *predictand* quantity. In some cases the agent may want to guess the cluster not only of a new instance, but also of all previous instances.

The third subsubtype is very rarely considered in machine learning, yet it is not an unrealistic task.
:::

\

The types, subtypes, subsubtypes above are obviously not mutually exclusive or comprehensive. We can easily imagine scenarios where an agent has some predictors \& predictands available about *some* previous instances, but only predictors or only predictands available for other previous instances. This scenario falls in between the three subsubtypes above. In machine learning, hybrid situations like these are categorized as "missing data".


## Flexible categorization from the point of view of probability theory [#sec-categ-probtheory]

### Notation

Let's introduce some symbol conventions to be used in the next chapters.

***To be continued***



## The omnipresence of decision-making in machine learning

A statement that is also common in machine-learning textbooks is that

> in supervised learning the algorithm learns a functional relationship between some kind of input and some kind of output

Such statement is misleading, because it seems to imply that a functional relationship actually exists between some quantities, only waiting to be discovered and "learned". In many important problems and applications, for example in medicine, this is actually not true: **there isn't any functional relationship between input and output at all**. Even if any possible "noise" were removed, there would still *not* be any functional relationship between the clean, actual input and output ([here is an example](steven-seagal-emotion-chart.jpg){.external}). From this point of view the very terms "input" and "output" become somewhat misleading.

In many important problems there's only a *statistical* or *probabilistic* relationship between quantities that we can observe and quantities that we'd like to infer.

The lack of a real input-output function has a very important consequence. If a machine-learning algorithm yields only *one* output among the possible ones that are consistent with the input, then it means that **the machine-learning algorithm must choose one of the possibilities**. How is this choice made? This is obviously a decision-making problem, and as we know from chapters [-@sec-framework] and [-@sec-basic-decisions] the optimal choice is determined by Decision Theory. Its determination requires:

1. the probabilities of the possible outputs
2. the utilities of the possible choices of output



***To be continued***

