[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ADA511Data science and data-driven engineering",
    "section": "",
    "text": "Preface\nTo be written."
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "To be written: motivation and structure of this course."
  },
  {
    "objectID": "statements.html#statements-or-what-is-data",
    "href": "statements.html#statements-or-what-is-data",
    "title": "2  Data: use and communication",
    "section": "2.1 Statements – or, what is “data”?",
    "text": "2.1 Statements – or, what is “data”?\nWhat is “data”?\n“Data” (from Latin “given”) is used more or less in the same sense as “information”, and in these notes we’ll use the two words as synonyms.\n“Data” is often presented as numbers; but it’s obviously more than that. I give you this number: “8”. Is it “data”? what is it about? what should you do with it? We can hardly call this number a piece of information, since we have no clue what we could do with it. Instead, if I tell you: “The number of official planets in the solar system is 8”, then we can say that I’ve given you data. So “data” is not just numbers. A number is not “data” unless there’s some verbal, non-numeric context associated with it – even if this context is only implicitly understood.\nData can also be completely non-numeric. A clinician saying “The patient has fully recovered from the disease” (we imagine to know who’s the patient and what was the disease) is giving us a piece of information that we could further use, for instance, to make prognoses about other, similar patients. The clinician’s statement surely is “data”. It is essentially non-numeric data, even if in some situations we can represent it as “1”, say, while “0” would represent “not recovered”.\nFrom these two examples, and with some further thought, we realize that “data” – and in general any piece of information or hypothesis – can universally be represented and communicated by statements , also called sentences or propositions1. In some cases we can summarize or represent such statements as numbers. But the numbers alone, by themselves, are not data.1 These terms are not equivalent in Logic, but we’ll use them as synonyms here.\nSo our conclusion is that information or data is represented by statements."
  },
  {
    "objectID": "statements.html#well-posed-and-ill-posed-statements",
    "href": "statements.html#well-posed-and-ill-posed-statements",
    "title": "2  Data: use and communication",
    "section": "2.2 Well-posed and ill-posed statements",
    "text": "2.2 Well-posed and ill-posed statements\nWe face problems when the statements that should convey information and data are not clear. Suppose that an electric-car model consumes 150 Wh/km and has a range of 200 km; a second car model consumes 250 Wh/km and has a range of 600 km. Someone says “I think the second model is better; what do you think?”. It isn’t clear how we should answer; what does “better” mean? If it refers to consumption, then the first car model is “better”. If it refers to range, then the second model is “better”. If it refers to a combination of these two characteristics, or to something else, then we simply can’t answer. Here we have a problem with querying and giving data, because the statement underlying such query is not clear.\nWe say that such statement are not well-posed, or that they are ill-posed.\nThis may seem an obvious discussion to you. Yet you’d be surprised by how often unclear statements appear in scientific papers about data engineering! Not seldom we find discussions and disagreements that actually come from unclear underlying statements, that two parties interpret in different ways.\nAs a data engineer, you’ll often have the upper hand if you are on the lookout for ill-posed statements. Whenever you face an important question, or you’re given an important piece of information, or you must provide an important piece of information, always take a little time to examine whether the question or information is actually well-posed.\n\n[TODO] Exercise: give actual paper to analyse"
  },
  {
    "objectID": "statements.html#reading-list",
    "href": "statements.html#reading-list",
    "title": "2  Data: use and communication",
    "section": "Reading list",
    "text": "Reading list"
  },
  {
    "objectID": "inference.html#what-is-inference",
    "href": "inference.html#what-is-inference",
    "title": "3  Inference",
    "section": "3.1 What is inference?",
    "text": "3.1 What is inference?\nOne core problem in all data-driven engineering applications – and in daily life too – is that we would like to know something that we don’t know. In other words, we would like to have more information. We may wish to acquire information out of simple curiosity; or we may need it for some specific reason or goal, as we’ll discuss later. Examples:\n\nWe’d like to know whether it’ll rain today, so we can decide whether to get an umbrella or rain clothes, or not to.\n\n\n\nA clinician would like to know which disease affects a patient, so as to decide for the optimal treatment.\nThe X-player of this game of Xs & Os: needs to know where put the next X in order to win.\nThe computer of a self-driving car needs to know whether a particular patch of colours in the visual field is a person, so as to slow down the car and stop.\nA rocket engineer needs to know how much is \\(\\sqrt{2\\,G\\,M\\,r}\\), where \\(G=6.67 \\cdot 10^{-11}\\,\\mathrm{m^3\\,s^{-2}\\,kg^{-1}}\\), and \\(M\\) and \\(r\\) are the mass and radius of the Earth, in order to launch a rocket to the Moon.\nAn aircraft’s autopilot system needs to predict how altering a wing’s attack edge will change the aircraft’s roll."
  },
  {
    "objectID": "truth_probability_inference.html#truth-falsity-and-their-consistency",
    "href": "truth_probability_inference.html#truth-falsity-and-their-consistency",
    "title": "4  Truth inference and probability inference",
    "section": "4.1 Truth, falsity, and their consistency",
    "text": "4.1 Truth, falsity, and their consistency"
  },
  {
    "objectID": "truth_probability_inference.html#inferences-without-uncertainty-the-truth-calculus",
    "href": "truth_probability_inference.html#inferences-without-uncertainty-the-truth-calculus",
    "title": "4  Truth inference and probability inference",
    "section": "4.2 Inferences without uncertainty: the truth calculus",
    "text": "4.2 Inferences without uncertainty: the truth calculus"
  },
  {
    "objectID": "truth_probability_inference.html#making-room-for-uncertainty-plausibility-credibility-degree-of-belief-probability",
    "href": "truth_probability_inference.html#making-room-for-uncertainty-plausibility-credibility-degree-of-belief-probability",
    "title": "4  Truth inference and probability inference",
    "section": "4.3 Making room for uncertainty:Plausibility, credibility, degree of belief, probability",
    "text": "4.3 Making room for uncertainty:Plausibility, credibility, degree of belief, probability"
  },
  {
    "objectID": "truth_probability_inference.html#inferences-with-uncertainty-the-probability-calculus",
    "href": "truth_probability_inference.html#inferences-with-uncertainty-the-probability-calculus",
    "title": "4  Truth inference and probability inference",
    "section": "4.4 Inferences with uncertainty: the probability calculus",
    "text": "4.4 Inferences with uncertainty: the probability calculus\n\n4.4.1 The Three Fundamental Laws of inference\n\nExercise: Monty-Hall problem & variations\nExercise: clinical test & diagnosis\n\n\n\n4.4.2 Bayes’s theorem"
  },
  {
    "objectID": "truth_probability_inference.html#common-points-of-certain-and-uncertain-inference",
    "href": "truth_probability_inference.html#common-points-of-certain-and-uncertain-inference",
    "title": "4  Truth inference and probability inference",
    "section": "4.5 Common points of certain and uncertain inference",
    "text": "4.5 Common points of certain and uncertain inference\n\nNo premises? No conclusions!"
  },
  {
    "objectID": "data_information.html#kinds-of-data",
    "href": "data_information.html#kinds-of-data",
    "title": "5  Data and information",
    "section": "5.1 Kinds of data",
    "text": "5.1 Kinds of data\n\n5.1.1 Binary\n\n\n5.1.2 Nominal\n\n\n5.1.3 Ordinal\n\n\n5.1.4 Continuous\n\nunbounded\nbounded\ncensored\n\n\n\n5.1.5 Complex data\n2D, 3D, images, graphs, etc.\n\n\n5.1.6 “Soft” data\n\norders of magnitude\nphysical bounds"
  },
  {
    "objectID": "data_information.html#data-transformations",
    "href": "data_information.html#data-transformations",
    "title": "5  Data and information",
    "section": "5.2 Data transformations",
    "text": "5.2 Data transformations\n\nlog\nprobit\nlogit"
  },
  {
    "objectID": "probability_distributions.html#the-difference-between-statistics-and-probability-theory",
    "href": "probability_distributions.html#the-difference-between-statistics-and-probability-theory",
    "title": "6  Allocation of uncertainty among possible data values: probability distributions",
    "section": "6.1 The difference between Statistics and Probability Theory",
    "text": "6.1 The difference between Statistics and Probability Theory\nStatistics is the study of collective properties of collections of data. It does not imply that there is any uncertainty.\nProbability theory is the quantification and propagation of uncertainty. It does not imply that we have collections of data."
  },
  {
    "objectID": "probability_distributions.html#whats-distributed",
    "href": "probability_distributions.html#whats-distributed",
    "title": "6  Allocation of uncertainty among possible data values: probability distributions",
    "section": "6.2 What’s “distributed”?",
    "text": "6.2 What’s “distributed”?\nDifference between distribution of probability and distribution of (a collection of) data."
  },
  {
    "objectID": "probability_distributions.html#distributions-of-probability",
    "href": "probability_distributions.html#distributions-of-probability",
    "title": "6  Allocation of uncertainty among possible data values: probability distributions",
    "section": "6.3 Distributions of probability",
    "text": "6.3 Distributions of probability\n\n6.3.1 Representations\n\nDensity function\nHistogram\nScatter plot\n\nBehaviour of representations under transformations of data."
  },
  {
    "objectID": "probability_distributions.html#summaries-of-distributions-of-probability",
    "href": "probability_distributions.html#summaries-of-distributions-of-probability",
    "title": "6  Allocation of uncertainty among possible data values: probability distributions",
    "section": "6.4 Summaries of distributions of probability",
    "text": "6.4 Summaries of distributions of probability\n\n6.4.1 Location\nMedian, mean\n\n\n6.4.2 Dispersion or range\nQuantiles & quartiles, interquartile range, median absolute deviation, standard deviation, half-range\n\n\n6.4.3 Resolution\nDifferential entropy\n\n\n6.4.4 Behaviour of summaries under transformations of data and errors in data"
  },
  {
    "objectID": "probability_distributions.html#outliers-and-out-of-population-data",
    "href": "probability_distributions.html#outliers-and-out-of-population-data",
    "title": "6  Allocation of uncertainty among possible data values: probability distributions",
    "section": "6.5 Outliers and out-of-population data",
    "text": "6.5 Outliers and out-of-population data\n(Warnings against tail-cutting and similar nonsense-practices)"
  },
  {
    "objectID": "probability_distributions.html#marginal-and-conditional-distributions-of-probability",
    "href": "probability_distributions.html#marginal-and-conditional-distributions-of-probability",
    "title": "6  Allocation of uncertainty among possible data values: probability distributions",
    "section": "6.6 Marginal and conditional distributions of probability",
    "text": "6.6 Marginal and conditional distributions of probability"
  },
  {
    "objectID": "probability_distributions.html#collecting-and-sampling-data",
    "href": "probability_distributions.html#collecting-and-sampling-data",
    "title": "6  Allocation of uncertainty among possible data values: probability distributions",
    "section": "6.7 Collecting and sampling data",
    "text": "6.7 Collecting and sampling data\n\n6.7.1 “Representative” samples\nSize of minimal representative sample = (2^entropy)/precision\n\nExercise: data with 14 binary variates, 10000 samples\n\n\n\n6.7.2 Unavoidable sampling biases\nIn high dimensions, all datasets are outliers.\nData splits and cross-validation cannot correct sampling biases"
  },
  {
    "objectID": "probability_distributions.html#quirks-and-warnings-about-high-dimensional-data",
    "href": "probability_distributions.html#quirks-and-warnings-about-high-dimensional-data",
    "title": "6  Allocation of uncertainty among possible data values: probability distributions",
    "section": "6.8 Quirks and warnings about high-dimensional data",
    "text": "6.8 Quirks and warnings about high-dimensional data"
  },
  {
    "objectID": "making_decisions.html#decisions-possible-situations-and-consequences",
    "href": "making_decisions.html#decisions-possible-situations-and-consequences",
    "title": "7  Making decisions",
    "section": "7.1 Decisions, possible situations, and consequences",
    "text": "7.1 Decisions, possible situations, and consequences"
  },
  {
    "objectID": "making_decisions.html#gains-and-losses-utilities",
    "href": "making_decisions.html#gains-and-losses-utilities",
    "title": "7  Making decisions",
    "section": "7.2 Gains and losses: utilities",
    "text": "7.2 Gains and losses: utilities\n\n7.2.1 Factors that enter utility quantification\nUtilities can rarely be assigned a priori."
  },
  {
    "objectID": "making_decisions.html#making-decisions-under-uncertainty-maximization-of-expected-utility",
    "href": "making_decisions.html#making-decisions-under-uncertainty-maximization-of-expected-utility",
    "title": "7  Making decisions",
    "section": "7.3 Making decisions under uncertainty: maximization of expected utility",
    "text": "7.3 Making decisions under uncertainty: maximization of expected utility"
  }
]