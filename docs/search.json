[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ADA511: Data science and data-driven engineering",
    "section": "",
    "text": "Preface\n**WARNING: THIS IS A WORKING DRAFT. TEXT WILL CHANGE A LOT. MANY PASSAGES ARE JUST TEMPORARY, INCOHERENT, AND DISJOINTED.\nTo be written."
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "To be written: motivation and structure of this course."
  },
  {
    "objectID": "sentences.html#sentences-or-what-is-data",
    "href": "sentences.html#sentences-or-what-is-data",
    "title": "2  Data: use and communication",
    "section": "2.1 Sentences – or, what is “data”?",
    "text": "2.1 Sentences – or, what is “data”?\nWhat is “data”?\n“Data” (from Latin “given”) is used more or less in the same sense as “information”, and in these notes we’ll use the two words as synonyms.\n“Data” is often presented as numbers; but it’s obviously more than that. I give you this number: “8”. Is it “data”? what is it about? what should you do with it? We can hardly call this number a piece of information, since we have no clue what we could do with it. Instead, if I tell you: “The number of official planets in the solar system is 8”, then we can say that I’ve given you data. So “data” is not just numbers. A number is not “data” unless there’s some verbal, non-numeric context associated with it – even if this context is only implicitly understood.\nData can also be completely non-numeric. A clinician saying “The patient has fully recovered from the disease” (we imagine to know who’s the patient and what was the disease) is giving us a piece of information that we could further use, for instance, to make prognoses about other, similar patients. The clinician’s statement surely is “data”. It is essentially non-numeric data, even if in some situations we can represent it as “1”, say, while “0” would represent “not recovered”.\nFrom these two examples, and with some further thought, we realize that “data” – and in general any piece of information or hypothesis – can universally be represented and communicated by sentences , also called statements or propositions1. In some cases we can summarize or represent such sentences as numbers. But the numbers alone, by themselves, are not data.1 These terms are not equivalent in Logic, but sometimes we’ll use them as synonyms.\nSo our conclusion is that information or data is represented by sentences.\nRecognizing that data and information are ultimately sentences has important practical consequences:\n\nClarity and goal-orientation.\n\nAs a data engineer you’ll have to acquire information and convey information. Acquiring information is not simply making some measurement or counting something: you must understand what you are measuring and why. If you gather data from third parties, you have to ask what exactly the data mean and how they were acquired. In designing and engineering a solution, you’ll have to understand what information or outcomes the end user exactly wants. It will often happen that you ask “wait, what do you mean by that?”; this question is not just an unofficial parenthesis in the official data-transfer workflow between you and someone else: it is an integral part of that workflow, it means that the data has not been completely transferred yet.\n\nArtificial Intelligence\n\nSentences are the central components of knowledge representation and inference in artificial-intelligence agents.\n\n\n\n\n\n\n\n\n\n\nReading material\n\n\n\n§ 7.1 in Artificial Intelligence"
  },
  {
    "objectID": "sentences.html#well-posed-and-ill-posed-sentences",
    "href": "sentences.html#well-posed-and-ill-posed-sentences",
    "title": "2  Data: use and communication",
    "section": "2.2 Well-posed and ill-posed sentences",
    "text": "2.2 Well-posed and ill-posed sentences\nWe face problems when the sentences that should convey information and data are not clear. Suppose that an electric-car model consumes 150 Wh/km and has a range of 200 km; a second car model consumes 250 Wh/km and has a range of 600 km. Someone says “I think the second model is better; what do you think?”. It isn’t clear how we should answer; what does “better” mean? If it refers to consumption, then the first car model is “better”. If it refers to range, then the second model is “better”. If it refers to a combination of these two characteristics, or to something else, then we simply can’t answer. Here we have a problem with querying and giving data, because the sentence underlying such query is not clear.\nWe say that such sentences are not well-posed, or that they are ill-posed.\nThis may seem an obvious discussion to you. Yet you’d be surprised by how often unclear sentences appear in scientific papers about data engineering! Not seldom we find discussions and disagreements that actually come from unclear underlying sentences, that two parties interpret in different ways.\nAs a data engineer, you’ll often have the upper hand if you are on the lookout for ill-posed sentences. Whenever you face an important question, or you’re given an important piece of information, or you must provide an important piece of information, always take a little time to examine whether the question or information is actually well-posed.\n\n[TODO] Exercise: give actual paper to analyse"
  },
  {
    "objectID": "sentences.html#reading-list",
    "href": "sentences.html#reading-list",
    "title": "2  Data: use and communication",
    "section": "Reading list",
    "text": "Reading list"
  },
  {
    "objectID": "inference.html#what-is-inference",
    "href": "inference.html#what-is-inference",
    "title": "3  Inference",
    "section": "3.1 What is inference?",
    "text": "3.1 What is inference?\nThe first core problem in all data-driven engineering applications – and in daily life too – is to draw inferences, that is, acquire information. We may wish to acquire information out of simple curiosity, or for some specific engineering reason or goal, as we’ll discuss later. Examples:\n\nWe’d like to know whether it’ll rain today, so we can decide whether to get an umbrella or rain clothes.\n\n\n\nA clinician would like to know which disease affects a patient, so as to decide for the optimal treatment.\nThe X-player of this game of Xs & Os:  needs to know where put the next X in order to win.\nThe computer of a self-driving car needs to know whether a particular patch of colours in the visual field is a person, so as to slow down the car and stop.\nIn order to launch a rocket to the Moon, a rocket engineer needs to know, within two significant digits, how much is the velocity \\(\\sqrt{2\\,G\\,M/r\\,}\\), where \\(G=6.67 \\cdot 10^{-11}\\,\\mathrm{m^3\\,s^{-2}\\,kg^{-1}}\\), and \\(M = 5.97 \\cdot 10^{24}\\,\\mathrm{kg}\\) and \\(r = 6.37 \\cdot 10^{6}\\,\\mathrm{m}\\) are the mass and radius of the Earth.\nWe’d like to know whether the rolled die will show ⚅, so we can win a bet.\nAn aircraft’s autopilot system needs to predict how much the aircraft’s roll will change by increasing the right wing’s angle of attack by 0.1 rad.\nAn archaeologist would like to know whether the fossil bone just dug out belonged to a Tyrannosaurus rex.\nAn automated system in an assembly line needs to predict whether an electric component of a widget will fail within the next two years.\n\nNote how each of these inferences boils down to determining whether some sentences are true or false. In example 1. we want to know whether the sentence \\(\\textsf{\\small`It rains today`}\\) is true or not. In example 2. the clinician wants to know which of the sentences \\(\\textsf{\\small`The patient has pneumonia`}\\), \\(\\textsf{\\small`The patient has asthma`}\\), \\(\\textsf{\\small`The patient has bronchitis`}\\), and so on, are true (several can be true at the same time). In example 5. the rocket engineer wants to know which among the sentences \\(\\textsf{\\small`The velocity is 0.010\\,m/s`}\\), \\(\\textsf{\\small`The velocity is 0.011\\,m/s`}\\), …, \\(\\textsf{\\small`The velocity is 130\\,m/s`}\\), and so on, is true. The sentences that underlie an inference can be extremely many and complex, and yet we must have an idea of what they are (otherwise, do we really know what our inference is about?).\n\n\n\n\n\n\nExercise\n\n\n\nTry to identify which sentences underlie the other example inferences above."
  },
  {
    "objectID": "inference.html#certain-and-uncertain-inference",
    "href": "inference.html#certain-and-uncertain-inference",
    "title": "3  Inference",
    "section": "3.2 Certain and uncertain inference",
    "text": "3.2 Certain and uncertain inference\nThe example inferences above present very different levels of difficulty.\nInferences 3. and 5. are special because they can actually be drawn exactly, that is, we really find out which of their underlying sentences are true and false. In example 3. it is trivial that putting the next X in the mid-right slot makes the X-player win. In example 5. a couple of mathematical operations show that the sentence \\(\\textsf{\\small`The velocity is 11\\,km/s`}\\) is true. When we can obtain the data we want from the data we have by using “only”1 logic and mathematical operations, our inference is certain, also called a “deduction”; in these notes we shall call it a truth inference. But every deduction can be basically drawn by repeatedly applying the rules of logic.1 “Only” in quotation marks because the logical analysis and operations leading to the answer can still be computationally very expensive.\nThe other example inferences cannot be drawn exactly, in the sense that we cannot know for sure whether all their underlying sentences are true or false. But this doesn’t mean that we cannot say anything whatsoever. In example 6. we consider the sentence \\(\\textsf{\\small`The die shows ⚅`}\\) to be more likely false than true. In example 2. the clinician might be quite sure about the disease, after observing the symptoms. On the other hand, in example 1. we might really have no clue whether \\(\\textsf{\\small`It rains today`}\\) will turn out to be true or false. These inferences are uncertain. Certain inferences can be considered as a limit case of uncertain ones, in which the uncertainty vanishes or is extremely small.\nTo draw certain inferences, we follow the rules of Logic. What rules do we follow to draw uncertain inferences?"
  },
  {
    "objectID": "truth_inference.html#building-blocks",
    "href": "truth_inference.html#building-blocks",
    "title": "4  Truth inference",
    "section": "4.1 Building blocks",
    "text": "4.1 Building blocks\nConsider the following trivial but certain inference: \\[\n\\frac{\n\\textsf{\\small`My umbrella is either blue or red`}\\quad\n\\textsf{\\small`My umbrella is not red`}\n}{\n\\textsf{\\small`My umbrella is blue`}\n\\textsf{\\small`My umbrella is not red`}\n}\n\\] Above the line we write the sentences representing the data we have. Below the line we infer the information that supposedly interests us.\nHow could we draw this obvious inference? Which rules did we follow?\nLogic is a huge field that formalizes and makes rigorous the rules that a rational person or an artificial intelligence should use in drawing certain inferences. We’ll get a glimpse of it here, as a trampoline for jumping towards our data-driven engineering problems.\n\nBasic sentences\nWe start by writing down the basic1 sentences that constitute our data and that underlie the inferences we want to draw. “Basic” in the sense that we will not analyse these sentences into further sub-sentences. In the trivial example above we identify two such sentences: \\(\\textsf{\\small`My umbrella is blue`}\\), and \\(\\textsf{\\small`My umbrella is pink`}\\). Let’s represent them by symbols: \\[\n\\begin{aligned}\nb &\\coloneqq \\textsf{\\small`My umbrella is blue`}\n\\\\\nr &\\coloneqq \\textsf{\\small`My umbrella is red`}\n\\end{aligned}\n\\]1 A more technical term is “atomic”\n\n\n\n\n\n\n\n\n\n\nNote a subtlety in our data – and again why we need to make their underlying sentences as clear as possible: it is understood here that my umbrella is all of one colour.\n\n\n\n\nConnectives\nYou notice that we didn’t consider \\(\\textsf{\\small`My umbrella is either blue or red`}\\) and \\(\\textsf{\\small`My umbrella is not red`}\\) as basic sentences. These sentences can indeed be expressed in terms of the basic sentences \\(b\\) and \\(r\\). We consider one way or operation to change a sentence into another related to it, and two ways or operations to combine two or more sentences together. These operations are called “connectives”. Our natural language offer many more operations to combine sentences, but these three turn out to be all we need in virtually all engineering problems. The three connectives are:\n\nNot: \\(\\lnot\\)\n\nfor example, \\[\n\\lnot r = \\textsf{\\small`My umbrella is not red`}\n\\]\n\nAnd: \\(\\land\\)\n\nfor example, \\[\nb \\land r = \\textsf{\\small`My umbrella is blue, and it is red`}\n\\]\n\nOr: \\(\\lor\\)\n\nfor example, \\[\nb \\lor r = \\textsf{\\small`My umbrella is blue, or red, or both`}\n\\]\n\n\n\n\n\n\n\n\n\n\n\n\nNote some subtleties of the connectives:\n\n“Not” doesn’t mean some kind of complementary quality, but only the negation. For instance, \\(\\lnot\\textsf{\\small`The chair is black`}\\) does not mean \\(\\textsf{\\small`The chair is white`}\\).\n\\(b \\lor r\\) does not exclude, a priori, that my umbrella cannot be both blue and black (there is a connective for that: “exclusive-or”, but it can be constructed out of the three we already have.)\n\n\n\nFrom this last remark we see that the sentence \\(\\textsf{\\small`My umbrella is either blue or red`}\\) does not correspond to \\(b \\lor r\\). The sentence also means implicitly that my umbrella cannot be both blue or red. We could rewrite it as \\(\\textsf{\\small`My umbrella is either blue or red, and it is not both blue and red`}\\). Convince yourself that in symbols we can write it like this: \\[\n(b \\lor r) \\land \\lnot(b \\land r) =\n\\textsf{\\small`My umbrella is either blue or red`}\n\\]\n\n\nData or axioms\nNow we have the sentences to represent our data, and even symbols to represent it in a compact way. But what do our data actually say? They say that the sentences \\(\\textsf{\\small`My umbrella is either blue or red`}\\) and \\(\\textsf{\\small`My umbrella is not red`}\\) are true. Here’s how we express this in symbols.\nWe represent our data by the symbol \\(D\\) and use the notation22 Current notation in logic writes \\(D\\models \\lnot r.\\) We use a different notation for an easier transition to probability logic.\n\\[\n\\begin{aligned}\n\\lnot r \\nonscript\\:\\vert\\nonscript\\:\\mathopen{}&D\n\\\\\n(b \\lor r) \\land \\lnot(b \\land r) \\nonscript\\:\\vert\\nonscript\\:\\mathopen{}&D\n\\end{aligned}\n\\]\nto mean that \\(\\textsf{\\small`My umbrella is not red`}\\) and \\(\\textsf{\\small`My umbrella is either blue or red`}\\) are true according to our data.\nWith this notation we can also augment our data with additional assumptions or hypotheses, even if just temporarily. For example,\n\\[\n\\lnot r \\nonscript\\:\\vert\\nonscript\\:\\mathopen{}b \\land D\n\\]\nmeans that \\(\\textsf{\\small`My umbrella is not red`}\\) is true according to data \\(D\\) together with the additional assumption that \\(\\textsf{\\small`My umbrella is blue`}\\) is true."
  },
  {
    "objectID": "truth_inference.html#truth-inference-rules",
    "href": "truth_inference.html#truth-inference-rules",
    "title": "4  Truth inference",
    "section": "4.2 Truth-inference rules",
    "text": "4.2 Truth-inference rules\nDeduction systems in formal logic give us a set of rules for making correct inferences. These rules can be represented in a wide variety of ways. For instance as lines: above, we write what the data say; below, what inference we can draw. An example is this:\n\\[\n\\frac{\na \\land b \\nonscript\\:\\vert\\nonscript\\:\\mathopen{} D\n}{\na \\nonscript\\:\\vert\\nonscript\\:\\mathopen{} D\n}\n\\tag{4.1}\\]\nIn total there are a dozen or so rules of this kind.\nBut we can compactly encode all these rules in the following way. First, represent true with the number \\(1\\), and false with \\(0\\). Second, express the fact that a sentence \\(a\\) – which can be made of subsentences combined by connectives – is true according to data \\(D\\) by writing\n\\[\n\\mathrm{T}(a \\nonscript\\:\\vert\\nonscript\\:\\mathopen{} D) = 1\n\\]\nand that it is false according to \\(D\\) by writing\n\\[\n\\mathrm{T}(a \\nonscript\\:\\vert\\nonscript\\:\\mathopen{} D) = 0\n\\]\nThen the rules of truth inference are summarized by the following equations, which must always hold:\n\n\n\nRule for “not”:\n\n\\[\\mathrm{T}(\\lnot a \\nonscript\\:\\vert\\nonscript\\:\\mathopen{} D)\n+ \\mathrm{T}(a \\nonscript\\:\\vert\\nonscript\\:\\mathopen{} D)\n= 1 \\tag{4.2}\\]\n\nRule for “and”:\n\n\\[\n\\mathrm{T}(a \\land b \\nonscript\\:\\vert\\nonscript\\:\\mathopen{} D)\n= \\mathrm{T}(a \\nonscript\\:\\vert\\nonscript\\:\\mathopen{} b \\land D) \\cdot\n\\mathrm{T}(b \\nonscript\\:\\vert\\nonscript\\:\\mathopen{} D)\n= \\mathrm{T}(b \\nonscript\\:\\vert\\nonscript\\:\\mathopen{} a \\land D) \\cdot\n\\mathrm{T}(a \\nonscript\\:\\vert\\nonscript\\:\\mathopen{} D)\n\\tag{4.3}\\]\n\nRule for “or”:\n\n\\[\\mathrm{T}(a \\lor b \\nonscript\\:\\vert\\nonscript\\:\\mathopen{} D)\n= \\mathrm{T}(a \\nonscript\\:\\vert\\nonscript\\:\\mathopen{} D) +\n\\mathrm{T}(b \\nonscript\\:\\vert\\nonscript\\:\\mathopen{} D)\n- \\mathrm{T}(a \\land b \\nonscript\\:\\vert\\nonscript\\:\\mathopen{} D)\n\\tag{4.4}\\]\n\nRule of self-consistency:\n\n\\[\\mathrm{T}(a \\nonscript\\:\\vert\\nonscript\\:\\mathopen{} a \\land D)\n= 1\n\\tag{4.5}\\]\n\n\n\n\n\n\nLet’s see how the inference rule (4.1), for example, is encoded in these equations. The rule starts with saying that \\(a \\land b\\) is true according to \\(D\\). This means that \\(\\mathrm{T}(a \\land b \\nonscript\\:\\vert\\nonscript\\:\\mathopen{} D)=1\\). But, by rule (4.3), we must then have \\(\\mathrm{T}(b \\nonscript\\:\\vert\\nonscript\\:\\mathopen{} a \\land D) \\cdot \\mathrm{T}(a \\nonscript\\:\\vert\\nonscript\\:\\mathopen{} D) = 1\\). This can only happen if both \\(\\mathrm{T}(b \\nonscript\\:\\vert\\nonscript\\:\\mathopen{} a \\land D)\\) and \\(\\mathrm{T}(a \\nonscript\\:\\vert\\nonscript\\:\\mathopen{} D)\\) are equal to \\(1\\). So we can conclude that \\(\\mathrm{T}(a \\nonscript\\:\\vert\\nonscript\\:\\mathopen{} D)=1\\), which is exactly the conclusion under the line in rule (4.1).\n\n\n\n\n\n\nExercise\n\n\n\nTry to prove our initial inference\n\\[\n\\frac{\n(b \\lor r) \\land \\lnot (b \\land r) \\nonscript\\:\\vert\\nonscript\\:\\mathopen{} D\n\\qquad\n\\lnot r \\nonscript\\:\\vert\\nonscript\\:\\mathopen{} D\n}{\nb\\nonscript\\:\\vert\\nonscript\\:\\mathopen{} D\n}\n\\]\nusing the basic rules (4.2, 4.3, 4.4, 4.5). Remember that you can use each rule as many times as you like, and that there is not only one way of constructing a proof."
  },
  {
    "objectID": "truth_inference.html#logical-ai-agents-and-their-limitations",
    "href": "truth_inference.html#logical-ai-agents-and-their-limitations",
    "title": "4  Truth inference",
    "section": "4.3 Logical AI agents and their limitations",
    "text": "4.3 Logical AI agents and their limitations\nThe basic rules above are also the rules that a logical artificial-intelligent agent should follow.\n\n\n\n\n\n\n\n\nReading material\n\n\n\nCh. 7 in Artificial Intelligence\n\n\nMany – if not most – inference problems that a data engineer must face are, however, of the uncertain kind: it is not possible to surely infer the truth of some data, and the truth of some initial data may not be known either. In the next chapter we shall see how to generalize the logic rules to uncertain situations.\n\n\n\n\n\n\nExtra reading material\n\n\n\nOur cursory visit of formal logic only showed a microscopic part of this vast field. The study of logic rules continues still today, with many exciting developments and applications. Feel free take a look at Logic in Computer Science, Mathematical Logic for Computer Science, Natural Deduction Systems in Logic"
  },
  {
    "objectID": "probability_inference.html#when-truth-isnt-known",
    "href": "probability_inference.html#when-truth-isnt-known",
    "title": "5  Probability inference",
    "section": "5.1 When truth isn’t known",
    "text": "5.1 When truth isn’t known\nIn most real-life and engineering situations we don’t know the truth or falsity of sentences that interest us. But this doesn’t mean that nothing can be said or done in such situations.\nWhen we cross a busy city street we look left and right to check whether any cars are approaching. We typically don’t look up to check whether something is falling from the sky. Yet, couldn’t it be false that cars are approaching? and couldn’t it be true that some object is falling from the sky? Of course both events are possible. Then why do we look left and right, but not up?\nThe main reason1 is that we believe strongly that cars might be approaching, believe very weakly that some object might be falling from the sky. In other words, we consider the first occurrence to be very probable; the second, extremely improbable.1 We shall see later that one more factor enters the explanation.\nWe shall take the notion of probability as intuitively understood (just as we did with the notion of truth). But it is important to emphasize and agree on at least two facts about it:\n\nProbability is agent- and context-dependent. A coin is tossed, comes down heads, and is quickly hidden from view. Alice sees that it landed heads-up. Bob instead doesn’t manage to see the outcome and has no clue. Alice considers the sentence \\(\\textsf{\\small`Coin came down heads`}\\) to be true, that is, to have 100% probability. Bob considers the same sentence to have 50% probability.\nNote how Alice and Bob assign two very different probabilities to the same sentence; yet both assignments are completely rational. If Bob assigned 100% to \\(\\textsf{\\small`heads`}\\), we would suspect that he had seen the outcome after all; if he assigned 0% to \\(\\textsf{\\small`heads`}\\), we would consider the assignment groundless and silly. We would be baffled if Alice assigned 50% to \\(\\textsf{\\small`heads`}\\), because she saw the outcome; we would hypothesize that she feels unsure about what she saw.\nProbability is not a physical property. Whether a tossed coin lands heads up or tails up is fully determined by the initial conditions (position, orientation, momentum, rotational momentum) of the toss and the boundary conditions (air velocity and pressure) during the flight. The same is true for all macroscopic engineering phenomena. (Even quantum phenomena have not been proved to be non-deterministic, and there are deterministic and experimentally consistent mathematical presentations of quantum theory.)\n\n\n\n\n\n\n\n\n\nReading material\n\n\n\nDynamical Bias in the Coin Toss\n\n\nThese two facts are not just matter of principle; they have real practical consequences. A data engineer who does not carefully assess the context of a probability will design a system with non-optimal performance2 – or even cause deaths. The same is true of a data engineer who does not carefully take advantage, when possible, of the physics involved in the engineering problem.2 This fact can be mathematically proven."
  },
  {
    "objectID": "probability_inference.html#making-room-for-uncertainty-plausibility-credibility-degree-of-belief-probability",
    "href": "probability_inference.html#making-room-for-uncertainty-plausibility-credibility-degree-of-belief-probability",
    "title": "5  Probability inference",
    "section": "5.2 Making room for uncertainty:Plausibility, credibility, degree of belief, probability",
    "text": "5.2 Making room for uncertainty:Plausibility, credibility, degree of belief, probability"
  },
  {
    "objectID": "probability_inference.html#inferences-with-uncertainty-the-probability-calculus",
    "href": "probability_inference.html#inferences-with-uncertainty-the-probability-calculus",
    "title": "5  Probability inference",
    "section": "5.3 Inferences with uncertainty: the probability calculus",
    "text": "5.3 Inferences with uncertainty: the probability calculus\n\n\n\n\n\n\n\nTHE FUNDAMENTAL RULES OF INFERENCE\n\n\n\n\nRule for “not” \\(\\boldsymbol{\\lnot}\\)\n\n\\[\\mathrm{P}(\\lnot a \\nonscript\\:\\vert\\nonscript\\:\\mathopen{} D)\n+ \\mathrm{P}(a \\nonscript\\:\\vert\\nonscript\\:\\mathopen{} D)\n= 1 \\tag{5.1}\\]\n\nRule for “and” \\(\\boldsymbol{\\land}\\)\n\n\\[\n\\mathrm{P}(a \\land b \\nonscript\\:\\vert\\nonscript\\:\\mathopen{} D)\n= \\mathrm{P}(a \\nonscript\\:\\vert\\nonscript\\:\\mathopen{} b \\land D) \\cdot\n\\mathrm{P}(b \\nonscript\\:\\vert\\nonscript\\:\\mathopen{} D)\n= \\mathrm{P}(b \\nonscript\\:\\vert\\nonscript\\:\\mathopen{} a \\land D) \\cdot\n\\mathrm{P}(a \\nonscript\\:\\vert\\nonscript\\:\\mathopen{} D)\n\\tag{5.2}\\]\n\nRule for “or” \\(\\boldsymbol{\\lor}\\)\n\n\\[\\mathrm{P}(a \\lor b \\nonscript\\:\\vert\\nonscript\\:\\mathopen{} D)\n= \\mathrm{P}(a \\nonscript\\:\\vert\\nonscript\\:\\mathopen{} D) +\n\\mathrm{P}(b \\nonscript\\:\\vert\\nonscript\\:\\mathopen{} D)\n- \\mathrm{P}(a \\land b \\nonscript\\:\\vert\\nonscript\\:\\mathopen{} D)\n\\tag{5.3}\\]\n\nRule of self-consistency\n\n\\[\\mathrm{P}(a \\nonscript\\:\\vert\\nonscript\\:\\mathopen{} a \\land D)\n= 1\n\\tag{5.4}\\]\n\n\n\n\n\n\nThe Three Fundamental Laws of inference\n\nExercise: Monty-Hall problem & variations\nExercise: clinical test & diagnosis\n\n\n\nBayes’s theorem"
  },
  {
    "objectID": "probability_inference.html#common-points-of-certain-and-uncertain-inference",
    "href": "probability_inference.html#common-points-of-certain-and-uncertain-inference",
    "title": "5  Probability inference",
    "section": "5.4 Common points of certain and uncertain inference",
    "text": "5.4 Common points of certain and uncertain inference\n\nNo premises? No conclusions!"
  },
  {
    "objectID": "data_information.html#kinds-of-data",
    "href": "data_information.html#kinds-of-data",
    "title": "6  Data and information",
    "section": "6.1 Kinds of data",
    "text": "6.1 Kinds of data\n\nBinary\n\n\nNominal\n\n\nOrdinal\n\n\nContinuous\n\nunbounded\nbounded\ncensored\n\n\n\nComplex data\n2D, 3D, images, graphs, etc.\n\n\n“Soft” data\n\norders of magnitude\nphysical bounds"
  },
  {
    "objectID": "data_information.html#data-transformations",
    "href": "data_information.html#data-transformations",
    "title": "6  Data and information",
    "section": "6.2 Data transformations",
    "text": "6.2 Data transformations\n\nlog\nprobit\nlogit"
  },
  {
    "objectID": "probability_distributions.html#the-difference-between-statistics-and-probability-theory",
    "href": "probability_distributions.html#the-difference-between-statistics-and-probability-theory",
    "title": "7  Allocation of uncertainty among possible data values: probability distributions",
    "section": "7.1 The difference between Statistics and Probability Theory",
    "text": "7.1 The difference between Statistics and Probability Theory\nStatistics is the study of collective properties of collections of data. It does not imply that there is any uncertainty.\nProbability theory is the quantification and propagation of uncertainty. It does not imply that we have collections of data."
  },
  {
    "objectID": "probability_distributions.html#whats-distributed",
    "href": "probability_distributions.html#whats-distributed",
    "title": "7  Allocation of uncertainty among possible data values: probability distributions",
    "section": "7.2 What’s “distributed”?",
    "text": "7.2 What’s “distributed”?\nDifference between distribution of probability and distribution of (a collection of) data."
  },
  {
    "objectID": "probability_distributions.html#distributions-of-probability",
    "href": "probability_distributions.html#distributions-of-probability",
    "title": "7  Allocation of uncertainty among possible data values: probability distributions",
    "section": "7.3 Distributions of probability",
    "text": "7.3 Distributions of probability\n\nRepresentations\n\nDensity function\nHistogram\nScatter plot\n\nBehaviour of representations under transformations of data."
  },
  {
    "objectID": "probability_distributions.html#summaries-of-distributions-of-probability",
    "href": "probability_distributions.html#summaries-of-distributions-of-probability",
    "title": "7  Allocation of uncertainty among possible data values: probability distributions",
    "section": "7.4 Summaries of distributions of probability",
    "text": "7.4 Summaries of distributions of probability\n\nLocation\nMedian, mean\n\n\nDispersion or range\nQuantiles & quartiles, interquartile range, median absolute deviation, standard deviation, half-range\n\n\nResolution\nDifferential entropy\n\n\nBehaviour of summaries under transformations of data and errors in data"
  },
  {
    "objectID": "probability_distributions.html#outliers-and-out-of-population-data",
    "href": "probability_distributions.html#outliers-and-out-of-population-data",
    "title": "7  Allocation of uncertainty among possible data values: probability distributions",
    "section": "7.5 Outliers and out-of-population data",
    "text": "7.5 Outliers and out-of-population data\n(Warnings against tail-cutting and similar nonsense-practices)"
  },
  {
    "objectID": "probability_distributions.html#marginal-and-conditional-distributions-of-probability",
    "href": "probability_distributions.html#marginal-and-conditional-distributions-of-probability",
    "title": "7  Allocation of uncertainty among possible data values: probability distributions",
    "section": "7.6 Marginal and conditional distributions of probability",
    "text": "7.6 Marginal and conditional distributions of probability"
  },
  {
    "objectID": "probability_distributions.html#collecting-and-sampling-data",
    "href": "probability_distributions.html#collecting-and-sampling-data",
    "title": "7  Allocation of uncertainty among possible data values: probability distributions",
    "section": "7.7 Collecting and sampling data",
    "text": "7.7 Collecting and sampling data\n\n“Representative” samples\nSize of minimal representative sample = (2^entropy)/precision\n\nExercise: data with 14 binary variates, 10000 samples\n\n\n\nUnavoidable sampling biases\nIn high dimensions, all datasets are outliers.\nData splits and cross-validation cannot correct sampling biases"
  },
  {
    "objectID": "probability_distributions.html#quirks-and-warnings-about-high-dimensional-data",
    "href": "probability_distributions.html#quirks-and-warnings-about-high-dimensional-data",
    "title": "7  Allocation of uncertainty among possible data values: probability distributions",
    "section": "7.8 Quirks and warnings about high-dimensional data",
    "text": "7.8 Quirks and warnings about high-dimensional data"
  },
  {
    "objectID": "making_decisions.html#decisions-possible-situations-and-consequences",
    "href": "making_decisions.html#decisions-possible-situations-and-consequences",
    "title": "8  Making decisions",
    "section": "8.1 Decisions, possible situations, and consequences",
    "text": "8.1 Decisions, possible situations, and consequences"
  },
  {
    "objectID": "making_decisions.html#gains-and-losses-utilities",
    "href": "making_decisions.html#gains-and-losses-utilities",
    "title": "8  Making decisions",
    "section": "8.2 Gains and losses: utilities",
    "text": "8.2 Gains and losses: utilities\n\nFactors that enter utility quantification\nUtilities can rarely be assigned a priori."
  },
  {
    "objectID": "making_decisions.html#making-decisions-under-uncertainty-maximization-of-expected-utility",
    "href": "making_decisions.html#making-decisions-under-uncertainty-maximization-of-expected-utility",
    "title": "8  Making decisions",
    "section": "8.3 Making decisions under uncertainty: maximization of expected utility",
    "text": "8.3 Making decisions under uncertainty: maximization of expected utility"
  }
]