# Inference
{{< include macros.qmd >}}

In the assembly-line decision problem of [ยง @sec-intro], the probability of early failure (and that of late failure), in view of the test results, was very important in determining the optimal decision. If the probability had been $5\%$ instead of $10\%$, the optimal decision would have been different. In that scenario the probabilities of the outcomes in view of the test results were already given. In real decision problems, however, probabilities almost always need to be calculated, and their calculation can be the most time- and resource-demanding step in solving a decision problem.

We'll loosely refer to problems of calculating probabilities as "*inference* problems", and to their calculation as "drawing an inference". Drawing inferences is very often a goal or need in itself, with no underlying decision process. Let's see a couple more informal examples of inference problems before continuing; for some of them an underlying decision problem is also alluded to:

1. Looking at the weather we try to assess if it'll rain today, to decide whether to take an umbrella.

2. Considering a patient's symptoms, test results, and medical history, a clinician tries to assess which disease affects a patient, so as to decide on the optimal treatment.

3.  Looking at the present game position ![](XsOs.png){width=10%} the X-player, which moves next, wonders whether placing the next [**X**]{style="color:#CA5556"} on the mid-right position leads to a win.

4. From the current set of camera frames, the computer of a self-driving car needs to assess whether a particular patch of colours in the frames is a person, so as to slow down the car and stop.

5. Given that [$G=6.67 \cdot 10^{-11}\,\mathrm{m^3\,s^{-2}\,kg^{-1}}$,]{.together} $M = 5.97 \cdot 10^{24}\,\mathrm{kg}$ (mass of the Earth), and $r = 6.37 \cdot 10^{6}\,\mathrm{m}$ (radius of the Earth), a rocket engineer needs to know [how much is $\sqrt{2\,G\,M/r\,}$](http://nasaphysics.cet.edu/escape-velocity.html).

6. We'd like to know whether the rolled is going to show {{< fa dice-six >}}.

7. An [aircraft's autopilot system](https://aerospaceamerica.aiaa.org/features/a-i-in-the-cockpit) needs to assess how much the [aircraft's roll](https://www.grc.nasa.gov/www/k-12/VirtualAero/BottleRocket/airplane/roll.html) will change if the right wing's [angle of attack](https://www.grc.nasa.gov/www/k-12/VirtualAero/BottleRocket/airplane/incline.html) is increased by $0.1\,\mathrm{rad}$.

8. By looking at the dimensions, shape, texture of a newly dug-out fossil bone, an archaeologist wonders whether it belonged to a Tyrannosaurus rex.

:::{.callout-caution}
## {{< fa user-edit >}} Exercises
@. For each example above, pinpoint what has to be inferred.

@. Point out which of the examples above *explicitly* gives data or information that should be used for the inference.

@. For the examples that do not give explicit data or information, speculate what information could be implicitly assumed.

    For those that do give explicit data, speculate which other additional information could be implicitly assumed.

@. Can any of the inferences above be done perfectly, that is, without any uncertainty (from the data given explicitly or implicitly)?

@. Point out which of the examples above explicitly involves a decision involved.

@. For the examples that involve a decision: in which of them does the decision affect the results of the inference? In which it does not?

@. Point out which of the inferences above is about something that could be already known at least in theory (for instance something that already happened).
:::



How are inference problems solved? We shall learn a universal set of principles to solve them, called the [**probability calculus**]{.blue} or more commonly **probability theory**^[We'll soon see why "calculus" is a more appropriate name than "theory".]




We now put momentarily the full decision-making problem backstage (but keeping it in the back of our minds), and focus on the problem of [**inference**]{.blue}. Drawing inferences is very often a goal or need in itself, with no underlying decision process.

## What is inference?

*Drawing an inference* could mean: to assess whether an unknown outcome or hypothesis is `true` or `false`, on the basis of some known data and information. This definition, however, is too limited in two respects, especially in problems of engineering and data science. We need to make it more general:

### From truth to probability
Our starting point is decision-making *under uncertainty*, because in concrete engineering problems it is often impossible to determine the truth or falsity of a hypothesis with certainty.

So by *drawing an inference* we cannot mean [**to assess the plausibility**]{.blue} or [**credibility**]{.blue} or [**probability**]{.blue} rather than the truth or falsity. Truth-determination is still included as a special case: `fully certain` corresponds to `true`, and `impossible` corresponds to `false`. We'll discuss the "plausibility" idea in more detail later.

### Hypothetical and counterfactual inferences
It is not always the case that we want to assess the truth or plausibility of something *unknown* on the basis of something *known*.  An agent must often make **hypothetical** or **counterfactual** reasoning.

Our assembly-line scenario gives a concrete example. The inference there is  that the component will fail within a year *if* it is accepted and sold. But that hasn't been decided yet; maybe it's going to be rejected instead. This is an example of *hypothetical reasoning*: we are making an inference based partly on facts and partly on imagined information, whose truth is still unknown.

In other situations, for example when backtracking an error, we may need to assess the plausibility of an outcome which did *not* happen, based on a hypothesis which may or may not be true. This assessment may help us in ruling out that hypothesis. This is an example of *counterfactual reasoning*.

Both these kinds of reasoning are staples of scientific research. We will see that they continuously enter in the calculation of probabilities.

## Proposal and conditional

\

Some additional aspects of inference must be emphasized:

### Known and unknown: by whom?
What's known to an agent can be unknown to another agent, and vice versa. This means that [**every inference is always relative to an agent's background knowledge**]{.blue}. This fact is especially important in data science and artificial intelligence.

Consider an engineer testing the programming of a particular AI system. The engineer inputs specially-chosen data and checks the AI's decisions about specially-chosen outcomes. In this scenario we have two ongoing inferences, drawn by two agents:

- The AI is one agent. This agent knows the inputs, but doesn't know the true outcomes. This agent's inference is about the outcomes.

- The engineer is the other agent. This agent knows inputs and true outcomes -- both are "data" for this agent -- but doesn't know the AI's final decisions. This agent's inference is about the AI's decisions.

### Future and past

An inference may concern not only unknown future outcomes,^[an inference about the future is often called a *forecast*.] but also unknown *past* outcomes. For instance, imagine that a particular device has stopped working, and an engineer needs to assess the plausibility that a mechanical failure happened, or an electronic failure happened. In this case the inference is about something unknown to the engineer (and maybe to anyone else), but that has already happened. Astrophysicists and archaeologists draw this kind of inferences all the time.






## Mathematical representation of inferences and their objects

We shall soon explore the rules that govern inference. But first we must address two questions:

- Inference *about what*? and *given what*? So far we've spoken about "outcomes", "data", "hypotheses", "background knowledge", and similar concepts. They are not identical concepts; can we view them all as instances of a more unified notion?

- How to mathematically *represent* this unified notion and those concepts? A mathematical representation is necessary for systematically approaching inference and decision problems of any complexity, and also for implementation in computer algorithms and artificial-intelligence agents.
