# Inference
{{< include macros.qmd >}}

In the assembly-line decision problem of [§ @sec-intro], the probability of early failure (and that of late failure), in view of the test results, was very important in determining the optimal decision. If the probability had been $5\%$ instead of $10\%$, the optimal decision would have been different. In that scenario the probabilities of the outcomes in view of the test results were already given. In real decision problems, however, probabilities almost always need to be calculated, and their calculation can be the most time- and resource-demanding step in solving a decision problem.

We'll loosely refer to problems of calculating probabilities as "*inference* problems", and to their calculation as "drawing an inference". Drawing inferences is very often a goal or need in itself, with no underlying decision process. 


## The wide scope and characteristics of inferences

Let's see a couple more informal examples of inference problems. For some of them an underlying decision problem is also alluded to:

A.  Looking at the weather we try to assess if it'll rain today, to decide whether to take an umbrella.

B.  Considering a patient's symptoms, test results, and medical history, a clinician tries to assess which disease affects a patient, so as to decide on the optimal treatment.

C.  Looking at the present game position ![](XsOs.png){width=10%} the X-player, which moves next, wonders whether placing the next [**X**]{style="color:#CA5556"} on the mid-right position leads to a win.

D.  From the current set of camera frames, the computer of a self-driving car needs to assess whether a particular patch of colours in the frames is a person, so as to slow down the car and stop.

E.  Given that [$G=6.67 \cdot 10^{-11}\,\mathrm{m^3\,s^{-2}\,kg^{-1}}$,]{.together} $M = 5.97 \cdot 10^{24}\,\mathrm{kg}$ (mass of the Earth), and $r = 6.37 \cdot 10^{6}\,\mathrm{m}$ (radius of the Earth), [a rocket engineer needs to know](http://nasaphysics.cet.edu/escape-velocity.html)  how much is [$\sqrt{2\,G\,M/r\,}$.]{.together}

F.  We'd like to know whether the rolled die is going to show {{< fa dice-six >}}.

G.  An [aircraft's autopilot system](https://aerospaceamerica.aiaa.org/features/a-i-in-the-cockpit) needs to assess how much the aircraft's [roll](https://www.grc.nasa.gov/www/k-12/VirtualAero/BottleRocket/airplane/roll.html) will change if the right wing's [angle of attack](https://www.grc.nasa.gov/www/k-12/VirtualAero/BottleRocket/airplane/incline.html) is increased by $0.1\,\mathrm{rad}$.

H.  By looking at the dimensions, shape, texture of a newly dug-out fossil bone, an archaeologist wonders whether it belonged to a Tyrannosaurus rex.

I.  A voltage test on a newly produced electronic component yields a reading of $100\,\mathrm{mV}$. The electronic component turns out to be defective. An engineer wants to assess whether the voltage-test reading could have been $100\,\mathrm{mV}$, if the component had not been defective.

J.  Same as above, but the engineer wants to assess whether the voltage-test reading could have been $80\,\mathrm{mV}$, if the component had not been defective.

\

K.  From measurements of the Sun's energy output and of concentrations of various substances in the Earth's atmosphere over the past 500 000 years, and of the emission rates of various substances in the years 1900--2022, climatologists and geophysicists try to assess the rate of mean-temperature increase in the years 2023--2100.

::::{.column-margin}
::: {.callout-tip}
## {{< fa rocket >}} For the extra curious
Ch. 10 in [*A Survival Guide to the Misinformation Age*](https://hvl.instructure.com/courses/25074/modules/items/668578).
:::
::::



:::{.callout-caution}
## {{< fa user-edit >}} Exercises
@. For each example above, pinpoint what has to be inferred, and also the *agent* interested in the inference.

@. Point out which of the examples above *explicitly* gives data or information that should be used for the inference.

@. For the examples that do not give explicit data or information, speculate what information could be implicitly assumed. For those that do give explicit data, speculate which other additional information could be implicitly assumed.

@. Can any of the inferences above be done perfectly, that is, without any uncertainty (from the data given explicitly or implicitly)?

@. Find the examples that explicitly involve a decision. In which of them does the decision affect the results of the inference? In which it does not?

@. Are any of the inferences *one-time only* -- that is, their object and the data on which they are based have never happened before and will never happen again?

@. Are any of the inferences based on data and information that come chronologically *after* the object of the inference?

@. Are any of the inferences about something that is actually already known?

@. Are any of the inferences about something that actually did not happen?

@. Do any of the inferences use "data" or "information" that are actually known (within the scenario itself) to be fictive, that is, *not* real?
:::

From the examples and your answers to the exercise we observe some very important characteristics of inferences:

- [*Some inferences can be made*]{.blue} exactly, that is, [*without uncertainty*]{.blue}: it is possible to say whether the object of the inference is true or false. Other inferences, instead, involve an uncertainty.

- [*All inferences are based on some data and information*]{.blue}, which may be explicitly expressed or only implicitly understood.

- An inference can be about something *past*, but based on *present or future* data and information: inferences can show  [*all sorts of temporal relations*]{.blue}. 

- An inference can be about something that is [*essentially unrepeatable*]{.blue}, or based on unrepeatable data and information.

- The data and information on which an inference is based can actually be unknown; that is, they can be only momentarily contemplated as real. Such an inference is said to be based on [**hypothetical reasoning**]{.blue}.

- The object of an inference can actually be something already known to be false or not real: the inference tries to assess it in the case that some data or information had been different. Such an inference is said to be based on [**counterfactual reasoning**]{.blue}.









====

How are inference problems solved? We shall learn a universal set of principles to solve them, called the [**probability calculus**]{.blue} or more commonly **probability theory**^[We'll soon see why "calculus" is a more appropriate name than "theory".]




We now put momentarily the full decision-making problem backstage (but keeping it in the back of our minds), and focus on the problem of [**inference**]{.blue}. Drawing inferences is very often a goal or need in itself, with no underlying decision process.

## What is inference?

*Drawing an inference* could mean: to assess whether an unknown outcome or hypothesis is `true` or `false`, on the basis of some known data and information. This definition, however, is too limited in two respects, especially in problems of engineering and data science. We need to make it more general:

### From truth to probability
Our starting point is decision-making *under uncertainty*, because in concrete engineering problems it is often impossible to determine the truth or falsity of a hypothesis with certainty.

So by *drawing an inference* we cannot mean [**to assess the plausibility**]{.blue} or [**credibility**]{.blue} or [**probability**]{.blue} rather than the truth or falsity. Truth-determination is still included as a special case: `fully certain` corresponds to `true`, and `impossible` corresponds to `false`. We'll discuss the "plausibility" idea in more detail later.

### Hypothetical and counterfactual inferences
It is not always the case that we want to assess the truth or plausibility of something *unknown* on the basis of something *known*.  An agent must often make **hypothetical** or **counterfactual** reasoning.

Our assembly-line scenario gives a concrete example. The inference there is  that the component will fail within a year *if* it is accepted and sold. But that hasn't been decided yet; maybe it's going to be rejected instead. This is an example of *hypothetical reasoning*: we are making an inference based partly on facts and partly on imagined information, whose truth is still unknown.

In other situations, for example when backtracking an error, we may need to assess the plausibility of an outcome which did *not* happen, based on a hypothesis which may or may not be true. This assessment may help us in ruling out that hypothesis. This is an example of *counterfactual reasoning*.

Both these kinds of reasoning are staples of scientific research. We will see that they continuously enter in the calculation of probabilities.

## Proposal and conditional

\

Some additional aspects of inference must be emphasized:

### Known and unknown: by whom?
What's known to an agent can be unknown to another agent, and vice versa. This means that [**every inference is always relative to an agent's background knowledge**]{.blue}. This fact is especially important in data science and artificial intelligence.

Consider an engineer testing the programming of a particular AI system. The engineer inputs specially-chosen data and checks the AI's decisions about specially-chosen outcomes. In this scenario we have two ongoing inferences, drawn by two agents:

- The AI is one agent. This agent knows the inputs, but doesn't know the true outcomes. This agent's inference is about the outcomes.

- The engineer is the other agent. This agent knows inputs and true outcomes -- both are "data" for this agent -- but doesn't know the AI's final decisions. This agent's inference is about the AI's decisions.

### Future and past

An inference may concern not only unknown future outcomes,^[an inference about the future is often called a *forecast*.] but also unknown *past* outcomes. For instance, imagine that a particular device has stopped working, and an engineer needs to assess the plausibility that a mechanical failure happened, or an electronic failure happened. In this case the inference is about something unknown to the engineer (and maybe to anyone else), but that has already happened. Astrophysicists and archaeologists draw this kind of inferences all the time.






## Mathematical representation of inferences and their objects

We shall soon explore the rules that govern inference. But first we must address two questions:

- Inference *about what*? and *given what*? So far we've spoken about "outcomes", "data", "hypotheses", "background knowledge", and similar concepts. They are not identical concepts; can we view them all as instances of a more unified notion?

- How to mathematically *represent* this unified notion and those concepts? A mathematical representation is necessary for systematically approaching inference and decision problems of any complexity, and also for implementation in computer algorithms and artificial-intelligence agents.
