# Inference
{{< include macros.qmd >}}

We now put momentarily the full decision-making problem backstage (but keeping it in the back of our minds), and focus on the problem of [**inference**]{.blue}. Drawing inferences is very often a goal or need in itself, with no underlying decision process.

## What is inference?

A first meaning of *drawing an inference* could be to assess whether an unknown outcome or hypothesis is `true` or `false`, on the basis of some known data and information. This definition, however, is too limited in two respects, especially in problems of engineering and data science. We need to make it more general:

### From truth to probability
As has been repeated many times, it is often impossible to determine the truth or falsity of a hypothesis with certainty. This is why  decision-making *under uncertainty* was our starting point. So by *drawing an inference* we mean [**to assess the plausibility**]{.blue} or [**credibility**]{.blue} or [**probability**]{.blue} rather than the truth or falsity. Note that truth-determination is still included as a special case: `fully certain` corresponds to `true`, and `impossible` corresponds to `false`.

### Hypothetical and counterfactual inferences
It is not always the case that we want to assess the truth or plausibility of something *unknown* on the basis of something *known*.  An agent must often make **hypothetical** or **counterfactual** reasoning.

Our assembly-line scenario gives a concrete example. The inference there is  that the component will fail within a year *if* it is accepted and sold. But that hasn't been decided yet; maybe it's going to be rejected instead. This is an example of *hypothetical reasoning*: we are making an inference based partly on facts and partly on imagined information, whose truth is still unknown.

In other situations, for example when backtracking an error, we may need to assess the plausibility of an outcome which did *not* happen, based on a hypothesis which may or may not be true. This assessment may help us in ruling out that hypothesis. This is an example of *counterfactual reasoning*.

Both these kinds of reasoning are staples of scientific research. We will see that they continuously enter in the calculation of probabilities.

\

Some other important aspects of inference must be emphasized:

### Known and unknown: by whom?
What's known to an agent can be unknown to another agent, and vice versa. This means that [**every inference is always relative to an agent's background knowledge**]{.blue}. This fact is especially important in data science and artificial intelligence.

Consider an engineer testing the programming of a particular AI system. The engineer inputs specially-chosen data and checks the AI's decisions about specially-chosen outcomes. In this scenario we have two ongoing inferences, drawn by two agents:

- The AI is one agent. This agent knows the inputs, but doesn't know the true outcomes. This agent's inference is about the outcomes.

- The engineer is the other agent. This agent knows inputs and true outcomes -- both are "data" for this agent -- but doesn't know the AI's final decisions. This agent's inference is about the AI's decisions.

### Future and past

An inference may concern not only unknown future outcomes,^[an inference about the future is often called a *forecast*.] but also unknown *past* outcomes. For instance, imagine that a particular device has stopped working, and an engineer needs to assess the plausibility that a mechanical failure happened, or an electronic failure happened. In this case the inference is about something unknown to the engineer (and maybe to anyone else), but that has already happened. Astrophysicists and archaeologists draw this kind of inferences all the time.

## Proposal and conditional


## Mathematical representation of inferences and their objects

We shall soon explore the rules that govern inference. But first we must address two questions:

- Inference *about what*? and *given what*? So far we've spoken about "outcomes", "data", "hypotheses", "background knowledge", and similar concepts. They are not identical concepts; can we view them all as instances of a more unified notion?

- How to mathematically *represent* this unified notion and those concepts? A mathematical representation is necessary for systematically approaching inference and decision problems of any complexity, and also for implementation in computer algorithms and artificial-intelligence agents.
