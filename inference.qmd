# Inference
{{< include macros.qmd >}}

We now put momentarily aside the full decision-making problem (but keeping it in the back of our minds), and focus on the problem of [**inference**]{.blue}. Drawing inferences is very often a goal or need in itself, with no underlying decision process.

## What is inference?

A first meaning of *drawing an inference* could be to assess whether an outcome or hypothesis is `true` or `false`, on the basis of some data and other information. This definition is too limited, however, especially in problems of engineering and data science; we need to make it more general in two respects. Some general aspects of inference should also be emphasized.

### From truth to probability
First, it is often impossible to determine the truth or falsity of a hypothesis with certainty. This is why  decision-making *under uncertainty* was our starting point. So by *drawing an inference* we mean [**to assess the plausibility**]{.blue} or [**credibility**]{.blue} or [**probability**]{.blue} rather than the truth or falsity. Note that truth-determination is still included as a special case as  `fully certain` and `impossible` cases of plausibility.

### Hypothetical and counterfactual inferences
Second, it is not always the case that we want to assess the truth or plausibility of something *unknown* on the basis of something *known*.  An agent must often make **hypothetical** or **counterfactual** reasoning.

Consider for instance the assembly-line scenario. To assess the outcome of accepting an electronic component, we momentarily imagine that the component is actually accepted and sold, and then find out what the consequences of this imagined situation would be. This is an example of *hypothetical reasoning*. Hypothetical reasoning is sometimes assisted by real experiments performed in restricted and controlled conditions. Such supporting experiments are not always viable, however, and often they do not exactly reflect the hypothetical situation.

Consider also the case where we know that a particular electronic component, already sold, has failed within a year. We can assess what would have been the plausibility of this failing we *had employed* a different kind of transistors in its construction. From this assessment we may find out whether it would be better to make changes in the assembly line. This is an example of *counterfactual reasoning*.

In either case we are determining the plausibility of something known given something unknown, or a combination of the two. Both these kinds of reasoning are staples of scientific research. We will see that they continuously enter in the calculation of probabilities.

### Known and unknown: by whom?

What's known to an agent can be unknown to another, and vice versa. This means that [**every inference is always relative to an agent's background knowledge**]{.blue}. This fact is especially important in data science and artificial intelligence:

Consider an engineer testing the programming of a particular AI system. The engineer inputs specially-chosen data and checks the AI's decisions about specially-chosen outcomes. In this scenario we have two ongoing inferences, drawn by two agents:

- The AI is one agent. This agent knows the inputs, but doesn't know the true outcomes. This agent's inference is about the outcomes.

- The engineer is the other agent. This agent knows inputs and true outcomes -- both are "data" for this agent -- but doesn't know the AI's final decisions. This agent's inference is about the AI's decisions.

### Future and past

An inference may concern not only unknown future outcomes -- in which case we'll often call it a *forecast* -- but also unknown *past* outcomes. For instance, imagine that a particular device has stopped working, and an engineer needs to assess the plausibility of a mechanical failure or of an electronic failure. In this case the inference is about something unknown to the engineer (and maybe to anyone else), but that has already happened. Astrophysicists and archaeologists draw this kind of inferences all the time.


## Mathematical representation of inferences and their objects

We shall soon explore the rules that govern inference. But first we must address two questions:

- Inference *about what*? and *given what*? So far we've spoken about "outcomes", "data", "hypotheses", "background knowledge", and similar concepts. They are not identical concepts; can we view them all as instances of a more unified notion?

- How to mathematically *represent* this unified notion and those concepts? A mathematical representation is necessary for systematically approaching inference and decision problems of any complexity, and also for implementation in computer algorithms and artificial-intelligence agents.
