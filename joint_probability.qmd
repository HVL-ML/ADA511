# [Joint probability distributions]{.green} {#sec-prob-joint}
{{< include macros.qmd >}}

So far we have considered  probability distributions for quantities of a basic (nominal, ordinal, binary, interval) type. These distributions have a sort of one-dimensional character and can be represented by ordinary histograms, line plots, and scatter plots. We now consider probability distributions for joint quantities.

[*(Make sure you're familiar with [§ @sec-quantities-types-multi] before you begin.)*]{.small style="color:#EE6677;"}

## Joint probabilities

A joint quantity, as discussed in [§  @sec-data-multiv], is just a collection or set of quantities of basic types. Saying that a joint quantity has a particular value means that each basic component quantity has a particular value in its specific domain. This is expressed by an `and` of sentences.

Consider for instance the joint quantity $X$ consisting of the age $\lblue A$ and sex $\green S$ of a specific person. The fact that $X$ has a particular value is expressed by a composite sentence such as

$$
\pr{The person's age is 25 years and the sex is female}
$$

which we can compactly write with an `and`:

$$
{\lblue A\mo 25\,\mathrm{y}} \land {\green S\mo\mathrm{f}}
$$

All the possible composite sentences of this kind are *mutually exclusive* and *exhaustive*.

An agent's uncertainty about $X$'s true value is therefore represented by a probability distribution over all `and`-ed sentences of this kind, representing all possible joint values:

$$
\P\bigl({\lblue A \mo 25\,\mathrm{y}} \land {\green S\mo\mathrm{f}} \| \yI\bigr) \ , \qquad
\P\bigl({\lblue A \mo 31\,\mathrm{y}} \land {\green S\mo\mathrm{m}} \| \yI\bigr) \ , \qquad
\dotsc
$$

where $\yI$ is the agent's state of knowledge, and the probabilities sum up to one. We call each of these probabilities a [**joint probability**]{.blue}, and their collection a [**joint probability distribution**]{.blue}. Usually these probabilities are written in much abbreviated form, and a comma "$\and$" is used instead of "$\land$" ([§ @sec-connecting-sentences]); for instance you can commonly find the following notation:

$$
\P(A\mo25 \and S\mo\mathrm{f} \| \yI)
$$

or even just

$$
\P(25, \mathrm{f} \| \yI)
$$

## Joint probability densities

@@ TODO


## Representation of joint probability distributions

There is a wide variety of ways of representing joint probability distributions, and new ways are invented (and rediscovered) all the time. In some cases, especially when the quantity has more than three component quantities, it can become impossible to graphically represent the probability distribution in a faithful way. Therefore one often tries to represent only some aspects or features of interest from the full distribution. Whenever you see a plot of a joint probability distribution, you should carefully read what the plot shows and how it was made. Here we only illustrate some examples and ideas for representations.

### Tables

When a quantity is *bi*variate and its two component quantities are both discrete and finite, the joint probabilities can be reported as a table.

Example: Consider the next patient that will arrive at a particular hospital. There's the possibility of arrival by `ambulance`, `helicopter`, or `other` transportation means; and the possibility that the patient will need `urgent` `non-urgent` care. These can be seen as two quantities $A$ (nominal) and $U$ (binary). When these two quantities are taken together; their joint probability distribution is as follows, conditional on the hospital's data $\yi[H]$:

+:-------------------------:+:---------------:+:---------------:+:---------------:+:---------------:+
|$\P(A\mo a \and U\mo u\|\yi[H])$|                 |**arrival** $A$                                      |
+---------------------------+-----------------+-----------------+-----------------+-----------------+
|                           |                 |ambulance        |helicopter       |other            |
+---------------------------+-----------------+-----------------+-----------------+-----------------+
|**urgency** $U$            |urgent           |0.11             |0.04             |0.03             |
+                           +-----------------+-----------------+-----------------+-----------------+
|                           |non-urgent       |0.17             |0.01             |0.64             |
+---------------------------+-----------------+-----------------+-----------------+-----------------+
: Joint probability distribution for transportation at arrival and urgency {#tbl-urgent-arrival .sm}

We see for instance that the most probable possibility is that the next patient will arrive by transportation means other than ambulance and helicopter, and won't require urgent care.

It is also possible to replace the numerical probability values with graphical representations; for example as shades of a colour, or squares with different areas.

@@ TODO ref to marginals section

### Multi-line plots

Joint probability distributions over one discrete and one continuous quantity (or ordinal discrete with numerous values) can be represented as a collection of line plots: each line plot represent the probability density for the continuous quantity and a specific value of the discrete quantity.

Consider for instance the probability that the next patient who arrives at a particular hospital has a given age (continuous quantity) and may require urgent care or not (binary quantity). The joint probability density can be visualized as in the plot in the margin. From the plot we can see that the probability of urgent patients is generally lower than non-urgent ones. A possibly disadvantage of this kind of plots is evident: the details, such as peaks, of the density for some values of the discrete quantity may be barely visible.

::::{.column-margin}
![](hospital_age_urgent.png){width=100%}
::::


### Surface plots

### Scatter plots

@@ TODO work also for 3D


::: {.callout-caution}
## {{< fa book >}} Study reading
- §§ 5.3.2--5.3.3 of [*Risk Assessment and Decision Analysis with Bayesian Networks*](https://hvl.instructure.com/courses/25074/modules/items/664427)

- § 12.2.2 of [*Artificial Intelligence*](https://hvl.instructure.com/courses/25074/modules/items/660089)

- §§ 5.1--5.5 of [*Probability*](https://hvl.instructure.com/courses/25074/modules/items/675505)
:::
