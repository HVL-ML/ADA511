# Probability inference
{{< include macros.qmd >}}

## When truth isn't known

In most real-life and engineering situations we don't know the truth or falsity of sentences that interest us. But this doesn't mean that nothing can be said or done in such situations.

When we cross a busy city street we look left and right to check whether any cars are approaching. We typically don't look up to check whether something is falling from the sky. Yet, couldn't it be `false` that cars are approaching? and couldn't it be `true` that [some object is falling from the sky ](https://www.aerotime.aero/articles/32818-cessna-door-falls-off-lands-in-parking-lot)? Of course both events are possible. Then why do we look left and right, but not up?

The main reason^[We shall see later that one more factor enters the explanation.] is that we *believe strongly* that cars might be approaching, *believe very weakly* that some object might be falling from the sky. In other words, we consider the first occurrence to be very *probable*; the second, extremely improbable.

We shall take the notion of **probability** as intuitively understood (just as we did with the notion of truth). But it is important to emphasize and agree on at least two facts about it:







- **Probability is agent- and context-dependent**. A coin is tossed, comes down heads, and is quickly hidden from view. Alice sees that it landed heads-up. Bob instead doesn't manage to see the outcome and has no clue. Alice considers the sentence $\pr{Coin came down heads}$ to be `true`, that is, to have `100% probability`. Bob considers the same sentence to have `50%` probability.

    Note how Alice and Bob assign two very different probabilities to the same sentence; yet both assignments are completely rational. If Bob assigned `100%` to $\pr{heads}$, we would suspect that he had seen the outcome after all; if he assigned `0%` to $\pr{heads}$, we would consider the assignment groundless and silly. We would be baffled if Alice assigned `50%` to $\pr{heads}$, because she saw the outcome; we would hypothesize that she feels unsure about what she saw.

- **Probability is not a physical property**. Whether a tossed coin lands heads up or tails up is fully determined by the initial conditions (position, orientation, momentum, rotational momentum) of the toss and the boundary conditions (air velocity and pressure) during the flight. The same is true for all macroscopic engineering phenomena. (Even quantum phenomena have not been proved to be non-deterministic, and there are [deterministic and experimentally consistent mathematical presentations](https://doi.org/10.48550/arXiv.quant-ph/9504010) of quantum theory.)

::: {.column-margin}
::: {.callout-tip}
## Reading material
[*Dynamical Bias in the Coin Toss*](https://hvl.instructure.com/courses/25074/modules/items/661553)
:::
:::

These two facts are not just matter of principle; they have real practical consequences. A data engineer who does not carefully assess the context of a probability will design a system with non-optimal performance^[This fact can be mathematically proven.] -- or even cause deaths. The same is true of a data engineer who does not carefully take advantage, when possible, of the physics involved in the engineering problem.




## Making room for uncertainty:<br>Plausibility, credibility, degree of belief, probability

## Inferences with uncertainty: the probability calculus

:::: {.column-body-outset style="color:#228833"}
::: {.callout-tip appearance="default" icon=false}
## [THE FUNDAMENTAL RULES OF INFERENCE]{.underline style="text-align:center;"}

Rule for "not" $\boldsymbol{\lnot}$
: $$\P(\lnot a \| D) 
+ \P(a \| D)
= 1$$ {#eq-not}

Rule for "and" $\boldsymbol{\land}$
: $$
\P(a \land b \| D) 
= \P(a \| b \land D) \cdot
\P(b \| D) 
= \P(b \| a \land D) \cdot
\P(a \| D)
$$ {#eq-and}

Rule for "or" $\boldsymbol{\lor}$
: $$\P(a \lor b \| D) 
= \P(a \| D) +
\P(b \| D) 
- \P(a \land b \| D)
$$ {#eq-or}

Rule of self-consistency
: $$\P(a \| a \land D) 
= 1
$$ {#eq-axiom}
:::
::::




### The Three Fundamental Laws of inference

* _Exercise: [Monty-Hall problem & variations](The_Monty_Hall_problem-exercise.pdf)_

* _Exercise: clinical test & diagnosis_

### Bayes's theorem

## Common points of certain and uncertain inference

> _No premises? No conclusions!_
