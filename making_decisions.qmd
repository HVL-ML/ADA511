
## [The omnipresence of decision-making in machine learning]{.blue} {#sec-decision-everywhere}

Many machine-learning textbooks say that

> in supervised learning the algorithm learns a functional relationship between some kind of input and some kind of output

Such statement is misleading, because it seems to imply that a functional relationship actually exists from input to output, or from predictor to predictand -- it's only waiting to be discovered and "learned". As we discussed in [chapter @sec-ml-introduction], in many important problems and applications this is actually not true: **there isn't any functional relationship between input and output at all**. Even if any possible "noise" were removed, there would still *not* be any functional relationship between the denoised, actual predictor and predictand ([here is an example](steven-seagal-emotion-chart.jpg){.external}).^[This is one more reason why we use the more general terms "predictor" & "predictand", rather that "input" & "output"]

In many important problems there's only a *statistical* relationship between predictands and predictors. In other words, whenever the agent saw a predictor value $\green X\mo x$, the predictand value turned out to be $\green Y\mo y'$ in a given number of units, but also $\green Y\mo y''$ in a given number of other units, and so on.

The lack of an actual predictor-predictand function has a very important consequence. If a machine-learning algorithm outputs just *one* predictand value, among the possible ones that are consistent with the predictor, then it means that **the algorithm must choose one of the possibilities**. How is this choice made? This is obviously a **decision-making problem**. As we know from chapters [-@sec-framework] and [-@sec-basic-decisions], the optimal choice is determined by Decision Theory. Its determination requires:

- [{{< fa scale-unbalanced-flip >}}\ \ the probabilities of the possible predictand values]{.green}

- [{{< fa sack-dollar >}}\ \ the utilities of the possible choices of values]{.blue}

This point of view is also valid when there's only one possible value: in this case the decision-making problem becomes trivial (one choice only), but it's still correctly handled by decision theory.

\

A decision-making step may also appear in tasks where the agent must generate a new unit. In some cases it may happen that a candidate alternative for generation should be discouraged, penalized, or even forbidden, because of particular circumstances; even if it would have been a probable candidate, given previous examples. Therefore also in this type of task there is an interplay between probabilities and utilities.


[*Rest to be written*]{.grey}


# [Making decisions]{.lightblue}


## Decisions, possible situations, and consequences



## Gains and losses: utilities

### Factors that enter utility quantification


Utilities can rarely be assigned a priori.



## Making decisions under uncertainty: maximization of expected utility







