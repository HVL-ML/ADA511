# [From inferences to decisions]{.blue} {#sec-from-inf-to-dec}
{{< include macros.qmd >}}
{{< include macros_exchangeability.qmd >}}
{{< include macros_opm.qmd >}}

## The omnipresence of decision-making in machine learning {#sec-decision-everywhere}

Many machine-learning textbooks say that

> in supervised learning the algorithm learns a functional relationship between some kind of input and some kind of output

Such statement is misleading, because it suggests there is a functional relationship from input to output, or from predictor to predictand -- such function is only waiting to be discovered and "learned". But as we discussed in [chapter @sec-ml-introduction], in many important tasks and applications this is actually not true: **there isn't any functional relationship between input and output at all**. Even if any possible "noise" were removed, there would still *not* be any functional relationship between the denoised predictor and predictand ([here is an example](steven-seagal-emotion-chart.jpg){.external}).^[This is one more reason why we use the more general terms "predictor" & "predictand", rather that "input" & "output"]

In many important tasks there's only a *statistical* relationship between predictands and predictors. In other words, whenever the agent saw a predictor value $\green X\mo x$, the predictand value turned out to be $\green Y\mo y'$ in a given number of units, but also $\green Y\mo y''$ in a given number of other units, and so on.

But even in tasks where there actually is a functional relation from predictors to predictands, the agent typically doesn't know what the function's output should be for particular predictor values, because no such values have been observed in the training data. It must interpolate or extrapolate what it has learned. Also in this case there are therefore several possibilities.

The remarks above have a very important consequence. If a machine-learning algorithm outputs just *one* predictand value, among the possible ones that are consistent with the predictor, then it means that **the algorithm is internally choosing one of the possibilities**. How is this choice made?

Such a choice is obviously a **decision-making problem**. As we know from chapters [-@sec-framework] and [-@sec-basic-decisions], the optimal choice is determined by Decision Theory, and its determination requires:

- [{{< fa scale-unbalanced-flip >}}\ \ the probabilities of the possible predictand values]{.green}

- [{{< fa arrows-split-up-and-left >}}\ \ a list of possible decisions]{.lightblue}

- [{{< fa sack-dollar >}}\ \ the utilities of the decisions, depending on the predictand's true value]{.blue}

\

A decision-making step  also appears in tasks where the agent must *generate* a new unit. Obviously there are many candidates for generation, that agree with what was observed in the training data. If the agent generates *one* unit, then it must internally have chosen among the possible candidates. Thus also this type of "generative" task involves probabilities, decisions, and utilities.


[*Rest to be written*]{.grey}


# [Making decisions]{.lightblue}


## Decisions, possible situations, and consequences



## Gains and losses: utilities

### Factors that enter utility quantification


Utilities can rarely be assigned a priori.



## Making decisions under uncertainty: maximization of expected utility







