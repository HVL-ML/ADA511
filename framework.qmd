# Framework
{{< include _macros.qmd >}}


Every data-driven engineering problem is unique. But there are also similarities among all engineering problems. We are going to learn a framework that allows us to frame and work out some important aspects of any data-driven engineering problem, and of any sub-problems into which a problem can be broken down. This framework is build on notions and on a set of principles that help us analyse the problem. This set of principles is important because it mathematically guarantees an optimal solution to the problem -- within the goals, means, and data into which we framed the problem.

## Our goal: not "success", but optimality

What can we demand of a method for facing engineering problems?

A typical and important aspect in any engineering problem is that there are several possible decisions, or courses of actions, available. The question is which one to choose. Making a particular decision will lead to some consequences, which could get us close to the desired goal but also lead to something else, possibly undesirable. Making a decision is often difficult because **its consequences are not known with certainty, given the information and data available** in the problem. We may lack information and data about past or present details, about future events and responses, and so on. Yet a decision has to made nevertheless. This is what we call a [**decision problem under uncertainty**]{.text-warning} or [**under risk**]{.text-warning}, or simply a "decision problem" for short.

By definition, in a decision problem under uncertainty there is generally no method to *determine* the decision that will surely lead to the desired consequence (if such a method existed, then the problem would not be one of deciding under uncertainty). Therefore, if there is a method to deal with decision problems, its goal cannot be the determination of the *successful* decision. This also means that a priori we cannot blame an engineer for making an unsuccessful decision in a situation of uncertainty.

Imagine two persons, Henry and Tina, who must bet on "heads" or "tails" under the following conditions (and who otherwise don't get any special thrill from betting):

- if the bet is "heads" and the coin lands "heads", the person wins a *small* amount of money; but if it lands "tails", they lose a *large* amount of money.
- if the bet is "tails" and the coin lands "tails", the person *wins* a small amount of money; if it lands "heads", they lose the same *small* amount of money.

Henry chooses the first bet, on "heads". Tina chooses the second bet, on "tails". The coin comes down "heads". So Henry wins the small amount of money, while Tina loses it small amount. What would we say about their decisions?

Henry's decision was lucky, and yet *irrational*: he risked losing much more money than in the second bet, without any possibility of winning more. Tina's decision was unlucky, and yet *rational*: the possibility and amount of winning was the same in the two bets, and she chose the bet with the least amount of loss. We expect that any person making Henry's decision in similar, future bets will eventually lose more money than any person making Tina's decision.

This example shows two points. First, "success" is generally not a good criterion to judge a decision under uncertainty. Second, even if there is no method to determine which decision is successful, there seems to be a method to determine which decision is rational or [**optimal**]{.text-warning}, given the particular gains, losses, and uncertainties involved in the decision problem.

Such a method indeed does exist, and its explanation and use will be the core of the present notes.

Let us emphasize, however, that we are not giving up on "success", or trading it for "optimality". Indeed we'll find that **the method automatically leads to the *successful* decision** in problems where uncertainty is not present or is irrelevant. It's a win-win. It's important to keep this point in mind:

::::: {.column-page-inset-right}
:::: {.callout-note appearance="default" icon=false style="color:#BBBBBB;"}
##
[Aiming to find the solutions that are *successful* can make us *fail* to find those that are optimal when the successful ones cannot be determined.]{style="color:#AA3377;font-size:125%"}

[Aiming to find the solutions that are *optimal* makes us automatically find those that are *successful* when those can be determined.]{style="color:#4477AA;font-size:125%"}
::::
:::::

We shall later witness this fact with our own eyes, and will take it up again in the discussion of some misleading techniques to evaluate machine-learning algorithms.

\

There are other important aspects in engineering problems, besides the one of making decisions under uncertainty. For instance the *discovery* or the *invention* of new technologies and solutions. These aspects can barely be planned or decided; but their fruits, once available, should be handled and used optimally -- thus leading to a decision problem.

Artificial intelligence is proving to be a valuable aid in these more creative aspects too. This kind of use of AI is outside the scope of the present notes. Some aspects of this creativity-assisting use, however, do fall within the domain of the present notes. A pattern-searching algorithm, for example, can be optimized by means of the method we are going to study.


## Decision Theory

We want a method that allows an engineer to make optimal decisions in uncertain situations, and successful decisions in situations with no uncertainty. What other kinds of features should such a method have, in order to be applied to as many kinds of decision problems as possible?

If we find an optimal course of action in regards to some outcome, it may still happen that the course of action can in practice be realized in several ways that are equivalent in regard to the outcome, but inequivalent in regard to time or resources. We thus face a decision within a decision. In general, a decision problem may involve several decision sub-problems, in turn involving decision sub-sub-problems, and so on.

The main engineering goal itself could be to design and build an automated or AI-based device capable of making an optimal decision in a specific kind of uncertain situations. Think for instance of an aeronautic engineer designing an autopilot system.

Therefore, to analyse and tackle this kind of problems we would like to have a framework with the following features:

- it should tell us what's optimal and, when possible, what's successful

- it should take into consideration choices, consequences, costs and gains

- it should be able to deal with uncertainties

- it should be susceptible to recursive or modular application, if needed

- it should be suited to being used not only for human decision-makers, but also for automated or AI devices.

A framework with these features exists: it is [**Decision Theory**]{.text-warning}.

Decision Theory has a long history, going back to Leibniz in the 1600s and partly even to Aristotle in the &minus;300s, and appearing in its present form around 1920--1960. What's remarkable about it is that it is not only *a* framework, but *the* framework we must use. A logico-mathematical theorem shows that any framework that does not break basic optimality and rationality criteria has to be equivalent to Decision Theory (in other words, it can use different technical terminology and rewrite mathematical operations in a different way, but it boils down to the same notions and operations of Decision Theory). So if you wanted to invent and use another framework, then either (a) it would lead to some irrational or illogical consequences, or (b) it would lead to results identical to Decision Theory's. Many frameworks that you are probably familiar with, such as optimization theory, are just specific applications or particular cases of Decision Theory.

Decision Theory can be roughly divided into two main parts: [**Probability Theory**]{.text-warning}, which deals with information, data, uncertainty, inference; and [**Utility Theory**]{.text-warning}, which deals with actions, consequences, gain and loss, decisions. We shall get acquainted with Decision Theory step by step, introducing its main ideas and notions as they become necessary.


## Anatomy of a decision problem

An extremely important -- and surprisingly often neglected -- first step in every engineering problem is to define exactly what the problem is. This means, in particular, to specify unambiguously the goals, the available data and information, the available decisions or courses of action, the hypotheses of interest.

Decision theory analyses any problem in terms of nested decision problems, each of which is framed in terms of these elements:

::::{.column-margin}
:::{.callout-caution}
## {{< fa seedling >}}
Remember: What matters is to be able to identify these elements in a concrete engineering problem, understanding their role. Their technical names don't matter.
:::
::::

- *Agent*: the person or device that has to make an optimal decision.

- *Assumptions*: data and background information that are known, or temporarily imagined to be known, to the agent.

- *Conclusions*: hypothesess, conjectures, or actual facts that the agent wishes to assess; often they are related to the unknown consequences of the possible actions.

- *Probabilities*: quantifying the uncertainties in the the conclusions given the assumptions.

- *Decisions* or *courses of actions*: the choices available to the agent.

- *Utilities*: the gains and losses involved in making each possible decision.

Together with the "assumptions" and "conclusions" it is also useful to keep in mind two more, somewhat different elements:

- *Knowns*: the data and information that are actually known to the agent.

- *Unknowns*: hypotheses, conjectures, and situations whose truth or falsity are actually unknown to the agent.

The basic idea is that the agent will [**infer**]{.text-warning} the conclusions given the assumptions, with some degree of [**uncertainty**]{.text-warning}. From these inferences it will determine the [**optimal**]{.text-warning} decision.

Some of the elements listed above may themselves be open to be analysed by a decision sub-problem. For instance, the utilities could be unknown: thus we have a decision sub-problem to determine the optimal values for the utilities of the main problem. This is an example of the modularity of decision theory.

The elements above must be unambiguously identified in every decision problem. The analysis into these elements greatly helps in making the problem and its solution well-defined. Suppose someone (probably a politician) says: "We must solve the energy crisis by reducing energy consumption or producing more energy". This person has effectively said *nothing whatsoever*. By definition the "energy crisis" is the problem that energy production doesn't meet demand. So this person has only said "we would like the problem to be solved", without giving any solution. A decision-theory approach to this problem requires us to specify which concrete courses of action should be taken for reducing consumption or increasing productions, and what their costs, gains, and probable consequences would be.

::::{.column-margin}
::: {.callout-tip}
## {{< fa book-open >}} For the curious
See MacKay's rational options-costs analysis in [Sustainable Energy -- without the hot air](https://www.withouthotair.com)
:::
::::

An advantage of decision theory is that its application *forces* us to make sense of an engineering problem. A useful procedure is to formulate the general problem in terms of the elements above, identifying them clearly. If the definition of any of the terms involves uncertainty of further decisions, then we analyse it in turn as a decision sub-problem, and so on.

