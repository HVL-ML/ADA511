# Framework and first building blocks
{{< include _macros.qmd >}}


Every data-driven engineering problem is unique. But there also are similarities among all engineering problems. We shall now learn a framework, some notions, and a set of principles that allow us to frame and face any data-driven engineering problem, and any sub-problems into which a problem can be broken down. The set of principles is important because it mathematically guarantees an optimal solution to the problem -- within the goals, means, and data into which we framed the problem.

## The framework: Decision Theory

There is always a goal underlying any engineering problem. The problem itself is how to reach that goal. Typically there are several possible courses of actions available; the question is which one to choose. Choice of a specific action will lead to a set of consequences; this could be the goal we want to reach, but it could also be something else, possibly undesirable. The decision upon a specific action is often difficult because its consequences are not known with certainty. This uncertainty comes in turn from a more general uncertainty about the whole context of the problem: past or present unknown details, unknown future events and responses, and so on. 

@@ example

This is what we call a **decision problem**.

A specific course of action may in turn be realized in several ways that are equivalent in regard to the outcome, but inequivalent in regard to costs, time, resources. We thus face a choice within a choice. In general, a decision problem may involve several decision sub-problems, in turn involving sub-sub-problems, and so on.

The main engineering goal itself could be to design and build a device that chooses an optimal course of action in a specific kind of uncertain situation, in an automated way. Think for instance of an aeronautic engineer who is designing an autopilot system.

To analyse and face this kind of situations, we would therefore like to have a framework that takes into consideration choices, consequences, costs and gains, and uncertainties. It must also be suited to recursive application if needed. And it must be suited to being used not only for human engineers, but also for automated or artificial-intelligence devices.

Such a framework turns out to exist: it is called [**Decision Theory**]{.text-warning}.

Decision theory has a long history, going back to Leibniz in the 1600s or maybe even to Aristotle in the &minus;300s, and appearing in its present form around 1920--1960. What's remarkable about it is that it is not only *a* framework, but *the* framework we must use. A logico-mathematical theorem shows that any framework that does not break basic optimality and rationality criteria has to be equivalent to Decision Theory (in other words, it can use different technical terminology and rewrite mathematical operations in a different way, but it boils down to the same notions and operations of Decision Theory). So if you wanted to invent and use another framework, then it either (a) would lead to some irrational or illogical consequences, or (b) would lead to results identical to Decision Theory's. Many frameworks that you are probably familiar with, such as optimization theory, are just specific applications or particular cases of Decision Theory.

Decision theory consists of two main parts:  [**Probability Theory**]{.text-warning}, which deals with data, information, uncertainty, inference; and  [**Utility Theory**]{.text-warning}, which deals with actions, consequences, gain and loss, choice.

We shall get acquainted with Decision Theory step by step, introducing its main ideas and notions as they become necessary. Let us start with the first building blocks.

:::{.callout-caution}
## {{< fa seedling >}}

Remember: the main goal is to be able to identify the notions in any data-driven engineering problem. What matters is not their technical names or formal definitions, but their roles and actual use in a concrete engineering problem.
:::


## First basic notions

### Agents

The agent is the person or device that has to make a choice between different courses of action. An agent has a specific set of data and background information available, a specific set of choices, and can incur specific gains or losses dependent on the consequences of the available choices.

It is important to identify the agent or agents involved in a problem, because each one will generally have different data, or different available choices, or different gains and losses. A person buying an insurance policy from an insurance company is an example of two agents that have roughly the same data and a common course of action (buy-sell) that is optimal for both. The optimality comes from the fact that the two agents have very different gains and losses for their various courses of action.

::: {.callout-caution}
## {{< fa book-open >}} Reading
[§ 1.1.4 in *Artificial Intelligence*](https://hvl.instructure.com/courses/25074/modules/items/660089)
:::

#### Notation

When necessary, agents are typically denoted by capital letters: $A, B,\dotsc$. But we'll rarely need symbols for them.



### Sentences: data, information, hypotheses

What is "data"? "Data" (from Latin "given") is used more or less in the same sense as "information", and in these notes we'll use the two words as synonyms.

Data is often presented as numbers; but it's obviously more than that. I give you this number: "8". Is it "data"? what is it about? what should you do with it? We can hardly call this number a piece of information, since we have no clue what we could do with it. Instead, if I tell you: "*[The number of official planets in the solar system is 8](https://solarsystem.nasa.gov/planets/overview)*", then we can say that I've given you data. So "data" is not just numbers: a number is not "data" unless there's some verbal, non-numeric context associated with it -- even if this context is only implicitly understood.

Data can also be completely non-numeric. A clinician saying "*The patient has fully recovered from the disease*" (we imagine to know who's the patient and what was the disease) is giving us a piece of information that we could further use, for instance, to make prognoses about other, similar patients. The clinician's statement surely is "data". It is essentially non-numeric data, even if in some situations we can represent it as "1", say, while "0" would represent "not recovered".

From these two examples, and with some further thought, we realize that "data" -- and in general any piece of information -- can universally be represented and communicated by **sentences**, also called *propositions* or *statements*^[These three terms are not always equivalent in Formal Logic, but here we'll use them as synonyms.]. In some cases we can summarize a sentence by a number, as a shorthand, when the full meaning of the sentence is understood.

Sentences also represent and convey *hypotheses*.

Recognizing that data, information, hypotheses are ultimately represented by sentences has important practical consequences:

- **Clarity, analysis, goal-orientation.** A data engineer must acquire information and convey information. Acquiring information is not simply making some measurement or counting something: the engineer must understand *what* is being measured and *why*. If data is gathered from third parties, the engineer must ask what exactly the data mean and how they were acquired. In designing and engineering a solution, it is important to understand what information or outcomes the end user exactly wants. As a data engineer it will often happen that you ask "wait, what do you mean by that?"; this question is not just an unofficial parenthesis in the official data-transfer workflow between you and someone else. It is an integral part of that workflow; it means that the data has not been completely transferred yet.

- **Artificial Intelligence.** Sentences are the central components of knowledge representation and inference in artificial-intelligence agents.

::: {.callout-caution}
## {{< fa book-open >}} Reading
[§ 7.1 in *Artificial Intelligence*](https://hvl.instructure.com/courses/25074/modules/items/660089)
:::

#### Notation

We'll denote sentences by sans-serif italic letters: $\se{A},\se{B},\se{a},\se{b},\dotsc$ For example,
$$
\se{O} \coloneqq \pr{The power output is 100 W}
$$
means that the symbol $\se{O}$ stands for the sentence above. In the next chapters we'll see how more complex sentences are built from simpler ones. No matter whether complex or simple, any sentence can be represented by symbols like the ones above.

A set of data, being a collection of sentences, will also be denoted by this kind of symbols, very often with $\se{D}$.



"Basic" in the sense that we will not analyse these sentences into further sub-sentences. In the trivial example above we identify three such sentences: $\pr{Rita has an umbrella}$, $\pr{The umbrella is blue}$, and $\pr{The umbrella is red}$. Let's represent them by symbols:
$$
\begin{aligned}
b &\coloneqq \pr{Rita's umbrella is blue}
\\
r &\coloneqq \pr{Rita's umbrella is red}
\end{aligned}
$$

<!-- ::::{.column-margin} -->
<!-- ::: {.callout-warning appearance="simple"} -->
<!-- ## -->
<!-- {{< fa exclamation-triangle >}} Note a subtlety in our data -- and again why we need to make their underlying sentences as clear as possible: it is understood here that the umbrella is all of one colour. We'll come back to this later. -->
<!-- ::: -->
<!-- :::: -->

### Connectives

We didn't consider $\pr{Rita's umbrella is either blue or red}$, $\pr{The umbrella is not blue}$, and $\pr{The umbrella is not red}$ as basic sentences. These sentences can in fact be expressed in terms of the basic sentences $b$ and $r$. We consider one way or operation to change a sentence into another related to it, and two ways or operations to combine two or more sentences together. These operations are called **connectives**. Our natural language offers many more operations to combine sentences, but these three turn out to be all we need in virtually all engineering problems. The three connectives are:

Not: $\lnot$
: for example,
$$
\lnot b = \pr{Rita's umbrella is not blue}
$$

And: $\land$
: for example,
$$
b \land r = \pr{Rita's umbrella is blue, and it is red}
$$

Or: $\lor$
: for example,
$$
b \lor r = \pr{Rita's umbrella is blue, or red, or both}
$$

::: {.callout-warning appearance="simple"}
## 
{{< fa exclamation-triangle >}} Note some subtleties of the connectives:

- "Not" doesn't mean some kind of complementary quality, but only the negation. For instance, $\lnot\pr{Rita's umbrella is black}$ does not mean $\pr{Rita's umbrella is white}$.

- $b \lor r$ does not exclude, a priori, that the umbrella cannot be both blue and black (there is a connective for that: "exclusive-or", but it can be constructed out of the three we already have.)

- It is important to distinguish between *logical* impossibility and *physical* impossibility. It is physically impossible that an umbrella be fully white and fully black, but formal logic does allow us to consider the sentence "the umbrella is fully white and fully black", without setting it true or false a priori. We express its physical impossibility by assigning to it the value `false` in any inference we want to make. This generality of formal logic is a feature: it allows us to entertain and study hypotheses even if we still don't know whether they are physically impossible. Scientific research could not be done without this feature.
:::

What about the "if" in "if the umbrella..."? Shouldn't that be a connective? This "if" is treated in a special way; we shall now see how it works.

:::{.column-margin}
<!-- {{< fa info-circle >}}  -->
There is an [old and still ongoing debate](https://plato.stanford.edu/entries/logic-conditionals) in logic and probability on how to deal with "if"-statements. Here we take the seemingly most common approach, which is simple and effective in applied problems.
:::


Obviously we possess even more information, which is implicitly understood. For example, it's understood that the umbrella is all of one colour. It must also be understood what an umbrella is, what "red" and "blue" mean, and so on. Usually this kind of information is extremely obvious or irrelevant, so we don't think about it very much and don't mention it. In real engineering problems, however, it may happen that we have to stop and examine this implicit, hidden knowledge, maybe to check whether it contains contradictory information or contradictory goals. It's a good idea to represent this implicitly-understood information by a symbol, for example $I$ (for "extra information"; we could have used $K$ for "knowledge").




### Separating assumptions and conclusions

Now we have the sentences that represent all our data and the information we are interested in, and even symbols to represent them in a compact way. It's important to keep the assumptions we make well separated from the conclusions we want to draw. Let's introduce a symbol to do just that.

We can simply use a vertical bar: on its right side we write the sentences that make up our assumptions, and on its left side those that make up our desired conclusions.^[Current notation in logic uses the symbols $\models$ or $\vdash$, and writes assumptions on the *left*, conclusions on the *right*. We use a different notation for an easier transition to probability logic.] So, in symbols, our inference is this:
$$
b \|[\Big] (b\lor r)\, \land\, \lnot r\, \land\, \lnot(b \land r)\, \land\, D
$$
Note how we `and`-ed all assumptions together. The collection of assumptions on the right side of the bar "$\|[\big]$" is called the [**conditional**]{.text-warning}. The expression above is read "$b$ *given* $(b\lor r)$" etc., or "$b$ *conditional on* $(b\lor r)$" etc.

All data in the conditional (that is, on the right side of "$\|[\big]$") are considered (at least temporarily) to be `true`. Our goal is to determine whether the sentence on the left of "$\|[\big]$" is `true` or `false`.





## well-posed and ill-posed sentences

We face problems when the sentences that should convey information and data are not clear. Suppose that an electric-car model [consumes 150 Wh/km](https://ev-database.org/cheatsheet/energy-consumption-electric-car) and [has a range of 200 km](https://ev-database.org/cheatsheet/range-electric-car); a second car model consumes 250 Wh/km and has a range of 600 km. Someone says "I think the second model is better; what do you think?". It isn't clear how we should answer; what does "better" mean? If it refers to consumption, then the first car model is "better". If it refers to range, then the second model is "better". If it refers to a combination of these two characteristics, or to something else, then we simply can't answer. Here we have a problem with querying and giving data, because the sentence underlying such query is not clear.

We say that such sentences are **not well-posed**, or that they are **ill-posed**.

This may seem an obvious discussion to you. Yet you'd be surprised by how often unclear sentences appear in scientific papers about data engineering! Not seldom we find discussions and disagreements that actually come from unclear underlying sentences, that two parties interpret in different ways.

As a data engineer, you'll often have the upper hand if you are on the lookout for ill-posed sentences. Whenever you face an important question, or you're given an important piece of information, or you must provide an important piece of information, *always take a little time to examine whether the question or information is actually well-posed*.

@@ [TODO] Exercise: give actual paper to analyse_



## Reading list {.unnumbered}

