{
  "hash": "2f70ea3a27556cc699a8cb2b9c383675",
  "result": {
    "markdown": "# [First connection with machine learning]{.red}\n::: {.hidden}\n<!-- $$\\require{mathtools}$$ -->\n\n\\providecommand{\\ul}{\\uline}\n\\providecommand{\\and}{\\mathbin{\\mkern-0mu,\\mkern-0mu}}\n\\renewcommand*{\\|}[1][]{\\nonscript\\:#1\\vert\\nonscript\\:\\mathopen{}}\n\\providecommand*{\\pr}[1]{\\textsf{\\small`#1'}}\n\\renewcommand*{\\pr}[1]{\\textsf{\\small`#1'}}\n\\providecommand*{\\prq}[1]{\\textsf{\\small #1}}\n\\providecommand{\\se}[1]{\\mathsfit{#1}}\n\\renewcommand{\\se}[1]{\\mathsfit{#1}}\n\\providecommand{\\cat}[1]{\\texttt{\\small #1}}\n\\providecommand{\\vec}[1]{\\boldsymbol{#1}}\n\\providecommand{\\p}{\\mathrm{p}}\n\\renewcommand{\\p}{\\mathrm{p}}\n\\renewcommand{\\P}{\\mathrm{P}}\n\\definecolor{quarto-callout-note-color}{HTML}{4477AA}\n\\definecolor{quarto-callout-note-color-frame}{HTML}{4477AA}\n\\definecolor{quarto-callout-important-color}{HTML}{AA3377}\n\\definecolor{quarto-callout-important-color-frame}{HTML}{AA3377}\n\\definecolor{quarto-callout-warning-color}{HTML}{EE6677}\n\\definecolor{quarto-callout-warning-color-frame}{HTML}{EE6677}\n\\definecolor{quarto-callout-tip-color}{HTML}{228833}\n\\definecolor{quarto-callout-tip-color-frame}{HTML}{228833}\n\\definecolor{quarto-callout-caution-color}{HTML}{CCBB44}\n\\definecolor{quarto-callout-caution-color-frame}{HTML}{CCBB44}\n\\providecommand*{\\mo}[1][\\textrm{\\small=}]{\\mathrel{\\nonscript\\mkern-2.5mu#1\\nonscript\\mkern-2.5mu}}\n\\providecommand*{\\yX}{\\se{X}}\n\\providecommand*{\\yY}{\\se{Y}}\n\\providecommand*{\\yI}{\\se{I}}\n\\providecommand*{\\yi}[1][]{\\se{I}_{\\text{#1}}}\n\\providecommand{\\di}{\\mathrm{d}}\n\\providecommand{\\defd}{\\coloneqq}\n\\providecommand{\\blue}{\\color[RGB]{68,119,170}}\n\\providecommand{\\red}{\\color[RGB]{238,102,119}}\n\\providecommand{\\purple}{\\color[RGB]{170,51,119}}\n\\providecommand{\\green}{\\color[RGB]{34,136,51}}\n\\providecommand{\\yellow}{\\color[RGB]{204,187,68}}\n\\providecommand{\\lblue}{\\color[RGB]{102,204,238}}\n\\providecommand{\\grey}{\\color[RGB]{187,187,187}}\n\\providecommand{\\midgrey}{\\color[RGB]{119,119,119}}\n\\providecommand{\\black}{\\color[RGB]{0,0,0}}\n$$\n\\DeclarePairedDelimiters{\\set}{\\{}{\\}}\n\\DeclareMathOperator*{\\argmax}{arg\\,max}\n$$\n\n<!-- \\renewcommand*{\\prq}[1]{\\textsf{\\small #1}} -->\n<!-- \\definecolor{lightblue}{HTML}{66CCEE} -->\n<!-- \\sethlcolor{lightblue} -->\n<!-- \\providecommand*{\\moo}[1][=]{\\mathord{\\mkern1.5mu#1\\mkern1.5mu}} -->\n<!-- \\providecommand*{\\mo}[1][=]{\\mathrel{\\mkern-4mu#1\\mkern-4mu}} -->\n<!-- \\providecommand*{\\mo}[1][\\textrm{\\small=}]{\\mathord{\\mkern1.5mu#1\\mkern1.5mu}} -->\n\n:::\n\n\n\nSome works in machine learning focus on \"guessing the correct answer\", and this focus is reflected in the way their machine-learning algorithms -- especially classifiers -- are trained and used.\n\nIn [§ @sec-optimality] we emphasized that \"trying to guess correctly\" can be a misleading goal, however, because it can lead us away from guessing *optimally*. We shall now see two simple but concrete examples of this.\n\n## A \"max-hit\" classifier vs an optimal classifier\n\nWe shall compare the results obtained in some numerical simulations by using\n\n- a [Machine-Learning Classifier]{.yellow} trained to do most correct guesses\n- a prototype \"[Optimal Predictor Machine]{.blue}\" trained to make the optimal decision\n\nFor the moment we treat both as \"black boxes\", that is, we don't study yet how they're calculating their outputs (although you may already have a good guess at how the Optimal Predictor Machine works).\n\nTheir operation is implemented in [this R script](code/hitsvsgain.R) that we now load:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsource('code/hitsvsgain.R')\n```\n:::\n\n\nThis script simply defines the function `hitsvsgain()`:\n\n```\nhitsvsgain(ntrials, chooseAtrueA, chooseAtrueB, chooseBtrueB, chooseBtrueA, probsA)\n```\n\nhaving six arguments:\n\n- `ntrials`: how many simulations of guesses to make\n- `chooseAtrueA`: utility gained by guessing `A` when the correct guess is indeed `A`\n- `chooseAtrueB`: utility gained by guessing `A` when the correct guess is `B` instead\n- `chooseBtrueB`: utility gained by guessing `B` when the correct guess is indeed `B`\n- `chooseBtrueA`: utility gained by guessing `B` when the correct guess is `A` instead\n- `probsA`: a tuple of probabilities (between `0` and `1`) to be used in the simulations (recycling it if necessary), for the correct guess being `A`; the corresponding probabilities for `B` are therefore `1-probsA`. If this argument is omitted it defaults to `0.5` (not very interesting)\n\n\n<!-- ## chooseAtrueA=1, chooseAtrueB=0, chooseBtrueB=0, chooseBtrueA=-1, probsA=c(0.6,0.7,0.4,0.3) -->\n\n## Example 1: electronic component\n\nLet's apply our two classifiers to the *Accept or discard?* problem of [§ @sec-intro]. Let's call `A` the alternative in which the element won't fail before one year, and should therefore be accepted *if this alternative were known at the time of the decision*. Let's call `B` the alternative in which the element will fail within a year, and should therefore be discarded *if this alternative were known at the time of the decision*. Remember that the crucial point here is that the classifiers *don't* have this information at the moment of making the decision.\n\nWe simulate this decision for 100 000 components (\"trials\"), assuming that the probabilities of failure can be `0.05`, `0.20`, `0.95`, `0.80`. The values of the arguments should be clear:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhitsvsgain(ntrials=100000, chooseAtrueA=+1, chooseAtrueB=-11, chooseBtrueB=0, chooseBtrueA=0, probsA=c(0.05, 0.20, 0.95, 0.80))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nTrials: 100000\nMLC: hits 87684 ( 87.7 %) | total gain -23500\nOPM: hits 72578 ( 72.6 %) | total gain 10864\n```\n:::\n:::\n\n\nNote how the [Machine-Learning Classifier]{.yellow} is the one that *makes most correct guesses* (they should be around 88%), **and yet it leads to a net loss!** If the utility were in *kroner*, this classifier would cause the company producing the components a [net loss of around 25 000 kr]{.red}.\n\nThe [Optimal Predictor Machine]{.blue}, on the other hand, *makes fewer correct guesses* overall (they should be around 72%), **and yet it leads to a net gain!** It would earn the company a [net gain of around 10 000 kr]{.green}.\n\n\n:::{.callout-caution}\n## {{< fa user-edit >}} Exercise\nHow is this possible? Try to understand what's happening; feel free to research this by modifying the `hitsvsgain()` function, so that it prints additional outputs.\n:::\n\n## Example 2: image recognition\n\n",
    "supporting": [
      "0th_connection_ML_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}