{
  "hash": "8d43f80a84080a847a2a88e94299c9f8",
  "result": {
    "markdown": "# [Example application: adult-income task]{.red} {#sec-code-workflow}\n::: {.hidden}\n<!-- $$\\require{mathtools}$$ -->\n\n\\providecommand{\\ul}{\\uline}\n\\providecommand{\\and}{\\mathbin{\\mkern-0.5mu,\\mkern-0.5mu}}\n\\renewcommand*{\\|}[1][]{\\nonscript\\:#1\\vert\\nonscript\\:\\mathopen{}}\n\\providecommand*{\\pr}[1]{\\textsf{\\small`#1'}}\n\\renewcommand*{\\pr}[1]{\\textsf{\\small`#1'}}\n\\providecommand*{\\prq}[1]{\\textsf{\\small #1}}\n\\providecommand*{\\se}[1]{\\mathsfit{#1}}\n\\renewcommand{\\se}[1]{\\mathsfit{#1}}\n\\providecommand*{\\sei}[1]{\\mathsfit{\\small #1}}\n<!-- \\providecommand{\\cat}[1]{\\texttt{\\small #1}} -->\n\\providecommand{\\cat}[1]{{\\small\\verb;#1;}}\n\\providecommand{\\vec}[1]{\\boldsymbol{#1}}\n\\providecommand{\\p}{\\mathrm{p}}\n\\renewcommand{\\p}{\\mathrm{p}}\n\\renewcommand{\\P}{\\mathrm{P}}\n\\definecolor{quarto-callout-note-color}{HTML}{4477AA}\n\\definecolor{quarto-callout-note-color-frame}{HTML}{4477AA}\n\\definecolor{quarto-callout-important-color}{HTML}{AA3377}\n\\definecolor{quarto-callout-important-color-frame}{HTML}{AA3377}\n\\definecolor{quarto-callout-warning-color}{HTML}{EE6677}\n\\definecolor{quarto-callout-warning-color-frame}{HTML}{EE6677}\n\\definecolor{quarto-callout-tip-color}{HTML}{228833}\n\\definecolor{quarto-callout-tip-color-frame}{HTML}{228833}\n\\definecolor{quarto-callout-caution-color}{HTML}{CCBB44}\n\\definecolor{quarto-callout-caution-color-frame}{HTML}{CCBB44}\n<!-- \\providecommand*{\\mo}[1][=]{\\mathrel{\\nonscript\\mkern-3mu\\textrm{\\small#1}\\nonscript\\mkern-3mu}} -->\n\\providecommand*{\\mo}[1][=]{\\mathclose{}\\mathord{\\nonscript\\mkern0mu\\textrm{\\small#1}\\nonscript\\mkern0mu}\\mathopen{}}\n\\providecommand*{\\yX}{\\se{X}}\n\\providecommand*{\\yY}{\\se{Y}}\n\\providecommand*{\\yI}{\\se{I}}\n\\providecommand*{\\yi}[1][]{\\se{I}_{\\text{#1}}}\n\\providecommand{\\di}{\\mathrm{d}}\n\\providecommand{\\defd}{\\coloneqq}\n\\providecommand{\\blue}{\\color[RGB]{68,119,170}}\n\\providecommand{\\red}{\\color[RGB]{238,102,119}}\n\\providecommand{\\purple}{\\color[RGB]{170,51,119}}\n\\providecommand{\\green}{\\color[RGB]{34,136,51}}\n\\providecommand{\\yellow}{\\color[RGB]{204,187,68}}\n\\providecommand{\\lblue}{\\color[RGB]{102,204,238}}\n\\providecommand{\\grey}{\\color[RGB]{187,187,187}}\n\\providecommand{\\midgrey}{\\color[RGB]{119,119,119}}\n\\providecommand{\\black}{\\color[RGB]{0,0,0}}\n\\newcommand*{\\e}{\\mathrm{e}}\n\\newcommand*{\\pu}{\\text{π}}\n\\newcommand*{\\RR}{\\mathbf{R}}\n\n$$\n\\DeclarePairedDelimiters{\\set}{\\{}{\\}}\n\\DeclareMathOperator*{\\argmax}{arg\\,max}\n$$\n\n<!-- \\renewcommand*{\\prq}[1]{\\textsf{\\small #1}} -->\n<!-- \\definecolor{lightblue}{HTML}{66CCEE} -->\n<!-- \\sethlcolor{lightblue} -->\n<!-- \\providecommand*{\\moo}[1][=]{\\mathord{\\mkern1.5mu#1\\mkern1.5mu}} -->\n<!-- \\providecommand*{\\mo}[1][=]{\\mathrel{\\mkern-4mu#1\\mkern-4mu}} -->\n<!-- \\providecommand*{\\mo}[1][\\textrm{\\small=}]{\\mathord{\\mkern1.5mu#1\\mkern1.5mu}} -->\n\n:::\n\n::: {.hidden}\n\\providecommand*{\\yon}{{\\green\\cat{on}}}\n\\providecommand*{\\yof}{{\\red\\cat{off}}}\n\\providecommand*{\\yy}{{\\lblue\\cat{Y}}}\n\\providecommand*{\\yn}{{\\yellow\\cat{N}}}\n\\providecommand{\\ypl}{{\\green\\cat{+}}}\n\\providecommand{\\ymi}{{\\red\\cat{-}}}\n\\providecommand{\\ypa}{{\\green\\cat{pass}}}\n\\providecommand{\\yfa}{{\\red\\cat{fail}}}\n<!-- \\providecommand{\\ypl}{\\mathord{\\green\\boldsymbol{+}}} -->\n<!-- \\providecommand{\\ymi}{\\mathord{\\red\\boldsymbol{-}}} -->\n\\providecommand{\\hi}{{\\green\\cat{high}}}\n\\providecommand{\\me}{{\\yellow\\cat{medium}}}\n\\providecommand{\\lo}{{\\red\\cat{low}}}\n\\providecommand*{\\yJ}{\\se{J}}\n\\providecommand{\\yva}{{\\lblue-1}}\n\\providecommand{\\yvb}{{\\midgrey0}}\n\\providecommand{\\yvc}{{\\yellow1}}\n\\providecommand*{\\yK}{\\se{K}}\n\\providecommand*{\\yL}{\\se{L}}\n\n\\providecommand*{\\yR}{R}\n\n\\providecommand*{\\bZ}{{\\blue Z}}\n\\providecommand*{\\bz}{{\\blue z}}\n\\providecommand*{\\rY}{{\\red Y}}\n\\providecommand*{\\bY}{{\\blue Y}}\n\\providecommand*{\\ry}{{\\red y}}\n\\providecommand*{\\gX}{{\\green X}}\n\\providecommand*{\\bX}{{\\blue X}}\n\\providecommand*{\\gx}{{\\green x}}\n\\providecommand*{\\vf}{\\vec{f}}\n<!-- \\providecommand*{\\if}{\\se{F}} -->\n\\providecommand*{\\yut}{\\se{K}_{\\textsf{3}}}\n\\providecommand*{\\yul}{\\se{K}}\n\n\\providecommand*{\\vfa}{\\vf'}\n\\providecommand*{\\vfb}{\\vf''}\n\n:::\n\n\n::: {.hidden}\n\n\\providecommand*{\\data}{\\se{\\green data}}\n\\providecommand*{\\yD}{\\se{D}}\n\\providecommand*{\\ya}{k}\n\\providecommand*{\\amin}{\\ya_{\\text{mi}}}\n\\providecommand*{\\amax}{\\ya_{\\text{ma}}}\n\\providecommand*{\\bA}{{\\blue A}}\n\\providecommand*{\\bB}{{\\blue B}}\n\\providecommand*{\\bC}{{\\blue C}}\n\n:::\n\n\n::: {.cell}\n\n:::\n\n\nLet's illustrate the example workflow described in [§ @sec-opm-workflow] with a toy, but not too simplistic, example, based on the [adult-income dataset](https://archive.ics.uci.edu/dataset/2/adult).\n\nWe start loading the R libraries and functions needed at several stages. Make sure you are in a directory homologous to `code/OPM-nominal/`:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary('data.table')\nlibrary('foreach')\nlibrary('png')\nsource('../tplotfunctions.R')\nsource('guessmetadata.R')\nsource('buildagent.R')\nsource('infer.R')\nsource('decide.R')\nsource('rF.R')\nsource('plotFsamples1D.R')\n```\n:::\n\n\n\n## Define the task\n\nThe main task is to infer whether a USA citizen earns less (≤) or more (>) than USD 50 000/year, given a set of characteristics of that citizen. In view of later workflow stages, let's note a couple of known and unknown facts to delimit this task in a more precise manner:\n\n- Given the flexibility of the agent we shall use, we can generalize the task: to infer any subset of the set of characteristics, given any other subset. In other words, we can choose the predictand and predictor variates for any new citizen. Later on we shall also extend the task to making a concrete decision, based on utilities relevant to that citizen.\n    \n\tThis flexibility is also convenient because no explanation is given as to *what purpose* the income should be guessed.\n\n- The training data come from a 1994 census, and our agent will use an exchangeable belief distribution about the population. The value of the USD and the economic situation of the country changes from year to year, as  well as the informational relationships between economic and demographic factors. For this reason the agent should be used to draw inferences about at most one or two years around 1994. Beyond such time range the exchangeability assumption is too dubious and risky.\n\n- The [USA population in 1994 was around 260 000 000](https://www.macrotrends.net/countries/USA/united-states/population), and we shall use around 11 000 training data. The population size can therefore be considered approximately infinite.\n\n## Collect & prepare background info\n\n### Variates and domains\n\nThe variates to be used must be of nominal type, because our agent's background beliefs (represented by the Dirichlet-mixture distribution) are only appropriate for nominal variates. In this toy example we simply discard all original non-nominal variates. These included some, such as age, that would surely be relevant for this task. As a different approach, we could have coarsened each non-nominal variate into three or four range values, so that treating it as nominal would have been an acceptable approximation.\n\nFirst, create a preliminary metadata file by running the function `guessmetadata()` on the training data [`train-income_data_example.csv`](https://github.com/pglpm/ADA511/blob/master/code/OPM-nominal/train-income_data_example.csv):\n\n\n::: {.cell}\n\n```{.r .cell-code}\nguessmetadata(data='train-income_data_example.csv', file='preliminary.csv')\n```\n:::\n\n\nInspect the resulting file `preliminary.csv` and check whether you can alter it to add additional background information.\n\nAs an example, note that domain of the $\\mathit{native\\_country}$ variate does not include $\\cat{Norway}$ or $\\cat{Netherlands}$. Yet it's extremely likely that there were some native Norwegian or Dutch USA citizens in 1994; maybe too few to have been sampled into the training data. Let's add these two values to the list of domain values, and increase the domain size of $\\mathit{native\\_country}$ from 40 to 42. The resulting, updated metadata file has already been saved as [`meta_income_data_example.csv`](https://github.com/pglpm/ADA511/blob/master/code/OPM-nominal/meta_income_data_example.csv).\n\n### Agent's parameters $\\amin, \\amax$\n\nWhat could be the representative-sample size for the variates above, in the USA 1994 population? Let's put an upper bound at around 1 000 000 (that's roughly 0.5% of the whole population) with $\\kmax=20$, and a lower bound at 1 with $\\kmin=0$; these are the default values. We shall see later what the agent suggests might be a reasonable representative-sample size.\n\n## Collect & prepare training data\n\nThe 11 306 training data have been prepared by including only nominal variates, and discarding datapoints with partially missing data (although the function `buildagent()` discards such incomplete datapoints automatically). The resulting file is [`test-income_data_example.csv`](https://github.com/pglpm/ADA511/blob/master/code/OPM-nominal/test-income_data_example.csv).\n\n## Prepare OPM agent\n\nFor the sake of this example we shall prepare two agents with the same background information:\n\n- `opm10`, trained with 10 training datapoints\n- `opmall`, trained with all 11 306 training datapoints\n\nPrepare and train each with the `buildagent()` function:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nopm10 <- buildagent(metadata='meta_income_data_example.csv', data=fread('train-income_data_example.csv', header=TRUE)[1:10])\n\nopmall <- buildagent(metadata='meta_income_data_example.csv', data='train-income_data_example.csv')\n```\n:::\n\n\nWe can peek into the internal structure of these \"agent objects\" with `str()`\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstr(opmall)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nList of 4\n $ counts   : num [1:7, 1:16, 1:7, 1:14, 1:6, 1:5, 1:2, 1:42, 1:2] 0 0 0 0 0 0 0 0 0 0 ...\n  ..- attr(*, \"dimnames\")=List of 9\n  .. ..$ workclass     : chr [1:7] \"Federal-gov\" \"Local-gov\" \"Private\" \"Self-emp-inc\" ...\n  .. ..$ education     : chr [1:16] \"10th\" \"11th\" \"12th\" \"1st-4th\" ...\n  .. ..$ marital_status: chr [1:7] \"Divorced\" \"Married-AF-spouse\" \"Married-civ-spouse\" \"Married-spouse-absent\" ...\n  .. ..$ occupation    : chr [1:14] \"Adm-clerical\" \"Armed-Forces\" \"Craft-repair\" \"Exec-managerial\" ...\n  .. ..$ relationship  : chr [1:6] \"Husband\" \"Not-in-family\" \"Other-relative\" \"Own-child\" ...\n  .. ..$ race          : chr [1:5] \"Amer-Indian-Eskimo\" \"Asian-Pac-Islander\" \"Black\" \"Other\" ...\n  .. ..$ sex           : chr [1:2] \"Female\" \"Male\"\n  .. ..$ native_country: chr [1:42] \"Cambodia\" \"Canada\" \"China\" \"Columbia\" ...\n  .. ..$ income        : chr [1:2] \"<=50K\" \">50K\"\n $ alphas   : num [1:21] 1 2 4 8 16 32 64 128 256 512 ...\n $ auxalphas: num [1:21] -160706 -157643 -154588 -151547 -148530 ...\n $ palphas  : num [1:21] 0 0 0 0 0 0 0 0 0 0 ...\n```\n:::\n:::\n\n\n\\\n\nThe agent has internally guessed the representative-sample size. We can peek at its guess by plotting its `alphas` parameters against the `palphas` ones:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntplot(x=opmall$alphas, y=opmall$palphas, type='b',\n      xlim=c(0, 10000), ylim=c(0, NA),\n      xlab='representative-sample size', ylab='probability')\n```\n\n::: {.cell-output-display}\n![](example_opm1_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n\nThe most probable representative-sample size seems to be of the order of magnitude of 2000 units.\n\n## Application\n\n### Preliminary tests\n\nOur two agents are ready to be applied to new instances.\n\nBefore applying them, let's check some of their inferences, and see if we find anything unconvincing about them. If we find something unconvincing, it means that the background information we provided to the agent doesn't match the one in our intuition. Then there are two or three possibilities: our intuition is misleading us and need correcting; or we need to go back to stage [*Collect & prepare background info*]{.blue} and correct the background information given to the agent; or a combination of these two possibilities.\n\nWe ask the `opm10` agent to forecast the $\\mathit{income}$ of the next unit, using the `infer()` function:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ninfer(agent=opm10, predictand='income')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nincome\n   <=50K     >50K \n0.506288 0.493712 \n```\n:::\n:::\n\n\nThe agent gives a very slightly larger probability to the $\\cat{<=50K}$ case. Using the function `plotFsamples1D()` we can also inspect `opm10`-agent's belief about the frequency distribution of $\\mathit{income}$ for the full population. This belief is represented by a generalized scatter plot of 200 representative frequency distributions:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplotFsamples1D(agent=opm10, n=200, predictand='income',\n               ylim=c(0,1), main='opm10')\n```\n\n::: {.cell-output-display}\n![](example_opm1_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\n\nwhere the [blue line]{.blue} is the distribution previously calculated with the `infer()` function.\n\nThis plot expresses the `opm10`-agent's belief that future training data might lead to even higher probabilities for $\\cat{<=50K}$. This is corroborated by the `opmall`-agent, trained with the full training dataset:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplotFsamples1D(agent=opmall, n=200, predictand='income',\n               ylim=c(0,1), main='opmall')\n```\n\n::: {.cell-output-display}\n![](example_opm1_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n\n\nThe probability that the next unit has $\\mathit{income}\\mo\\cat{<=50}$ is now above 70%. Also note that the `opmall`-agent doesn't believe that this probability would change appreciably if more training data were provided.\n\n\\\n\nWe can perform a similar exploration for any other variate. Let's take the $\\mathit{race}$ variate:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplotFsamples1D(agent=opm10, n=200, predictand='race',\n               ylim=c(0,1), main='opm10', cex.axis=0.75)\n```\n\n::: {.cell-output-display}\n![](example_opm1_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n\n\nNote again how the little-trained `opm10`-agent has practically uniform beliefs. But it's also expressing the fact that future training data will probably increase the probability of $\\mathit{race}\\mo\\cat{White}$. This is again corroborated by the fully-trained agent:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplotFsamples1D(agent=opmall, n=200, predictand='race',\n               ylim=c(0,1), main='opmall', cex.axis=0.75)\n```\n\n::: {.cell-output-display}\n![](example_opm1_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n:::\n\n\n\\\n\nThese checks are partially satisfying, but not completely. Examine for instance the last two plots. The `opm10`-agent is not giving not high probability (less than 1/200) to the possibility that future training data will lead to probabilities for $\\mathit{race}\\mo\\cat{White}$ above 70%, which is what we are observing with the `opmall`-agent instead. So maybe we would like our agent to be more \"open-minded\" about future training data. To achieve this we would have to go back to the [*Collect & prepare background info*]{.blue} stage, and for example modify the parameters $\\amin, \\amax$, then re-check. It's even possible that we can find our present agent (more precisely, its encoded background information) not appropriate at all.\n\n:::{.callout-warning}\n## {{< fa exclamation-triangle >}} No \"test\" or \"validation\" datasets used or needed\n\nThe tests and explorations above were done without any \"validation\" or \"test\" datasets. This is because our agent is capable of calculating and showing its beliefs about the *full population* -- and therefore about future data.\n\nThe need for validation or test datasets with common machine-learning algorithms arise from the fact that full-population beliefs are hidden or, more commonly, not computed at all, in order to gain speed. The application of the trained machine-learning algorithm to a validation dataset is an approximate way of extracting such beliefs.\n\n:::\n\n\\\n\nLet's continue with one more check, specifying some predictor.\n\n\nWe ask the `opm10` agent to forecast the $\\mathit{income}$ of the next unit, using the `infer()` function:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplotFsamples1D(agent=opm10, n=200,\n               predictand='income',\n               predictor=list(workclass='Self-emp-inc', race='White'),\n               ylim=c(0,1), main='opm10')\n```\n\n::: {.cell-output-display}\n![](example_opm1_files/figure-html/unnamed-chunk-12-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nplotFsamples1D(agent=opmall, n=200,\n               predictand='income',\n               predictor=list(workclass='Self-emp-inc', race='White'),\n               ylim=c(0,1), main='opmall')\n```\n\n::: {.cell-output-display}\n![](example_opm1_files/figure-html/unnamed-chunk-13-1.png){width=672}\n:::\n:::\n",
    "supporting": [
      "example_opm1_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}