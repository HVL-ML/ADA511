# Sentences
{{< include macros.qmd >}}

We have seen that an inference involves at the very least two things: the object of the inference (*proposal*), and the data, information, or hypotheses on which the inference is based (*conditional*).

We also observed that wildly different "items" can be the object of an inference or the information on which the inference is based: measurement results, decision outcomes, hypotheses, not-real events, assumptions, data and information of all kinds (for example, images). In fact, such variety in some cases can make it difficult to pinpoint what an inference is about or what is it based on.

Is there a general, flexible, yet precise way of representing all these kinds of "items"?


## The central components of knowledge representation

When speaking of "data", what comes to mind to many people is basically numbers or collections of numbers. Maybe numbers, then, could be used to represent all the variety of items exemplified above. This option, however, turns out to be too restrictive.

I give you this number: ["$8$",]{.together} saying that it is "data". But what is it about? You, as an agent, can hardly call this number a piece of information, because you have no clue what to do with it. Instead, if I tell you: "[The number of official planets in the solar system is 8](https://solarsystem.nasa.gov/planets/overview)", then we can say that I've given you data. So "data" is not just numbers: a number is not "data" unless there's an additional verbal, non-numeric context accompanying it, even if only implicitly. Sure, we could represent this meta-data information as numbers too; but this move would only shift the problem one level up: we would need an auxiliary verbal context explaining what the meta-data numbers are about.

Data can, moreover, be completely non-numeric. A clinician saying "The patient has fully recovered from the disease" (we imagine to know who's the patient and what was the disease) is giving us a piece of information that we could further use, for instance, to make prognoses about other, similar patients. The clinician's statement surely is "data", but essentially non-numeric data. Sure, in some situations we can represent it as "1", while "0" would represent "not recovered"; but the opposite convention could also be used, or the numbers "0.3" and "174". These numbers have intrinsically nothing to do with the clinician's "recovery" data.

But the examples above actually reveal the answer to our needs. In the examples we expressed the data by means of *sentences*. Clearly any measurement result, decision outcome, hypothesis, not-real event, assumption, data, and any piece of information can be expressed by a sentence. 

We shall therefore use [**sentences**]{.blue}, also called [**propositions**]{.blue} or **statements**,^[These three terms are not always equivalent in formal logic, but here we'll use them as synonyms.] to represent and communicate all the kinds of "items" that can be the proposal or conditional of an inference. In some cases we can of course summarize a sentence by a number, as a shorthand, when the full meaning of the sentence is understood.
\
\

*Sentences are the central components of knowledge representation in AI agents*. For example they appear at the heart of automated control programs and fault-management systems in NASA spacecrafts.

:::{.column-margin}
![](SMART.png){width=100%}
(From the *SMART* paper)
:::

::: {.callout-caution}
## {{< fa book >}} Reading
- § 7.1 in [*Artificial Intelligence*](https://hvl.instructure.com/courses/25074/modules/items/660089).
- Take a *quick look* at these:
    - [*SMART: A propositional logic-based trade analysis and risk assessment tool for a complex mission*](https://hdl.handle.net/2014/45618)
    - around p. 22 in [*No More Band-Aids: Integrating FM into the Onboard Execution Architecture*](https://www.nasa.gov/sites/default/files/637606main_day_1-michel_ingham.pdf)
    - § 2.1 in [*Deliberation for autonomous robots: A survey*](http://doi.org/10.1016/j.artint.2014.11.003)
	- part IV in [*Model-based programming of intelligent embedded systems and robotic space explorers*](https://hvl.instructure.com/courses/25074/modules/items/668587)
:::

## Identifying and working with sentences

But what is a sentence, more exactly? The everyday meaning of this word will work for us, even though there are more precise definitions -- and still a lot of research in logic an artificial intelligence on how to define and use sentences. We shall adopt this useful definition:

::::{.column-margin}
::: {.callout-tip}
## {{< fa rocket >}} For the extra curious
[Propositions](https://plato.stanford.edu/archives/win2020/entries/propositions)
:::
::::

::: {.callout-note}
##
[A "sentence" is a verbal message for which we can determine whether it is `true` or `false`, at least in principle and in such a way that all interested receivers of the message would agree.]{.blue style="font-size:120%"}
:::

For instance, in most engineering contexts the phrase "[This valve will operate for at least two months]{.midgrey}" is a sentence; whereas the phrase "[Apples are much tastier than pears]{.midgrey}" is not, because it's a matter of personal taste -- there's no objective criterion to determine its truth or falsity (however, the phrase "[Rita finds apples tastier than pears]{.midgrey}" could be a sentence; its truth is found by asking Rita). In a data-science context, the phrase "[The neural-network algorithm has better performance than the random-forest one]{.midgrey}" is *not* a sentence unless we have objectively specified what "*better*" means, for example by using a particular comparison metric.

Some expressions in fact, even involving technical terms, may appear to be sentences at first, but a deeper analysis may reveal that they are not. A famous example is the sentence "[The two events (at different spatial locations) are simultaneous]{.midgrey}". Einstein showed that there's no physical way to determine whether such an expression is true or false. Its truth turns out to be a matter of convention (also in Newtonian mechanics). The Theory of Relativity was born from this observation.

::::{.column-margin}
::: {.callout-tip}
## {{< fa rocket >}} For the extra curious
[*On the electrodynamics of moving bodies*](https://einsteinpapers.press.princeton.edu/vol2-trans/154).
:::
::::

One sentence can be expressed by many different phrases and in different languages. For instance, "[The temperature is 248.15 K]{.midgrey}", "[Temperaturen ligger på minus 25 grader]{.midgrey}", and "[25 °C is the value of the temperature]{.midgrey}" all represent the *same* sentence.

A sentence can contain numbers, pictures, and graphs.

\

We agree that [*the proposal and the conditional of an inference have to be sentences*]{.blue}. This means that the proposal of the inference must be something that can only be true or false. Many inferences, especially when they concern numerical measurements, are actually collections of inferences. For example, if we want to infer what the result of rolling the die will be, we are actually considering six separate inferences with the proposals
$$
\begin{aligned}
&\pr{The result of the roll is 1}
\\
&\pr{The result of the roll is 2}
\\
&\dotso
\\
&\pr{The result of the roll is 6}
\end{aligned}
$$





We already mentioned that sentences play an important role in AI. They also have many advantages in our framework has important practical consequences:

- **Clarity, analysis, goal-orientation**. A data engineer must acquire information and convey information. "Acquiring information" does not simply consist in making measurements or counting something: the engineer must understand *what* is being measured and *why*. If data is gathered from third parties, the engineer must ask what exactly the data mean and how they were acquired. In designing and engineering a solution, it is important to understand what information or outcomes the end user exactly wants. A data engineer will often ask "*wait, what do you mean by that?*". This question is not just an unofficial parenthesis in the official data-transfer workflow between the engineer and someone else. It is an integral part of that workflow: it means that some data have not been completely transferred yet.


### Notation

In these notes we'll denote sentences by sans-serif italic letters: $\se{A},\se{B},\se{a},\se{b},\dotsc$ For example,
$$
\se{A} \coloneqq \pr{The power output is 100\,W}
$$
means that the symbol $\se{A}$ stands for the sentence above. Often we shall simply write sentences in abbreviated form, when their full meaning is understood from the context. For instance, we could abbreviate the sentence above to
["$O = 100\,\mathrm{W}$"]{.together}, where $O$ is a physical variable (not a sentence!) denoting the power output; or even just to ["$100\,\mathrm{W}$"]{.together}.

We'll next see how more complex sentences are built from simpler ones. No matter whether complex or simple, any sentence can be represented by symbols like the ones above.

## Combining sentences

### Basic sentences

In analysing the information, data, outcomes, hypotheses that enter into an inference problem, it is convenient to find a collection of [**basic sentences**]{.blue}^[A more technical term is *atomic sentences*.] out of which all other sentences of interest can be constructed. These basic sentences often represent elementary pieces of information in the problem.

Consider for instance the following statement, which could appear in our assembly-line scenario:

> "The electronic component is still whole after the shock test and the subsequent heating test. The voltage reported in the power test is either 90 mV or 110 mV."

<!-- In the assembly-line scenario, the statement above represents data, that is, it's the description of a factual situation. But keep in mind that in a different problem -- say, one where it need to be assessed whether the component is still whole -- the same statement could represent a hypothesis, that is, one possible state of affairs among other possible ones. -->

In this statement we can identify at least four basic sentences, which we denote by convenient symbols:
$$\begin{aligned}
\se{s} &\coloneqq \pr{The component is whole after the shock test}
\\
\se{h} &\coloneqq \pr{The component is whole after the heating test}
\\
\se{v}_{90} &\coloneqq \pr{The power-test voltage reading is 90\,mV}
\\
\se{v}_{110} &\coloneqq \pr{The power-test voltage reading is 110\,mV}
\end{aligned}
$$

The inference may actually require more basic sentences than just these. For instance, it might become necessary to consider basic sentences with other values for the reported voltage, such as
$$\begin{aligned}
\se{v}_{110} &\coloneqq \pr{The power-test voltage reading is 100\,mV}
\\
\se{v}_{80} &\coloneqq \pr{The power-test voltage reading is 80\,mV}
\end{aligned}$$
and so on.

There may also be other basic sentences coming from data or hypotheses that aren't stated explicitly because they're obvious. Yet they may have to be spelled out. An example in our scenario is the sentence
$$
\pr{The electronic component cannot be broken after the shock test and whole after the subsequent heating test}
$$
which must necessarily be true for physical reasons.

### Connectives

How do we construct the statement above and other more complex statements out of basic sentences?

We consider one operation to change a sentence into another related to it, and two operations to combine two or more sentences together. These operations are called [**connectives**]{.blue}, and you may have already encountered them in Boolean algebra. Our natural language offers many more operations to combine sentences, but these three connectives turn out to be all we need in virtually all engineering and data science problems:

:::{.border}
[Not:\ \ $\lnot$]{.blue}
: for example,
$$
\lnot \se{s} = \pr{The component is broken after the shock test}
$$

[And:\ \ $\land$]{.blue}
: for example,
$$
\se{s} \land \se{h} = \pr{The component is whole after the shock and heating tests}
$$

[Or:\ \ $\lor$]{.blue}
: for example,
$$
\se{v}_{90} \lor \se{v}_{110} = \pr{The power-test voltage reading is 90\,mV, or 110\,mV, or both}
$$
:::
\

The connectives can be applied multiple times, to form increasingly complex sentences.

{{< fa exclamation-circle >}}\ \ Note some important subtleties of the connectives:

- There is no strict correspondence between the words "not", "and", "or" in natural language and the three connectives. For instance the `and` connective could correspond to the words "but" or "whereas", or just to a comma " , ".

- `Not` doesn't mean some kind of complementary quality, but only the negation. For instance,\ \ $\lnot\pr{The chair is black}$\ \ generally does not mean\ \ [$\pr{The chair is white}$ ,]{.together}\ \  although in some situations these two sentences could amount to the same thing.

    It's best to always declare explicitly what the `not` of a sentence concretely means. In our example we take
	$$
	\lnot\pr{The component is whole} \equiv \pr{The component is broken}
	$$ 
	But in other examples the negation of "being whole" could comprise several different conditions. A good guideline is to always state the `not` of a sentence in *positive* terms.

- `Or` does not exclude that both the sentences it connects can be true. So in our example\ \ $\se{v}_{90} \lor \se{v}_{110}$\ \ does not exclude, a priori, that the reported voltage could be both 90 mV and 110 mV. (There is a connective for that: "exclusive-or", but it can be constructed out of the three we already have.)

From the last remark we see that the sentence
$$
\pr{The power-test voltage reading is 90\,mV or 110\,mV}
$$
does *not* correspond to \ \ [$\se{v}_{90} \lor \se{v}_{110}$ .]{.together}\ \ It is implicitly clear that a voltage reading cannot yield two different values at the same time. Convince yourself that the correct way to write that sentence is this:
$$
(\se{v}_{90} \lor \se{v}_{110})
\land
\lnot(\se{v}_{90} \land \se{v}_{110})
$$

Finally, the full data statement of our present example can be written in symbols as follows:
$$
\se{s} \land \se{h} \land
(\se{v}_{90} \lor \se{v}_{110})
\land
\lnot(\se{v}_{90} \land \se{v}_{110})
$$


## Distinguishing assumptions and outcomes

Now we know how to represent arbitrarily complex sentences and express them in symbols. Let's introduce a way to clearly distinguish sentences that constitute the *assumptions* from those that constitute the *outcome* in a basic decision problem. In our assembly-line example, suppose that assumptions are the statement discussed in the previous section. The outcome to be inferred is expressed by this sentence:
$$
\se{f} \coloneqq \pr{The component will fail within a year}
$$

To distinguish assumptions and outcomes we can simply use a vertical bar,^[Notation in formal logic uses the symbols\ \ [" $\models$ "]{.together}\ \ or\ \ [" $\vdash$ ",]{.together}\ \ and writes assumptions on the *left*, outcomes on the *right*. We use the notation used in probability logic.] like\ \ ["$\color[RGB]{68,119,170}\pmb{\|[\big]}$" :]{.together}

- on its *left* side we write the sentence representing the *outcome*,
- on its *right* side we write the sentences that make up our *assumptions*, `and`-ed together:

$$
\textit{\small outcome} \pmb{\|[\big]} \textit{\small assumptions}
$$

So in our example we write:
$$
f \|[\Big]
\se{s} \land \se{h} \land
(\se{v}_{90} \lor \se{v}_{110})
\land
\lnot(\se{v}_{90} \land \se{v}_{110})
$$

The collection of assumptions on the right side of the bar ["$\pmb{\|[\big]}$"]{.together} is called the [**conditional**]{.blue}. The expression above is read\
["$\se{c}_{2,90}$\ \  *given*\ \  $\se{t}_{1,50} \land \se{t}_{2,50}
\land\dotsb$"]{.together}\
or\
["$\se{c}_{2,90}$\ \  *conditional on*\ \  $\se{t}_{1,50} \land \se{t}_{2,50} \land\dotsb$".]{.together}

\

We are now equipped with all the notions and symbolic notation to deal with our first concrete goal: drawing uncertain inferences.

## Inferences: certain and uncertain

In a decision problem we have a set of different outcomes that we want to assess given the same assumptions:
$$\begin{aligned}
\textit{\small outcome\,1} &\pmb{\|[\big]} \textit{\small assumptions}
\\
\textit{\small outcome\,2} &\pmb{\|[\big]} \textit{\small assumptions}
\\
\textit{\small outcome\,3} &\pmb{\|[\big]} \textit{\small assumptions}
\\
\dotso&
\end{aligned}$$

The first goal in a decision problem is to assess these outcomes. What do we mean by "assess"? We cannot demand that the truth or falsity of the outcomes be determined with certainty. 
