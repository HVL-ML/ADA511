{{< include macros.qmd >}}

# A first look at machine-learning algorithms {#sec-view-ML}

So far we have been speaking about inference and data, and haven't made any mention of machine-learning algorithms, although they may have been evoked in your mind in some inference scenarios that we discussed. Let's point out now some intuitive connections between machine learning and what we have studied so far; so that more precise quantitative connections that we'll draw later will not be completely unexpected.

A machine-learning algorithm is usually presented in textbooks as something that first "learns" from data, and thereafter can repeatedly perform some kind of task. This task can usually be reduced, essentially, to give a numeric output. How the learning happens, and how the learned data influence the output, both depend on the kind of algorithm.

If you have been exposed to machine-learning textbooks before, a re-orientation and change in point of view may be necessary.

## "Unsupervised" vs "supervised": <br>information used at each new application

Typically a distinction is made between "supervised" and "unsupervised" learning, but its explanation can be misleading:

- Some books say that in supervised learning the algorithm "learns a functional relationship between input and output". This is usually *not* true, because in the vast majority of applications there isn't any *functional* relationship between input and output, but only a *statistical* or *probabilistic* one. So  no function exists at all that can be learned. This is clear also from the fact that two learning datapoints can have identical inputs but different outputs; you remember from Calculus I that we can't speak of a function in this case.

    The algorithm is actually doing something more complex, which we'll analyse in detail later.

- Yet other books say that the distinction rests in the kind of data used: "input-output" pairs for supervised learning, and only "inputs" for unsupervised learning. It's good that this description doesn't mention "functions", but it is still quite poor and misleading, because it confuses the means for the purpose. It's a little like saying that the difference between car and aeroplane is that the latter has wings. Sure -- but *why?* This description misses their essential difference: the two transportation means operate through different material media and exploit different kinds of physics; that's why the second has wings.

    From this point of view the very terms "supervised learning" and "unsupervised learning" are somewhat poor, suffering from the same drawback.

- More enlightening books explain that the distinction rests in what the algorithm needs for each new application: in supervised learning, it uses features (that is, information), that is available at each new application; in unsupervised learning, it doesn't use any new information at each new application.

When considered from the latter, informational, point of view, the distinction between "supervised" and "unsupervised" becomes less sharp: we can imagine to increase the information that's used at each new instance, from zero ("unsupervised") to larger and larger amounts ("supervised").

## Output

Looking at their output, machine-learning algorithms are often categorized as doing "classification", if the output is discrete (and usually finite); or "regression", if the output is continuous.













