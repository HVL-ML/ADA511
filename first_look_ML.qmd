{{< include macros.qmd >}}

# A first look at machine-learning algorithms {#sec-view-ML}

So far we have been speaking about inference and data, and haven't made any mention of machine-learning algorithms, although they may have been evoked in your mind in some inference scenarios that we discussed. Let's point out now some intuitive connections between machine learning and what we have studied so far; so that more precise quantitative connections that we'll draw later will not be completely unexpected.

If you have been exposed to machine-learning textbooks before, a re-orientation and change in point of view may be necessary.

A machine-learning algorithm is usually presented in textbooks as something that first "learns" from data, and thereafter can repeatedly perform some kind of task. This task can usually be reduced, essentially, to give a numeric output. How the learning happens, and how the learned data influence the output, both depend on the kind of algorithm.

Typically a distinction is also made between "supervised" and "unsupervised" learning, and the explanation given is frequently misleading:

- Some books say that in supervised learning the algorithm "learns a functional relationship between input and output". This is usually *not* true, because in the vast majority of applications there isn't any *functional* relationship between input and output, but only a *statistical* or *probabilistic* one. So there's no function at all that can be learned. This is clear also from the fact that two learning datapoints can have identical inputs but different outputs; and you remember from Calculus I that we can't speak about a function in this case.

    The algorithm is doing actually something more complex, which we'll analyse more in detail later.

- Yet other books say that the distinction rests in the kind of data used: "input-output" pairs for supervised learning, and only "inputs" for unsupervised learning. It's good that this description doesn't mention "functions", but it is still quite poor and misleading, because it confuses the means for the purpose. It's a little like saying that the difference between car and aeroplane is that the latter has wings. Sure -- but *why?* This description misses the main point: that the two transportation means operate through different material media and exploit different kinds of physics; that's why the second has wings.

    The very terms "supervised learning" and "unsupervised learning" are in fact somewhat poor terms, suffering the same drawback.

- Better books say that the distinction rests in what the algorithm needs for each new application: in supervised learning, it uses features, or more generally information, that is available in the new application; in unsupervised learning, it doesn't use any new information in each new application.







