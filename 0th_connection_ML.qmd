# [First connection with machine learning]{.red}
{{< include macros.qmd >}}

Some works in machine learning focus on "guessing the correct answer", and this focus is reflected in the way their machine-learning algorithms -- especially classifiers -- are trained and used.

In [§ @sec-optimality] we emphasized that "trying to guess correctly" can be a misleading goal, however, because it can lead us away from guessing *optimally*. We shall now see two simple but concrete examples of this.

## A "max-hit" classifier vs an optimal classifier

We shall compare the results obtained in some numerical simulations by using

- a [Machine-Learning Classifier]{.yellow} trained to do most correct guesses
- a prototype "[Optimal Predictor Machine]{.blue}" trained to make the optimal decision

For the moment we treat both as "black boxes", that is, we don't study yet how they're calculating their outputs (although you may already have a good guess at how the Optimal Predictor Machine works).

Their operation is implemented in [this R script](code/hitsvsgain.R) that we now load:

```{r}
source('code/hitsvsgain.R')
```

This script simply defines the function `hitsvsgain()`:

```
hitsvsgain(ntrials, chooseAtrueA, chooseAtrueB, chooseBtrueB, chooseBtrueA, probsA)
```

having six arguments:

- `ntrials`: how many simulations of guesses to make
- `chooseAtrueA`: utility gained by guessing `A` when the correct guess is indeed `A`
- `chooseAtrueB`: utility gained by guessing `A` when the correct guess is `B` instead
- `chooseBtrueB`: utility gained by guessing `B` when the correct guess is indeed `B`
- `chooseBtrueA`: utility gained by guessing `B` when the correct guess is `A` instead
- `probsA`: a tuple of probabilities (between `0` and `1`) to be used in the simulations (recycling it if necessary), for the correct guess being `A`; the corresponding probabilities for `B` are therefore `1-probsA`. If this argument is omitted it defaults to `0.5` (not very interesting)


<!-- ## chooseAtrueA=1, chooseAtrueB=0, chooseBtrueB=0, chooseBtrueA=-1, probsA=c(0.6,0.7,0.4,0.3) -->

## Example 1: electronic component

Let's apply our two classifiers to the *Accept or discard?* problem of [§ @sec-intro]. Let's call `A` the alternative in which the element won't fail before one year, and should therefore be accepted *if this alternative were known at the time of the decision*. Let's call `B` the alternative in which the element will fail within a year, and should therefore be discarded *if this alternative were known at the time of the decision*. Remember that the crucial point here is that the classifiers *don't* have this information at the moment of making the decision.

We simulate this decision for 100 000 components ("trials"), assuming that the probabilities of failure can be `0.05`, `0.20`, `0.95`, `0.80`. The values of the arguments should be clear:

```{r}
hitsvsgain(ntrials=100000, chooseAtrueA=+1, chooseAtrueB=-11, chooseBtrueB=0, chooseBtrueA=0, probsA=c(0.05, 0.20, 0.95, 0.80))
```

Note how the [Machine-Learning Classifier]{.yellow} is the one that *makes most correct guesses* (around 88%), **and yet it leads to a net loss!** If the utility were in *kroner*, this classifier would cause the company producing the components a [net loss of more than 20 000 kr]{.red}.

The [Optimal Predictor Machine]{.blue}, on the other hand, *makes fewer correct guesses* overall (around 72%), **and yet it leads to a net gain!** It would earn the company a [net gain of around 10 000 kr]{.green}.


:::{.callout-caution}
## {{< fa user-edit >}} Exercise
How is this possible? Try to understand what's happening; feel free to research this by modifying the `hitsvsgain()` function, so that it prints additional outputs.
:::


## Example 2: image recognition

