# [Exchangeable beliefs]{.green} {#sec-exchangeable-beliefs}
{{< include macros.qmd >}}
{{< include macros_populations_variates.qmd >}}

## Recap {#sec-recap-before-exchang}

In the chapters of part [Inference I]{.green} we had an overview of how an agent can draw inferences and make predictions of the most general kind, expressed by general sentences, using the four fundamental rules of inference.

Then, in the chapters of part [Inference II]{.green}, we successively narrowed our focus on more and more specialized kinds of inference typical of engineering and data-science problems and machine-learning algorithms: first, inferences about measurements and observations; and then inferences about multiple instances of similar measurements and observations. For these purposes we introduced a specialized language about quantities and data types (chapters of part [Data I]{.yellow}), and "populations" of similar data (chapters of part [Data II]{.yellow}).

The idea was that that an agent can arrive at sharper degrees of belief -- that is, learn -- by using information about "similar instances". We also found the main formula, derived from the four fundamental rules, that takes care of learning and prediction (also in both "supervised" and "unsupervised" machine learning):

:::{.column-page-right}
$$
\begin{aligned}
    &\P\bigl(
	{\red Y_{N+1} \mo y_{N+1}}
	\pmb{\|[\big]} 
	{\red X_{N+1} \mo x_{N+1}}\, \and\,
    \green Y_N \mo y_N \and X_N \mo x_N \and
	\dotsb \and 
	Y_1 \mo y_1 \and X_1 \mo x_1 
    \black\and {\yellow\yI} \bigr)
	\\[2ex]
	&\qquad{}=
	\frac{
	    \P\bigl(
	\red Y_{N+1} \mo y_{N+1} \and
	\red X_{N+1} \mo x_{N+1}
	\black
		\and
    \green Y_N \mo y_N \and X_N \mo x_N
	\and
	\dotsb \and 
	\green Y_1 \mo y_1 \and X_1 \mo x_1 
    \black\pmb{\|[\big]} {\yellow\yI} \bigr)
}{
	 \sum_{\red y} \P\bigl(
	{\red Y_{N+1} \mo y} \and
	{\red X_{N+1} \mo x_{N+1}}
		\and
    \green Y_N \mo y_N \and X_N \mo x_N \and
	\dotsb \and 
	Y_1 \mo y_1 \and X_1 \mo x_1 
    \black\pmb{\|[\big]}  {\yellow\yI} \bigr)
}
\end{aligned}
$$
:::

To calculate this formula, an agent needs the joint probability distribution

$$
	    \P\bigl(
	\red Y_{N+1} \mo y_{N+1} \and
	\red X_{N+1} \mo x_{N+1}
	\black
		\and
    \green Y_N \mo y_N \and X_N \mo x_N
	\and
	\dotsb \and 
	\green Y_1 \mo y_1 \and X_1 \mo x_1 
    \black\pmb{\|[\big]} {\yellow\yI} \bigr)
$$

for all possible values of $x_1,y_1$, $x_2, y_2$, $\dotsc$, and for a possibly unlimited number $N+1$ of instances.

\

We shall now narrow our focus further for one last time, on inferences where this probability distribution satisfies a property that greatly simplifies the calculations. Such special inferences are also typical of many machine-learning applications, including "supervised" and "unsupervised" learning.

\

## Exchangeable degrees of belief {#sec-exchang-degrees}

An agent's degrees of belief about a particular population may satisfy a special symmetry, usually called "exchangeability". This symmetry can be understood from different points of view. We start from one of these viewpoints, and then make connections with alternative ones.

Take again the two populations briefly mentioned in [§ @sec-collections]

- Stock exchange
: The daily change in closing price of a stock during 1000 consecutive days. Each day the change can be positive or zero: $\ypl$, or negative: $\ymi$.

:::{.column-margin}
![](stock_course.jpg){width=50%}
:::


- Mars prospecting
: A collection of 1000 similar-sized rocks gathered from a specific, large crater on Mars. Each rock either contains hematite: $\yy$, or it doesn't: $\yn$.

:::{.column-margin}
![](mars_crater2.jpg){width=50%}
:::

\

Suppose that, in each of these populations, you (the agent) don't know the variate value for unit [#735]{.yellow}, and for some reason would like to infer it. You are given the variate value for 100 other units, which you can use to improve your inference (by using them in the conditional). Now consider this question:

> [*How much does the relative order of the 100 known units and the unknown unit matter to you, for drawing your inference?*]{.lightblue}

We know, from information theory, that it never hurts having extra information, such as the units' order. But you probably judge the units' order to be much more important for your inference in the stock-exchange case than in the Mars-prospecting one. In the stock-exchange case it would be more informative to have data from units temporally close to unit [#735]{.yellow}; for example units [#635--#734]{.yellow}, or [#736--#835]{.yellow}, or [#685--#734]{.yellow} & [#736--#785]{.yellow}, or similar ranges. In the Mars-prospecting case we might still find it acceptable if the 100 known units were picked up in some unsystematic way from the catalogue of remaining 999 units. There are reasons, boiling down to physics, behind this kind of judgement.

The question above could also be replaced by others, slightly different but still connected to the same issue. For example:

> [*How strongly would you wish to be able to choose which 100 units you can have data from, in order to draw your inference?*]{.lightblue}

or

> [*How much would you be upset if the original order of the population units were destroyed by accidental shuffling?*]{.lightblue}

or

> [*Would it be acceptable to you if only the **frequencies** of the values ($\set{\ypl,\ymi}$ in one case, $\set{\yy,\yn}$ in the other) in the 100 known units were given to you?*]{.lightblue}


:::{.callout-caution}
## {{< fa user-edit >}} Exercise
- Find examples of populations where the units have some kind of ordering that you think would be *very* important for drawing inferences about some units, given other units. Examine why you judge such ordering to be important. (The ordering doesn't need to be one-dimensional. For instance, the pixel intensities of an image also have a two-dimensional relative order or position: is that important if you want to draw inferences about the intensities of some pixels from those of other pixels?)

- Find examples of populations where any potential ordering of the units would *not* be very important for drawing inferences about some units, given other units. Or, put it otherwise, you wouldn't be excessively upset or worried if such order were lost owing to accidental shuffling of the units.
:::






### Stock exchange and Mars prospecting, again

Consider the following two sketches of inference problems, related to the scenarios of [§ @sec-collections]:

- Stock exchange
: In 100 days, the daily change in closing price of a stock has been `positive` 74 times, and `negative` 26 times, according a particular sequence; for instance:

    ![](stock.png){width=100%}

    In which of the subsequent 3 days will the closing-price change be positive, and in which negative?

:::{.column-margin}
![](stock_course.jpg){width=100%}
:::

\

- Mars prospecting
: Of the last 100 similar-sized rocks examined in a large crater on Mars, 74 contained hematite (`Y`), and 26 did not (`N`). For instance, the data could be:

    ![](rock.png){width=100%}

    Which, among the next 3 rocks that will be examined, will contain hematite, and which will be hematite-free?

:::{.column-margin}
![](mars_crater2.jpg){width=100%}
:::



To solve *any* inference problem, or to design an AI agent for solving an inference problem, all we have to do in principle is to repeatedly use the [fundamental laws of inference of § @sec-fundamental].

In many cases an in-principle application of the inference laws is computationally impossible, however. Approximate calculations and premises are then used, which are sometimes quite drastic. The approximations used depend on the nature of the inference problem. This leads to many "recipes", which may look extremely different from one another, being used in specialized fields and applications. People working in those fields are trained to use those recipes.

:::{.column-margin}
[![](ibm_quantum.jpg){width=100%}](https://www.flickr.com/photos/ibm_research_zurich/52714013388/)
Technological advances such as quantum computing may make the use of more powerful exact inference methods possible -- for those who know them.
:::

For a data-science engineer it is important to keep in mind that these recipes are only approximations, and that there are only a couple of principles underlying all of them, despite their diversity. The principled, maximally optimal solution should always be kept in sight. Technological advances continually allow us to make computations that were previously impossible -- think of "quantum computers" these days. A truly optimal in-principle solution, preferable to a sub-optimal approximation, can suddenly become accessible -- to those who know it!

\

We shall now introduce a very broad class of inference problems. They include tasks performed by most common machine-learning algorithms: classification and regression, "supervised" and "unsupervised" learning, and similar. After studying the principled solution to this class of problems we'll discuss present-day approximations to it.


## Induction

It is a fact of everyday experience that we expect things to happen in particular ways because of our previous experience with similar things. If we observe that ten electronic components in a row come out damaged from an assembly line, then we expect that the next one will be damaged as well. If you regularly go hiking in a particular area and often see deer, and sometimes hares, then you think it likely to see deer also at your next hike and, if you're lucky, a hare. You would probably be surprised to see a moose if you had never seen one in those areas. This doesn't only concern the future: if someone asks you whether you saw a deer during a hike from long time ago, which you don't quite remember anymore, you'd say "probably I did".

This familiar experience is called [*induction*](https://plato.stanford.edu/entries/induction-problem/), especially in the philosophical literature. It has generated a lot of thought and research since the times of [Hume](https://plato.stanford.edu/entries/hume/) (18th century), who apparently was the first to ask how and why this experience is possible.

But this kind of regularities does not have clear-cut circumstances. In some cases it is not clear what should be considered "similar" things -- in fact, sometimes we circularly reverse the reasoning: if something does not respect an observed regularity then we say it wasn't "similar". Also the circumstances in which this regularity should occur are often not-well-defined: should you expect to see deer if you hike in a somewhat different area?

And sometimes this kind of regularities simply fails. Something expected doesn't happen any longer, even if the circumstances and the "similarity" are clearly the same. Jeffreys aptly said:

> [A common argument for induction is that induction has always worked in the past and therefore may be expected to hold in the future. It has been objected that this is itself an inductive argumentand cannot be used in support of induction. What is hardly ever mentioned is that induction has often failed in the past and that progress in science is very largely the consequence of direct attention to instances where the inductive method has led to incorrect predictions.]{.small}

::::{.column-margin}
::: {.callout-tip}
## {{< fa rocket >}} For the extra curious
Chapter I of [*Scientific Inference* (3rd ed.)](https://hvl.instructure.com/courses/25074/modules/items/678374) is an extremely insightful reading about inference, probability, and science.
:::
::::


### Induction and data science

Induction, with the mentioned caveats that accompany it, is at the basis of how we approach and solve many engineering problems, and at the heart of data science: from data about particular things or phenomena we try to infer new or old instances of "similar" things or phenomena.

We shall now see how this is done in a quantitative manner with the probability calculus. It is important to clarify what the probability calculus, and all approximate inference methods derived from it, can and cannot do:

- [{{< fa check >}} It allows us to make inductive inferences in a *quantitative* and guaranteed *self-consistent* way.]{.green}

- [{{< fa times >}} It does not *explain* why there are regularities and why induction in some cases works.]{.red}

- [{{< fa times >}} It does *not* tell us which things or phenomena should be considered "similar". In fact, what's similar and what's not is something that *we must input* into the probability calculus.]{.red}

- [{{< fa check >}} If we formulate the "similarity" and "non-similarity" of an instance as well-defined hypotheses, then the probability calculus allows us to calculate their probabilities (and make a decision as to accept, if necessary).]{.green}



## Inferences and populations {#sec-two-populations}

### Stock exchange and Mars prospecting, again

Consider the following two sketches of inference problems, related to the scenarios of [§ @sec-collections]:

- Stock exchange
: In 100 days, the daily change in closing price of a stock has been `positive` 74 times, and `negative` 26 times, according a particular sequence; for instance:

    ![](stock.png){width=100%}

    In which of the subsequent 3 days will the closing-price change be positive, and in which negative?

:::{.column-margin}
![](stock_course.jpg){width=100%}
:::

\

- Mars prospecting
: Of the last 100 similar-sized rocks examined in a large crater on Mars, 74 contained hematite (`Y`), and 26 did not (`N`). For instance, the data could be:

    ![](rock.png){width=100%}

    Which, among the next 3 rocks that will be examined, will contain hematite, and which will be hematite-free?

:::{.column-margin}
![](mars_crater2.jpg){width=100%}
:::


:::{.callout-caution}
## {{< fa user-edit >}} Exercise
Discuss:

- Which of the two inferences above seems more difficult?...

- ...Why? Speculate on which factors make one inference more difficult than the other.

- Which differences and similarities do you find between the two inferences?

- Which additional information could be important for drawing more precise inferences?

- Which type of quantities appear in the two inferences?

<!-- - Answer the same questions, considering two inference problems that are similar but "backwards in time": -->

<!--     1b. Assessing the value that a particular investment fund had in 3750 days ago, given the course of that fund in the past 3650 days. -->

<!--     2b. Assessing the failure status of the past 1100th electronic component from an assembly line, given the failure status of the last 1000 electronic components already out of the same assembly line. -->
:::

### Translation into sentences

Let us remember [chapter @sec-probability] that in order to set up and solve an inference problem we must first define appropriate *sentences* which we'll use in probability supposals and conditionals.

For the two problems above it looks obvious that we can use sentences involving the language of statistical populations. We must then try to define the units and the variates. *Tentatively* let's try the following definitions:

Stock exchange
: - *Units:* the problem is only sketched, so let's assume that a precise definition can be found somewhere. There are at least 100 + 3 units, but the problem suggests that we might consider an infinite population.
    - *Variates:* the change in closing price seems an obvious binary variate for the population. Let's denote it $C$, with domain $\set{\ypl,\ymi}$.


Mars prospecting
: - *Units:* again the problem is only sketched, so let's assume that a precise description exists of how the rocks to be examined should be chosen. There are at least 100 + 3 units, but the problem suggests that we might consider a practically infinite population.
    - *Variates:* the presence of hematite is an obvious binary variate. Let's denote it with $H$, with domain $\set{\yy,\yn}$.


The population data can be represented as follows, where question marks **`?`** indicate the units about which we want to draw inferences, and the ellipses "[...]{.midgrey}" indicate that the populations possibly extend to infinite other units:

::::{.columns}

:::::{.column width="40%"}
|  [unit]{.yellow}  | $C$             |
|:--:|:------:|
| [...]{.midgrey}   | [...]{.midgrey} |
| [1]{.yellow}      | $\ymi$          |
| [2]{.yellow}      | $\ymi$          |
| [3]{.yellow}      | $\ypl$          |
| [4]{.yellow}      | $\ymi$          |
| [5]{.yellow}      | $\ypl$          |
| [6]{.yellow}      | $\ymi$          |
|[(omitted)]{.grey .small}|[(omitted)]{.grey .small}|
| [95]{.yellow}     | $\ypl$          |
| [96]{.yellow}     | $\ypl$          |
| [97]{.yellow}     | $\ypl$          |
| [98]{.yellow}     | $\ypl$          |
| [99]{.yellow}     | $\ypl$          |
| [100]{.yellow}    | $\ypl$          |
| [101]{.yellow}    | **`?`**         |
| [102]{.yellow}    | **`?`**         |
| [103]{.yellow}    | **`?`**         |
| [...]{.midgrey}   | [...]{.midgrey} |
: Stock exchange {#tbl-stock .sm .striped}
:::::

:::::{.column width="20%"}

:::::

:::::{.column width="40%"}
|  [unit]{.yellow}  | $H$             |
|:--:|:------:|
| [...]{.midgrey}   | [...]{.midgrey} |
| [1]{.yellow}      | $\yy$           |
| [2]{.yellow}      | $\yy$           |
| [3]{.yellow}      | $\yn$           |
| [4]{.yellow}      | $\yy$           |
| [5]{.yellow}      | $\yy$           |
| [6]{.yellow}      | $\yy$           |
|[(omitted)]{.grey .small}|[(omitted)]{.grey .small}|
| [95]{.yellow}     | $\yn$           |
| [96]{.yellow}     | $\yy$           |
| [97]{.yellow}     | $\yn$           |
| [98]{.yellow}     | $\yy$           |
| [99]{.yellow}     | $\yy$           |
| [100]{.yellow}    | $\yy$           |
| [101]{.yellow}    | **`?`**         |
| [102]{.yellow}    | **`?`**         |
| [103]{.yellow}    | **`?`**         |
| [...]{.midgrey}   | [...]{.midgrey} |
: Mars prospecting {#tbl-mars .sm .striped}

:::::
::::

:::{.callout-caution}
## {{< fa user-edit >}} Exercise
Would you define these two populations in a different way? Do you think other variates should be included, for example?
:::

### Desired probabilities

The stock-exchange  problem asks "In which of the subsequent 3 days will the closing-price change be positive, and in which negative?". In terms of the populations just introduced, this can be translated into:
\
\
"will the $C$ variate for units #101, #102, #103 have value $\ypl$ or $\ymi$?"

In other words, we are asking which of the two following mutually exclusive sentences, expressed symbolically, will be true:

$$
C_{101}\mo\ypl \qquad C_{101}\mo\ymi
$$

Since one of them must be true, their probabilities form a probability distribution ([§ @sec-prob-distribs]), in which for the moment we omit the conditional:

$$
\P\bigl(C_{101}\mo\ypl \pmb{\|[\big]}  \quad\quad
\P\bigl(C_{101}\mo\ymi \pmb{\|[\big]}
$$

Analogously for units #102 and #103, leading to two more probability distributions.

When we `and` together sentences for the three units we obtain a joint probability distribution ([§ @sec-prob-joint]) over 2³ = 8 mutually exclusive and exhaustive composite sentences:

$$\begin{aligned}
&\P\bigl(C_{101}\mo\ypl \and C_{102}\mo\ypl \and C_{103}\mo\ypl
\pmb{\|[\big]}
\\[1ex]
&\P\bigl(C_{101}\mo\ymi \and C_{102}\mo\ypl \and C_{103}\mo\ypl
\pmb{\|[\big]}
\\[1ex]
&\dotso
\\[1ex]
&\P\bigl(C_{101}\mo\ymi \and C_{102}\mo\ymi \and C_{103}\mo\ymi
\pmb{\|[\big]}
\end{aligned}$$

\

Now let's focus on the conditional. The information we are given consists of the values of the $C$ variate for units #1 to #100, which we can `and` together. We must  also `and` all other information implicit in the stock-exchange problem, which we denote $\yi[s]$:

$$
 \pmb{\|[\big]} C_{100}\mo\ypl \and C_{99}\mo\ypl \and \dotsc \and 
C_{3}\mo\ypl \and C_{2}\mo\ymi \and C_{1}\mo\ymi \and \yi[s] \bigr)
$$


We finally arrive at the eight probabilities (which constitute a probability distribution) that we want to calculate:

:::{.column-page-right}
$$\begin{aligned}
&\P\bigl(C_{101}\mo\ypl \and C_{102}\mo\ypl \and C_{103}\mo\ypl
\pmb{\|[\big]} C_{100}\mo\ypl \and C_{99}\mo\ypl \and \dotsc \and 
C_{3}\mo\ypl \and C_{2}\mo\ymi \and C_{1}\mo\ymi \and \yi[s] \bigr)
\\[1ex]
&\P\bigl(C_{101}\mo\ymi \and C_{102}\mo\ypl \and C_{103}\mo\ypl
\pmb{\|[\big]} C_{100}\mo\ypl \and C_{99}\mo\ypl \and \dotsc \and 
C_{3}\mo\ypl \and C_{2}\mo\ymi \and C_{1}\mo\ymi \and \yi[s] \bigr)
\\[1ex]
&\dotso
\\[1ex]
&\P\bigl(C_{101}\mo\ymi \and C_{102}\mo\ymi \and C_{103}\mo\ymi
\pmb{\|[\big]} C_{100}\mo\ypl \and C_{99}\mo\ypl \and \dotsc \and 
C_{3}\mo\ypl \and C_{2}\mo\ymi \and C_{1}\mo\ymi \and \yi[s] \bigr)
\end{aligned}$$
:::

:::{.callout-caution}
## {{< fa user-edit >}} Exercise
Do a similar analysis for the Mars-prospecting problem, and write down the final probability distribution that we wish to calculate.
:::

<!-- :::{.column-page-right} -->
<!-- $$\begin{aligned} -->
<!-- &\P(H_{101}\mo\yy \and H_{102}\mo\yy \and H_{103}\mo\yy -->
<!-- \| H_{100}\mo\yy \and H_{99}\mo\yy \and \dotsc \and -->
<!-- H_{3}\mo\yn \and H_{2}\mo\yy \and H_{1}\mo\yy \and \yi[M] ) -->
<!-- \\[1ex] -->
<!-- &\P(H_{101}\mo\yn \and H_{102}\mo\yy \and H_{103}\mo\yy -->
<!-- \| H_{100}\mo\yy \and H_{99}\mo\yy \and \dotsc \and -->
<!-- H_{3}\mo\yn \and H_{2}\mo\yy \and H_{1}\mo\yy \and \yi[M] ) -->
<!-- \\[1ex] -->
<!-- &\dotso -->
<!-- \\[1ex] -->
<!-- &\P(H_{101}\mo\yn \and H_{102}\mo\yn \and H_{103}\mo\yn -->
<!-- \| H_{100}\mo\yy \and H_{99}\mo\yy \and \dotsc \and -->
<!-- H_{3}\mo\yn \and H_{2}\mo\yy \and H_{1}\mo\yy \and \yi[M] ) -->
<!-- \end{aligned}$$ -->
<!-- ::: -->

\

The next -- fundamental -- question is: how do we calculate these probabilities? Which other probabilities can we take as our starting point?

